[
    {
        "id": 30000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 1,
        "chunk": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 30000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 2,
        "chunk": "information loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 30000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 3,
        "chunk": "proposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 30000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 4,
        "chunk": "price levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 30000001,
        "doi": null,
        "title": "Dataset Size Recovery from LoRA Weights",
        "abstract": "Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its\nweights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a\nsimple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean\nabsolute error of 0.36 images, establishing the feasibility of this attack.",
        "chunk-id": 1,
        "chunk": "Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its",
        "authors": [
            "Mohammad Salama",
            "Jonathan Kahana",
            "Eliahu Horwitz",
            "Yedid Hoshen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19395v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19395v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000001,
        "doi": null,
        "title": "Dataset Size Recovery from LoRA Weights",
        "abstract": "Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its\nweights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a\nsimple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean\nabsolute error of 0.36 images, establishing the feasibility of this attack.",
        "chunk-id": 2,
        "chunk": "weights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a",
        "authors": [
            "Mohammad Salama",
            "Jonathan Kahana",
            "Eliahu Horwitz",
            "Yedid Hoshen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19395v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19395v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000001,
        "doi": null,
        "title": "Dataset Size Recovery from LoRA Weights",
        "abstract": "Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its\nweights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a\nsimple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean\nabsolute error of 0.36 images, establishing the feasibility of this attack.",
        "chunk-id": 3,
        "chunk": "simple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean",
        "authors": [
            "Mohammad Salama",
            "Jonathan Kahana",
            "Eliahu Horwitz",
            "Yedid Hoshen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19395v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19395v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000001,
        "doi": null,
        "title": "Dataset Size Recovery from LoRA Weights",
        "abstract": "Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its\nweights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a\nsimple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean\nabsolute error of 0.36 images, establishing the feasibility of this attack.",
        "chunk-id": 4,
        "chunk": "absolute error of 0.36 images, establishing the feasibility of this attack.",
        "authors": [
            "Mohammad Salama",
            "Jonathan Kahana",
            "Eliahu Horwitz",
            "Yedid Hoshen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19395v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19395v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000002,
        "doi": null,
        "title": "HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection",
        "abstract": "Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a\ncomprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic\nself-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline\nproposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.",
        "chunk-id": 1,
        "chunk": "Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a",
        "authors": [
            "Liujuan Cao",
            "Jianghang Lin",
            "Zebo Hong",
            "Yunhang Shen",
            "Shaohui Lin",
            "Chao Chen",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19394v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19394v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000002,
        "doi": null,
        "title": "HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection",
        "abstract": "Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a\ncomprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic\nself-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline\nproposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.",
        "chunk-id": 2,
        "chunk": "comprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic",
        "authors": [
            "Liujuan Cao",
            "Jianghang Lin",
            "Zebo Hong",
            "Yunhang Shen",
            "Shaohui Lin",
            "Chao Chen",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19394v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19394v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000002,
        "doi": null,
        "title": "HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection",
        "abstract": "Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a\ncomprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic\nself-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline\nproposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.",
        "chunk-id": 3,
        "chunk": "self-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline",
        "authors": [
            "Liujuan Cao",
            "Jianghang Lin",
            "Zebo Hong",
            "Yunhang Shen",
            "Shaohui Lin",
            "Chao Chen",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19394v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19394v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000002,
        "doi": null,
        "title": "HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection",
        "abstract": "Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a\ncomprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic\nself-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline\nproposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.",
        "chunk-id": 4,
        "chunk": "proposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.",
        "authors": [
            "Liujuan Cao",
            "Jianghang Lin",
            "Zebo Hong",
            "Yunhang Shen",
            "Shaohui Lin",
            "Chao Chen",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19394v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19394v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000003,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 1,
        "chunk": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000003,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 2,
        "chunk": "address this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000003,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 3,
        "chunk": "alignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000004,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 1,
        "chunk": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000004,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 2,
        "chunk": "relationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000004,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 3,
        "chunk": "Our benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000004,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 4,
        "chunk": "generated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 1,
        "chunk": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 2,
        "chunk": "works have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 3,
        "chunk": "often fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 4,
        "chunk": "proximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 5,
        "chunk": "learning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000005,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 6,
        "chunk": "to standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000006,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 1,
        "chunk": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000006,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 2,
        "chunk": "subsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000006,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 3,
        "chunk": "without sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000007,
        "doi": null,
        "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
        "abstract": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.",
        "chunk-id": 1,
        "chunk": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have",
        "authors": [
            "Tao Zhang",
            "Xiangtai Li",
            "Hao Fei",
            "Haobo Yuan",
            "Shengqiong Wu",
            "Shunping Ji",
            "Chen Change Loy",
            "Shuicheng Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19389v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19389v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000007,
        "doi": null,
        "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
        "abstract": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.",
        "chunk-id": 2,
        "chunk": "difficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal",
        "authors": [
            "Tao Zhang",
            "Xiangtai Li",
            "Hao Fei",
            "Haobo Yuan",
            "Shengqiong Wu",
            "Shunping Ji",
            "Chen Change Loy",
            "Shuicheng Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19389v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19389v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000007,
        "doi": null,
        "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
        "abstract": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.",
        "chunk-id": 3,
        "chunk": "segmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate",
        "authors": [
            "Tao Zhang",
            "Xiangtai Li",
            "Hao Fei",
            "Haobo Yuan",
            "Shengqiong Wu",
            "Shunping Ji",
            "Chen Change Loy",
            "Shuicheng Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19389v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19389v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000007,
        "doi": null,
        "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
        "abstract": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.",
        "chunk-id": 4,
        "chunk": "perception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and",
        "authors": [
            "Tao Zhang",
            "Xiangtai Li",
            "Hao Fei",
            "Haobo Yuan",
            "Shengqiong Wu",
            "Shunping Ji",
            "Chen Change Loy",
            "Shuicheng Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19389v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19389v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000007,
        "doi": null,
        "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
        "abstract": "Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.",
        "chunk-id": 5,
        "chunk": "model have been released for further research.",
        "authors": [
            "Tao Zhang",
            "Xiangtai Li",
            "Hao Fei",
            "Haobo Yuan",
            "Shengqiong Wu",
            "Shunping Ji",
            "Chen Change Loy",
            "Shuicheng Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19389v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19389v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000008,
        "doi": null,
        "title": "Taming Data and Transformers for Audio Generation",
        "abstract": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "chunk-id": 1,
        "chunk": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and",
        "authors": [
            "Moayed Haji-Ali",
            "Willi Menapace",
            "Aliaksandr Siarohin",
            "Guha Balakrishnan",
            "Sergey Tulyakov",
            "Vicente Ordonez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:58:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19388v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19388v1",
        "categories": [
            "Sound",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Multimedia",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000008,
        "doi": null,
        "title": "Taming Data and Transformers for Audio Generation",
        "abstract": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "chunk-id": 2,
        "chunk": "efficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We",
        "authors": [
            "Moayed Haji-Ali",
            "Willi Menapace",
            "Aliaksandr Siarohin",
            "Guha Balakrishnan",
            "Sergey Tulyakov",
            "Vicente Ordonez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:58:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19388v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19388v1",
        "categories": [
            "Sound",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Multimedia",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000008,
        "doi": null,
        "title": "Taming Data and Transformers for Audio Generation",
        "abstract": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "chunk-id": 3,
        "chunk": "then use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu",
        "authors": [
            "Moayed Haji-Ali",
            "Willi Menapace",
            "Aliaksandr Siarohin",
            "Guha Balakrishnan",
            "Sergey Tulyakov",
            "Vicente Ordonez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:58:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19388v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19388v1",
        "categories": [
            "Sound",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Multimedia",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000008,
        "doi": null,
        "title": "Taming Data and Transformers for Audio Generation",
        "abstract": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "chunk-id": 4,
        "chunk": "obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio",
        "authors": [
            "Moayed Haji-Ali",
            "Willi Menapace",
            "Aliaksandr Siarohin",
            "Guha Balakrishnan",
            "Sergey Tulyakov",
            "Vicente Ordonez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:58:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19388v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19388v1",
        "categories": [
            "Sound",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Multimedia",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000008,
        "doi": null,
        "title": "Taming Data and Transformers for Audio Generation",
        "abstract": "Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "chunk-id": 5,
        "chunk": "samples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.",
        "authors": [
            "Moayed Haji-Ali",
            "Willi Menapace",
            "Aliaksandr Siarohin",
            "Guha Balakrishnan",
            "Sergey Tulyakov",
            "Vicente Ordonez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:58:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19388v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19388v1",
        "categories": [
            "Sound",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Multimedia",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000009,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 1,
        "chunk": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000009,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 2,
        "chunk": "experiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000009,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 3,
        "chunk": "features. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000010,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 1,
        "chunk": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 30000010,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 2,
        "chunk": "differential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 30000010,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 3,
        "chunk": "that can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 30000011,
        "doi": null,
        "title": "Characterizing Contextuality via Rank Separation with Applications to Cloning",
        "abstract": "Quantum contextuality is a key nonclassical feature essential for\nunderstanding advantages in quantum computation and communication. We introduce\na new framework to study contextuality based solely on information processing\nstatistics. This simple and intuitive perspective leads to a powerful criterion\ndenoted as rank separation for identifying contextuality in various quantum\nscenarios. We showcase the power of this technique through several\napplications, including a new derivation of Hardy's quantum excess-baggage\ntheorem, and a simplified proof of contextuality for minimum error quantum\nstate discrimination. Finally, we show as a prominent example that quantum\ncontextuality provides the resource in optimal phase-covariant and universal\ncloning schemes, hence establishing it as a fundamental source of\nnonclassicality in all known optimal quantum cloning scenarios.",
        "chunk-id": 1,
        "chunk": "Quantum contextuality is a key nonclassical feature essential for\nunderstanding advantages in quantum computation and communication. We introduce\na new framework to study contextuality based solely on information processing\nstatistics. This simple and intuitive perspective leads to a powerful criterion\ndenoted as rank separation for identifying contextuality in various quantum",
        "authors": [
            "Farid Shahandeh",
            "Theodoros Yianni",
            "Mina Doosti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:56:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19382v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19382v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000011,
        "doi": null,
        "title": "Characterizing Contextuality via Rank Separation with Applications to Cloning",
        "abstract": "Quantum contextuality is a key nonclassical feature essential for\nunderstanding advantages in quantum computation and communication. We introduce\na new framework to study contextuality based solely on information processing\nstatistics. This simple and intuitive perspective leads to a powerful criterion\ndenoted as rank separation for identifying contextuality in various quantum\nscenarios. We showcase the power of this technique through several\napplications, including a new derivation of Hardy's quantum excess-baggage\ntheorem, and a simplified proof of contextuality for minimum error quantum\nstate discrimination. Finally, we show as a prominent example that quantum\ncontextuality provides the resource in optimal phase-covariant and universal\ncloning schemes, hence establishing it as a fundamental source of\nnonclassicality in all known optimal quantum cloning scenarios.",
        "chunk-id": 2,
        "chunk": "scenarios. We showcase the power of this technique through several\napplications, including a new derivation of Hardy's quantum excess-baggage\ntheorem, and a simplified proof of contextuality for minimum error quantum\nstate discrimination. Finally, we show as a prominent example that quantum\ncontextuality provides the resource in optimal phase-covariant and universal",
        "authors": [
            "Farid Shahandeh",
            "Theodoros Yianni",
            "Mina Doosti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:56:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19382v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19382v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000011,
        "doi": null,
        "title": "Characterizing Contextuality via Rank Separation with Applications to Cloning",
        "abstract": "Quantum contextuality is a key nonclassical feature essential for\nunderstanding advantages in quantum computation and communication. We introduce\na new framework to study contextuality based solely on information processing\nstatistics. This simple and intuitive perspective leads to a powerful criterion\ndenoted as rank separation for identifying contextuality in various quantum\nscenarios. We showcase the power of this technique through several\napplications, including a new derivation of Hardy's quantum excess-baggage\ntheorem, and a simplified proof of contextuality for minimum error quantum\nstate discrimination. Finally, we show as a prominent example that quantum\ncontextuality provides the resource in optimal phase-covariant and universal\ncloning schemes, hence establishing it as a fundamental source of\nnonclassicality in all known optimal quantum cloning scenarios.",
        "chunk-id": 3,
        "chunk": "cloning schemes, hence establishing it as a fundamental source of\nnonclassicality in all known optimal quantum cloning scenarios.",
        "authors": [
            "Farid Shahandeh",
            "Theodoros Yianni",
            "Mina Doosti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:56:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19382v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19382v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000012,
        "doi": null,
        "title": "Higher-Order Constrained Dependency Pairs for (Universal) Computability",
        "abstract": "Dependency pairs constitute a series of very effective techniques for the\ntermination analysis of term rewriting systems. In this paper, we adapt the\nstatic dependency pair framework to logically constrained simply-typed term\nrewriting systems (LCSTRSs), a higher-order formalism with logical constraints\nbuilt in. We also propose the concept of universal computability, which enables\na form of open-world termination analysis through the use of static dependency\npairs.",
        "chunk-id": 1,
        "chunk": "Dependency pairs constitute a series of very effective techniques for the\ntermination analysis of term rewriting systems. In this paper, we adapt the\nstatic dependency pair framework to logically constrained simply-typed term\nrewriting systems (LCSTRSs), a higher-order formalism with logical constraints\nbuilt in. We also propose the concept of universal computability, which enables",
        "authors": [
            "Liye Guo",
            "Kasper Hagens",
            "Cynthia Kop",
            "Deivid Vale"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19379v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19379v1",
        "categories": [
            "Logic in Computer Science"
        ]
    },
    {
        "id": 30000012,
        "doi": null,
        "title": "Higher-Order Constrained Dependency Pairs for (Universal) Computability",
        "abstract": "Dependency pairs constitute a series of very effective techniques for the\ntermination analysis of term rewriting systems. In this paper, we adapt the\nstatic dependency pair framework to logically constrained simply-typed term\nrewriting systems (LCSTRSs), a higher-order formalism with logical constraints\nbuilt in. We also propose the concept of universal computability, which enables\na form of open-world termination analysis through the use of static dependency\npairs.",
        "chunk-id": 2,
        "chunk": "a form of open-world termination analysis through the use of static dependency\npairs.",
        "authors": [
            "Liye Guo",
            "Kasper Hagens",
            "Cynthia Kop",
            "Deivid Vale"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19379v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19379v1",
        "categories": [
            "Logic in Computer Science"
        ]
    },
    {
        "id": 30000013,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 1,
        "chunk": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000013,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 2,
        "chunk": "Component Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000013,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 3,
        "chunk": "Since the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000014,
        "doi": null,
        "title": "A Novel Phase Diagram for a Spin-1 System Exhibiting a Haldane Phase",
        "abstract": "We provide the phase diagram of a 2-parameter spin-1 chain that has a\nsymmetry-protected topological (SPT) Haldane phase using computational\nalgorithms along with tensor-network tools. We improve previous results,\nshowing the existence of a new phase and new triple points. New striking\nfeatures are the triple end of the Haldane phase and the complexity of phases\nbordering the Haldane phase in proximity allowing moving to nearby non-SPT\nphases via small perturbations. These characteristics make the system, which\nappears in Rydberg excitons, e.g. in Cu$_2$O, a prime candidate for\napplications.",
        "chunk-id": 1,
        "chunk": "We provide the phase diagram of a 2-parameter spin-1 chain that has a\nsymmetry-protected topological (SPT) Haldane phase using computational\nalgorithms along with tensor-network tools. We improve previous results,\nshowing the existence of a new phase and new triple points. New striking\nfeatures are the triple end of the Haldane phase and the complexity of phases",
        "authors": [
            "Mohamad Mousa",
            "Birgit Wehefritz-Kaufmann",
            "Sabre Kais",
            "Shawn Cui",
            "Ralph Kaufmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:51:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19372v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19372v1",
        "categories": [
            "Strongly Correlated Electrons"
        ]
    },
    {
        "id": 30000014,
        "doi": null,
        "title": "A Novel Phase Diagram for a Spin-1 System Exhibiting a Haldane Phase",
        "abstract": "We provide the phase diagram of a 2-parameter spin-1 chain that has a\nsymmetry-protected topological (SPT) Haldane phase using computational\nalgorithms along with tensor-network tools. We improve previous results,\nshowing the existence of a new phase and new triple points. New striking\nfeatures are the triple end of the Haldane phase and the complexity of phases\nbordering the Haldane phase in proximity allowing moving to nearby non-SPT\nphases via small perturbations. These characteristics make the system, which\nappears in Rydberg excitons, e.g. in Cu$_2$O, a prime candidate for\napplications.",
        "chunk-id": 2,
        "chunk": "bordering the Haldane phase in proximity allowing moving to nearby non-SPT\nphases via small perturbations. These characteristics make the system, which\nappears in Rydberg excitons, e.g. in Cu$_2$O, a prime candidate for\napplications.",
        "authors": [
            "Mohamad Mousa",
            "Birgit Wehefritz-Kaufmann",
            "Sabre Kais",
            "Shawn Cui",
            "Ralph Kaufmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:51:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19372v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19372v1",
        "categories": [
            "Strongly Correlated Electrons"
        ]
    },
    {
        "id": 30000015,
        "doi": null,
        "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
        "abstract": "Existing research on instruction following largely focuses on tasks with\nsimple instructions and short responses. In this work, we explore\nmulti-constraint instruction following for generating long-form text. We create\nSuri, a dataset with 20K human-written long-form texts paired with\nLLM-generated backtranslated instructions that contain multiple complex\nconstraints. Because of prohibitive challenges associated with collecting human\npreference judgments on long-form texts, preference-tuning algorithms such as\nDPO are infeasible in our setting; thus, we propose Instructional ORPO\n(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving\nnegative feedback from dispreferred responses, I-ORPO obtains negative feedback\nfrom synthetically corrupted instructions generated by an LLM. Using Suri, we\nperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The\nresulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts\n(~5K tokens) than base models without significant quality deterioration. Our\nhuman evaluation shows that while both SFT and I-ORPO models satisfy most\nconstraints, Suri-I-ORPO generations are generally preferred for their coherent\nand informative incorporation of the constraints. We release our code at\nhttps://github.com/chtmp223/suri.",
        "chunk-id": 1,
        "chunk": "Existing research on instruction following largely focuses on tasks with\nsimple instructions and short responses. In this work, we explore\nmulti-constraint instruction following for generating long-form text. We create\nSuri, a dataset with 20K human-written long-form texts paired with\nLLM-generated backtranslated instructions that contain multiple complex",
        "authors": [
            "Chau Minh Pham",
            "Simeng Sun",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19371v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19371v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000015,
        "doi": null,
        "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
        "abstract": "Existing research on instruction following largely focuses on tasks with\nsimple instructions and short responses. In this work, we explore\nmulti-constraint instruction following for generating long-form text. We create\nSuri, a dataset with 20K human-written long-form texts paired with\nLLM-generated backtranslated instructions that contain multiple complex\nconstraints. Because of prohibitive challenges associated with collecting human\npreference judgments on long-form texts, preference-tuning algorithms such as\nDPO are infeasible in our setting; thus, we propose Instructional ORPO\n(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving\nnegative feedback from dispreferred responses, I-ORPO obtains negative feedback\nfrom synthetically corrupted instructions generated by an LLM. Using Suri, we\nperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The\nresulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts\n(~5K tokens) than base models without significant quality deterioration. Our\nhuman evaluation shows that while both SFT and I-ORPO models satisfy most\nconstraints, Suri-I-ORPO generations are generally preferred for their coherent\nand informative incorporation of the constraints. We release our code at\nhttps://github.com/chtmp223/suri.",
        "chunk-id": 2,
        "chunk": "constraints. Because of prohibitive challenges associated with collecting human\npreference judgments on long-form texts, preference-tuning algorithms such as\nDPO are infeasible in our setting; thus, we propose Instructional ORPO\n(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving",
        "authors": [
            "Chau Minh Pham",
            "Simeng Sun",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19371v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19371v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000015,
        "doi": null,
        "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
        "abstract": "Existing research on instruction following largely focuses on tasks with\nsimple instructions and short responses. In this work, we explore\nmulti-constraint instruction following for generating long-form text. We create\nSuri, a dataset with 20K human-written long-form texts paired with\nLLM-generated backtranslated instructions that contain multiple complex\nconstraints. Because of prohibitive challenges associated with collecting human\npreference judgments on long-form texts, preference-tuning algorithms such as\nDPO are infeasible in our setting; thus, we propose Instructional ORPO\n(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving\nnegative feedback from dispreferred responses, I-ORPO obtains negative feedback\nfrom synthetically corrupted instructions generated by an LLM. Using Suri, we\nperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The\nresulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts\n(~5K tokens) than base models without significant quality deterioration. Our\nhuman evaluation shows that while both SFT and I-ORPO models satisfy most\nconstraints, Suri-I-ORPO generations are generally preferred for their coherent\nand informative incorporation of the constraints. We release our code at\nhttps://github.com/chtmp223/suri.",
        "chunk-id": 3,
        "chunk": "negative feedback from dispreferred responses, I-ORPO obtains negative feedback\nfrom synthetically corrupted instructions generated by an LLM. Using Suri, we\nperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The\nresulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts",
        "authors": [
            "Chau Minh Pham",
            "Simeng Sun",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19371v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19371v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000015,
        "doi": null,
        "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
        "abstract": "Existing research on instruction following largely focuses on tasks with\nsimple instructions and short responses. In this work, we explore\nmulti-constraint instruction following for generating long-form text. We create\nSuri, a dataset with 20K human-written long-form texts paired with\nLLM-generated backtranslated instructions that contain multiple complex\nconstraints. Because of prohibitive challenges associated with collecting human\npreference judgments on long-form texts, preference-tuning algorithms such as\nDPO are infeasible in our setting; thus, we propose Instructional ORPO\n(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving\nnegative feedback from dispreferred responses, I-ORPO obtains negative feedback\nfrom synthetically corrupted instructions generated by an LLM. Using Suri, we\nperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The\nresulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts\n(~5K tokens) than base models without significant quality deterioration. Our\nhuman evaluation shows that while both SFT and I-ORPO models satisfy most\nconstraints, Suri-I-ORPO generations are generally preferred for their coherent\nand informative incorporation of the constraints. We release our code at\nhttps://github.com/chtmp223/suri.",
        "chunk-id": 4,
        "chunk": "(~5K tokens) than base models without significant quality deterioration. Our\nhuman evaluation shows that while both SFT and I-ORPO models satisfy most\nconstraints, Suri-I-ORPO generations are generally preferred for their coherent\nand informative incorporation of the constraints. We release our code at\nhttps://github.com/chtmp223/suri.",
        "authors": [
            "Chau Minh Pham",
            "Simeng Sun",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19371v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19371v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000016,
        "doi": null,
        "title": "Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model",
        "abstract": "Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different\narchitectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we\nbuild a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale\ntransformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.",
        "chunk-id": 1,
        "chunk": "Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different",
        "authors": [
            "Haobo Yuan",
            "Xiangtai Li",
            "Lu Qi",
            "Tao Zhang",
            "Ming-Hsuan Yang",
            "Shuicheng Yan",
            "Chen Change Loy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:49:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19369v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19369v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000016,
        "doi": null,
        "title": "Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model",
        "abstract": "Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different\narchitectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we\nbuild a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale\ntransformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.",
        "chunk-id": 2,
        "chunk": "architectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we",
        "authors": [
            "Haobo Yuan",
            "Xiangtai Li",
            "Lu Qi",
            "Tao Zhang",
            "Ming-Hsuan Yang",
            "Shuicheng Yan",
            "Chen Change Loy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:49:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19369v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19369v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000016,
        "doi": null,
        "title": "Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model",
        "abstract": "Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different\narchitectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we\nbuild a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale\ntransformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.",
        "chunk-id": 3,
        "chunk": "build a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale",
        "authors": [
            "Haobo Yuan",
            "Xiangtai Li",
            "Lu Qi",
            "Tao Zhang",
            "Ming-Hsuan Yang",
            "Shuicheng Yan",
            "Chen Change Loy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:49:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19369v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19369v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000016,
        "doi": null,
        "title": "Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model",
        "abstract": "Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different\narchitectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we\nbuild a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale\ntransformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.",
        "chunk-id": 4,
        "chunk": "transformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.",
        "authors": [
            "Haobo Yuan",
            "Xiangtai Li",
            "Lu Qi",
            "Tao Zhang",
            "Ming-Hsuan Yang",
            "Shuicheng Yan",
            "Chen Change Loy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:49:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19369v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19369v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000017,
        "doi": null,
        "title": "SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text Cues",
        "abstract": "Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in\ntraining segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:\ncolonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.",
        "chunk-id": 1,
        "chunk": "Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in",
        "authors": [
            "Yuxin Xie",
            "Tao Zhou",
            "Yi Zhou",
            "Geng Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:46:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19364v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19364v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000017,
        "doi": null,
        "title": "SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text Cues",
        "abstract": "Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in\ntraining segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:\ncolonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.",
        "chunk-id": 2,
        "chunk": "training segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:",
        "authors": [
            "Yuxin Xie",
            "Tao Zhou",
            "Yi Zhou",
            "Geng Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:46:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19364v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19364v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000017,
        "doi": null,
        "title": "SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text Cues",
        "abstract": "Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in\ntraining segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:\ncolonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.",
        "chunk-id": 3,
        "chunk": "colonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.",
        "authors": [
            "Yuxin Xie",
            "Tao Zhou",
            "Yi Zhou",
            "Geng Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:46:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19364v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19364v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000018,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 1,
        "chunk": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000018,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 2,
        "chunk": "solution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000018,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 3,
        "chunk": "the absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000018,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 4,
        "chunk": "challenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000018,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 5,
        "chunk": "a Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000019,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 1,
        "chunk": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000019,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 2,
        "chunk": "cross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000019,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 3,
        "chunk": "among public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000020,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 1,
        "chunk": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000020,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 2,
        "chunk": "crucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000020,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 3,
        "chunk": "MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000020,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 4,
        "chunk": "human evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000021,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 1,
        "chunk": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000021,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 2,
        "chunk": "a storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000021,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 3,
        "chunk": "problems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000021,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 4,
        "chunk": "entailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000021,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 5,
        "chunk": "a desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000022,
        "doi": null,
        "title": "CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement",
        "abstract": "Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object\nrearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K\ncollaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness\nof our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.",
        "chunk-id": 1,
        "chunk": "Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object",
        "authors": [
            "Chengwen Zhang",
            "Yun Liu",
            "Ruofan Xing",
            "Bingda Tang",
            "Li Yi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:32:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19353v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19353v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000022,
        "doi": null,
        "title": "CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement",
        "abstract": "Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object\nrearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K\ncollaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness\nof our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.",
        "chunk-id": 2,
        "chunk": "rearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K",
        "authors": [
            "Chengwen Zhang",
            "Yun Liu",
            "Ruofan Xing",
            "Bingda Tang",
            "Li Yi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:32:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19353v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19353v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000022,
        "doi": null,
        "title": "CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement",
        "abstract": "Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object\nrearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K\ncollaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness\nof our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.",
        "chunk-id": 3,
        "chunk": "collaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness",
        "authors": [
            "Chengwen Zhang",
            "Yun Liu",
            "Ruofan Xing",
            "Bingda Tang",
            "Li Yi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:32:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19353v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19353v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000022,
        "doi": null,
        "title": "CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement",
        "abstract": "Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object\nrearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K\ncollaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness\nof our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.",
        "chunk-id": 4,
        "chunk": "of our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.",
        "authors": [
            "Chengwen Zhang",
            "Yun Liu",
            "Ruofan Xing",
            "Bingda Tang",
            "Li Yi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:32:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19353v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19353v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000023,
        "doi": null,
        "title": "Periodic phenomena in equivariant stable homotopy theory",
        "abstract": "Building off of many recent advances in the subject by many different\nresearchers, we describe a picture of A-equivariant chromatic homotopy theory\nwhich mirrors the now classical non-equivariant picture of Morava,\nMiller-Ravenel-Wilson, and Devinatz-Hopkins-Smith, where A is a finite abelian\np-group. Specifically, we review the structure of the Balmer spectrum of the\ncategory of A-spectra, and the work of Hausmann-Meier connecting this to MU_A\nand equivariant formal group laws. Generalizing work of\nBhattacharya-Guillou-Li, we introduce equivariant analogs of v_n-self maps, and\ngeneralizing work of Carrick and Balderrama, we introduce equivariant analogs\nof the chromatic tower, and give equivariant analogs of the smash product and\nchromatic convergence theorems. The equivariant monochromatic theory is also\ndiscussed. We explore computational examples of this theory in the case of A =\nC_2, where we connect equivariant chromatic theory with redshift phenomena in\nMahowald invariants.",
        "chunk-id": 1,
        "chunk": "Building off of many recent advances in the subject by many different\nresearchers, we describe a picture of A-equivariant chromatic homotopy theory\nwhich mirrors the now classical non-equivariant picture of Morava,\nMiller-Ravenel-Wilson, and Devinatz-Hopkins-Smith, where A is a finite abelian\np-group. Specifically, we review the structure of the Balmer spectrum of the",
        "authors": [
            "Mark Behrens",
            "Jack Carlisle"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19352v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19352v1",
        "categories": [
            "Algebraic Topology"
        ]
    },
    {
        "id": 30000023,
        "doi": null,
        "title": "Periodic phenomena in equivariant stable homotopy theory",
        "abstract": "Building off of many recent advances in the subject by many different\nresearchers, we describe a picture of A-equivariant chromatic homotopy theory\nwhich mirrors the now classical non-equivariant picture of Morava,\nMiller-Ravenel-Wilson, and Devinatz-Hopkins-Smith, where A is a finite abelian\np-group. Specifically, we review the structure of the Balmer spectrum of the\ncategory of A-spectra, and the work of Hausmann-Meier connecting this to MU_A\nand equivariant formal group laws. Generalizing work of\nBhattacharya-Guillou-Li, we introduce equivariant analogs of v_n-self maps, and\ngeneralizing work of Carrick and Balderrama, we introduce equivariant analogs\nof the chromatic tower, and give equivariant analogs of the smash product and\nchromatic convergence theorems. The equivariant monochromatic theory is also\ndiscussed. We explore computational examples of this theory in the case of A =\nC_2, where we connect equivariant chromatic theory with redshift phenomena in\nMahowald invariants.",
        "chunk-id": 2,
        "chunk": "category of A-spectra, and the work of Hausmann-Meier connecting this to MU_A\nand equivariant formal group laws. Generalizing work of\nBhattacharya-Guillou-Li, we introduce equivariant analogs of v_n-self maps, and\ngeneralizing work of Carrick and Balderrama, we introduce equivariant analogs\nof the chromatic tower, and give equivariant analogs of the smash product and",
        "authors": [
            "Mark Behrens",
            "Jack Carlisle"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19352v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19352v1",
        "categories": [
            "Algebraic Topology"
        ]
    },
    {
        "id": 30000023,
        "doi": null,
        "title": "Periodic phenomena in equivariant stable homotopy theory",
        "abstract": "Building off of many recent advances in the subject by many different\nresearchers, we describe a picture of A-equivariant chromatic homotopy theory\nwhich mirrors the now classical non-equivariant picture of Morava,\nMiller-Ravenel-Wilson, and Devinatz-Hopkins-Smith, where A is a finite abelian\np-group. Specifically, we review the structure of the Balmer spectrum of the\ncategory of A-spectra, and the work of Hausmann-Meier connecting this to MU_A\nand equivariant formal group laws. Generalizing work of\nBhattacharya-Guillou-Li, we introduce equivariant analogs of v_n-self maps, and\ngeneralizing work of Carrick and Balderrama, we introduce equivariant analogs\nof the chromatic tower, and give equivariant analogs of the smash product and\nchromatic convergence theorems. The equivariant monochromatic theory is also\ndiscussed. We explore computational examples of this theory in the case of A =\nC_2, where we connect equivariant chromatic theory with redshift phenomena in\nMahowald invariants.",
        "chunk-id": 3,
        "chunk": "chromatic convergence theorems. The equivariant monochromatic theory is also\ndiscussed. We explore computational examples of this theory in the case of A =\nC_2, where we connect equivariant chromatic theory with redshift phenomena in\nMahowald invariants.",
        "authors": [
            "Mark Behrens",
            "Jack Carlisle"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19352v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19352v1",
        "categories": [
            "Algebraic Topology"
        ]
    },
    {
        "id": 30000024,
        "doi": null,
        "title": "Dynamical Analysis of Autobidding Systems",
        "abstract": "It has become the default in markets such as ad auctions for participants to\nbid in an auction through automated bidding agents (autobidders) which adjust\nbids over time to satisfy return-over-spend constraints. Despite the prominence\nof such systems for the internet economy, their resulting dynamical behavior is\nstill not well understood. Although one might hope that such relatively simple\nsystems would typically converge to the equilibria of their underlying\nauctions, we provide a plethora of results that show the emergence of complex\nbehavior, such as bi-stability, periodic orbits and quasi periodicity. We\nempirically observe how the market structure (expressed as motifs)\nqualitatively affects the behavior of the dynamics. We complement it with\ntheoretical results showing that autobidding systems can simulate both linear\ndynamical systems as well logical boolean gates.",
        "chunk-id": 1,
        "chunk": "It has become the default in markets such as ad auctions for participants to\nbid in an auction through automated bidding agents (autobidders) which adjust\nbids over time to satisfy return-over-spend constraints. Despite the prominence\nof such systems for the internet economy, their resulting dynamical behavior is",
        "authors": [
            "Renato Paes Leme",
            "Georgios Piliouras",
            "Jon Schneider",
            "Kelly Spendlove",
            "Song Zuo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:30:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19350v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19350v1",
        "categories": [
            "Computer Science and Game Theory"
        ]
    },
    {
        "id": 30000024,
        "doi": null,
        "title": "Dynamical Analysis of Autobidding Systems",
        "abstract": "It has become the default in markets such as ad auctions for participants to\nbid in an auction through automated bidding agents (autobidders) which adjust\nbids over time to satisfy return-over-spend constraints. Despite the prominence\nof such systems for the internet economy, their resulting dynamical behavior is\nstill not well understood. Although one might hope that such relatively simple\nsystems would typically converge to the equilibria of their underlying\nauctions, we provide a plethora of results that show the emergence of complex\nbehavior, such as bi-stability, periodic orbits and quasi periodicity. We\nempirically observe how the market structure (expressed as motifs)\nqualitatively affects the behavior of the dynamics. We complement it with\ntheoretical results showing that autobidding systems can simulate both linear\ndynamical systems as well logical boolean gates.",
        "chunk-id": 2,
        "chunk": "still not well understood. Although one might hope that such relatively simple\nsystems would typically converge to the equilibria of their underlying\nauctions, we provide a plethora of results that show the emergence of complex\nbehavior, such as bi-stability, periodic orbits and quasi periodicity. We\nempirically observe how the market structure (expressed as motifs)",
        "authors": [
            "Renato Paes Leme",
            "Georgios Piliouras",
            "Jon Schneider",
            "Kelly Spendlove",
            "Song Zuo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:30:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19350v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19350v1",
        "categories": [
            "Computer Science and Game Theory"
        ]
    },
    {
        "id": 30000024,
        "doi": null,
        "title": "Dynamical Analysis of Autobidding Systems",
        "abstract": "It has become the default in markets such as ad auctions for participants to\nbid in an auction through automated bidding agents (autobidders) which adjust\nbids over time to satisfy return-over-spend constraints. Despite the prominence\nof such systems for the internet economy, their resulting dynamical behavior is\nstill not well understood. Although one might hope that such relatively simple\nsystems would typically converge to the equilibria of their underlying\nauctions, we provide a plethora of results that show the emergence of complex\nbehavior, such as bi-stability, periodic orbits and quasi periodicity. We\nempirically observe how the market structure (expressed as motifs)\nqualitatively affects the behavior of the dynamics. We complement it with\ntheoretical results showing that autobidding systems can simulate both linear\ndynamical systems as well logical boolean gates.",
        "chunk-id": 3,
        "chunk": "qualitatively affects the behavior of the dynamics. We complement it with\ntheoretical results showing that autobidding systems can simulate both linear\ndynamical systems as well logical boolean gates.",
        "authors": [
            "Renato Paes Leme",
            "Georgios Piliouras",
            "Jon Schneider",
            "Kelly Spendlove",
            "Song Zuo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:30:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19350v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19350v1",
        "categories": [
            "Computer Science and Game Theory"
        ]
    },
    {
        "id": 30000025,
        "doi": null,
        "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
        "abstract": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
        "chunk-id": 1,
        "chunk": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian",
        "authors": [
            "Lucky Susanto",
            "Musa Izzanardi Wijanarko",
            "Prasetia Anugrah Pratama",
            "Traci Hong",
            "Ika Idris",
            "Alham Fikri Aji",
            "Derry Wijaya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:26:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19349v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19349v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000025,
        "doi": null,
        "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
        "abstract": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
        "chunk-id": 2,
        "chunk": "texts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity",
        "authors": [
            "Lucky Susanto",
            "Musa Izzanardi Wijanarko",
            "Prasetia Anugrah Pratama",
            "Traci Hong",
            "Ika Idris",
            "Alham Fikri Aji",
            "Derry Wijaya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:26:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19349v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19349v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000025,
        "doi": null,
        "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
        "abstract": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
        "chunk-id": 3,
        "chunk": "classification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)",
        "authors": [
            "Lucky Susanto",
            "Musa Izzanardi Wijanarko",
            "Prasetia Anugrah Pratama",
            "Traci Hong",
            "Ika Idris",
            "Alham Fikri Aji",
            "Derry Wijaya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:26:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19349v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19349v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000025,
        "doi": null,
        "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
        "abstract": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
        "chunk-id": 4,
        "chunk": "fine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
        "authors": [
            "Lucky Susanto",
            "Musa Izzanardi Wijanarko",
            "Prasetia Anugrah Pratama",
            "Traci Hong",
            "Ika Idris",
            "Alham Fikri Aji",
            "Derry Wijaya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:26:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19349v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19349v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000026,
        "doi": null,
        "title": "Unconditional Stability Analysis of N-Port Networks Based on Structured Singular Value Computation",
        "abstract": "In this paper, a novel approach based on robust stability concepts and tools\nis introduced to evaluate the unconditional stability of microwave active\n$\\textit{n}$-port devices. An efficient calculation of the Structured Singular\nValue of the $\\textit{n}$x$\\textit{n}$ scattering matrix is proposed to obtain\nthe stability characteristics of the device. The presented method is validated\nin two ways. First, it is applied to a referential 4x4 scattering parameter set\nfor independent verification. Second, the method is applied to a 4-port GaAs\nFET amplifier fabricated in hybrid technology. The results confirm the validity\nand computational efficiency of the proposed approach.",
        "chunk-id": 1,
        "chunk": "In this paper, a novel approach based on robust stability concepts and tools\nis introduced to evaluate the unconditional stability of microwave active\n$\\textit{n}$-port devices. An efficient calculation of the Structured Singular\nValue of the $\\textit{n}$x$\\textit{n}$ scattering matrix is proposed to obtain",
        "authors": [
            "Aimar Mateo",
            "Ibone Lizarraga",
            "Jorge Terrer",
            "Aitziber Anakabe",
            "J. M Collantes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19342v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19342v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000026,
        "doi": null,
        "title": "Unconditional Stability Analysis of N-Port Networks Based on Structured Singular Value Computation",
        "abstract": "In this paper, a novel approach based on robust stability concepts and tools\nis introduced to evaluate the unconditional stability of microwave active\n$\\textit{n}$-port devices. An efficient calculation of the Structured Singular\nValue of the $\\textit{n}$x$\\textit{n}$ scattering matrix is proposed to obtain\nthe stability characteristics of the device. The presented method is validated\nin two ways. First, it is applied to a referential 4x4 scattering parameter set\nfor independent verification. Second, the method is applied to a 4-port GaAs\nFET amplifier fabricated in hybrid technology. The results confirm the validity\nand computational efficiency of the proposed approach.",
        "chunk-id": 2,
        "chunk": "the stability characteristics of the device. The presented method is validated\nin two ways. First, it is applied to a referential 4x4 scattering parameter set\nfor independent verification. Second, the method is applied to a 4-port GaAs\nFET amplifier fabricated in hybrid technology. The results confirm the validity\nand computational efficiency of the proposed approach.",
        "authors": [
            "Aimar Mateo",
            "Ibone Lizarraga",
            "Jorge Terrer",
            "Aitziber Anakabe",
            "J. M Collantes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19342v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19342v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000027,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 1,
        "chunk": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000027,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 2,
        "chunk": "learned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000027,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 3,
        "chunk": "process, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000027,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 4,
        "chunk": "instance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000028,
        "doi": null,
        "title": "LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans",
        "abstract": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "chunk-id": 1,
        "chunk": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver",
        "authors": [
            "Kaushalya Sivayogaraj",
            "Sahan T. Guruge",
            "Udari Liyanage",
            "Jeevani Udupihille",
            "Saroj Jayasinghe",
            "Gerard Fernando",
            "Ranga Rodrigo",
            "M. Rukshani Liyanaarachchi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:10:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19336v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19336v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000028,
        "doi": null,
        "title": "LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans",
        "abstract": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "chunk-id": 2,
        "chunk": "visibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver",
        "authors": [
            "Kaushalya Sivayogaraj",
            "Sahan T. Guruge",
            "Udari Liyanage",
            "Jeevani Udupihille",
            "Saroj Jayasinghe",
            "Gerard Fernando",
            "Ranga Rodrigo",
            "M. Rukshani Liyanaarachchi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:10:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19336v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19336v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000028,
        "doi": null,
        "title": "LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans",
        "abstract": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "chunk-id": 3,
        "chunk": "reconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no",
        "authors": [
            "Kaushalya Sivayogaraj",
            "Sahan T. Guruge",
            "Udari Liyanage",
            "Jeevani Udupihille",
            "Saroj Jayasinghe",
            "Gerard Fernando",
            "Ranga Rodrigo",
            "M. Rukshani Liyanaarachchi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:10:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19336v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19336v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000028,
        "doi": null,
        "title": "LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans",
        "abstract": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "chunk-id": 4,
        "chunk": "significant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our",
        "authors": [
            "Kaushalya Sivayogaraj",
            "Sahan T. Guruge",
            "Udari Liyanage",
            "Jeevani Udupihille",
            "Saroj Jayasinghe",
            "Gerard Fernando",
            "Ranga Rodrigo",
            "M. Rukshani Liyanaarachchi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:10:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19336v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19336v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000028,
        "doi": null,
        "title": "LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans",
        "abstract": "3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "chunk-id": 5,
        "chunk": "knowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.",
        "authors": [
            "Kaushalya Sivayogaraj",
            "Sahan T. Guruge",
            "Udari Liyanage",
            "Jeevani Udupihille",
            "Saroj Jayasinghe",
            "Gerard Fernando",
            "Ranga Rodrigo",
            "M. Rukshani Liyanaarachchi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:10:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19336v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19336v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000029,
        "doi": null,
        "title": "Accelerating Multiphase Flow Simulations with Denoising Diffusion Model Driven Initializations",
        "abstract": "This study introduces a hybrid fluid simulation approach that integrates\ngenerative diffusion models with physics-based simulations, aiming at reducing\nthe computational costs of flow simulations while still honoring all the\nphysical properties of interest. These simulations enhance our understanding of\napplications such as assessing hydrogen and CO$_2$ storage efficiency in\nunderground reservoirs. Nevertheless, they are computationally expensive and\nthe presence of nonunique solutions can require multiple simulations within a\nsingle geometry. To overcome the computational cost hurdle, we propose a hybrid\nmethod that couples generative diffusion models and physics-based modeling. We\nintroduce a system to condition the diffusion model with a geometry of\ninterest, allowing to produce variable fluid saturations in the same geometry.\nWhile training the model, we simultaneously generate initial conditions and\nperform physics-based simulations using these conditions. This integrated\napproach enables us to receive real-time feedback on a single compute node\nequipped with both CPUs and GPUs. By efficiently managing these processes\nwithin one compute node, we can continuously evaluate performance and stop\ntraining when the desired criteria are met. To test our model, we generate\nrealizations in a real Berea sandstone fracture which shows that our technique\nis up to 4.4 times faster than commonly used flow simulation initializations.",
        "chunk-id": 1,
        "chunk": "This study introduces a hybrid fluid simulation approach that integrates\ngenerative diffusion models with physics-based simulations, aiming at reducing\nthe computational costs of flow simulations while still honoring all the\nphysical properties of interest. These simulations enhance our understanding of\napplications such as assessing hydrogen and CO$_2$ storage efficiency in",
        "authors": [
            "Jaehong Chung",
            "Agnese Marcato",
            "Eric J. Guiltinan",
            "Tapan Mukerji",
            "Hari Viswanathan",
            "Yen Ting Lin",
            "Javier E. Santos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19333v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19333v1",
        "categories": [
            "Geophysics",
            "Computational Physics",
            "Fluid Dynamics"
        ]
    },
    {
        "id": 30000029,
        "doi": null,
        "title": "Accelerating Multiphase Flow Simulations with Denoising Diffusion Model Driven Initializations",
        "abstract": "This study introduces a hybrid fluid simulation approach that integrates\ngenerative diffusion models with physics-based simulations, aiming at reducing\nthe computational costs of flow simulations while still honoring all the\nphysical properties of interest. These simulations enhance our understanding of\napplications such as assessing hydrogen and CO$_2$ storage efficiency in\nunderground reservoirs. Nevertheless, they are computationally expensive and\nthe presence of nonunique solutions can require multiple simulations within a\nsingle geometry. To overcome the computational cost hurdle, we propose a hybrid\nmethod that couples generative diffusion models and physics-based modeling. We\nintroduce a system to condition the diffusion model with a geometry of\ninterest, allowing to produce variable fluid saturations in the same geometry.\nWhile training the model, we simultaneously generate initial conditions and\nperform physics-based simulations using these conditions. This integrated\napproach enables us to receive real-time feedback on a single compute node\nequipped with both CPUs and GPUs. By efficiently managing these processes\nwithin one compute node, we can continuously evaluate performance and stop\ntraining when the desired criteria are met. To test our model, we generate\nrealizations in a real Berea sandstone fracture which shows that our technique\nis up to 4.4 times faster than commonly used flow simulation initializations.",
        "chunk-id": 2,
        "chunk": "underground reservoirs. Nevertheless, they are computationally expensive and\nthe presence of nonunique solutions can require multiple simulations within a\nsingle geometry. To overcome the computational cost hurdle, we propose a hybrid\nmethod that couples generative diffusion models and physics-based modeling. We\nintroduce a system to condition the diffusion model with a geometry of",
        "authors": [
            "Jaehong Chung",
            "Agnese Marcato",
            "Eric J. Guiltinan",
            "Tapan Mukerji",
            "Hari Viswanathan",
            "Yen Ting Lin",
            "Javier E. Santos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19333v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19333v1",
        "categories": [
            "Geophysics",
            "Computational Physics",
            "Fluid Dynamics"
        ]
    },
    {
        "id": 30000029,
        "doi": null,
        "title": "Accelerating Multiphase Flow Simulations with Denoising Diffusion Model Driven Initializations",
        "abstract": "This study introduces a hybrid fluid simulation approach that integrates\ngenerative diffusion models with physics-based simulations, aiming at reducing\nthe computational costs of flow simulations while still honoring all the\nphysical properties of interest. These simulations enhance our understanding of\napplications such as assessing hydrogen and CO$_2$ storage efficiency in\nunderground reservoirs. Nevertheless, they are computationally expensive and\nthe presence of nonunique solutions can require multiple simulations within a\nsingle geometry. To overcome the computational cost hurdle, we propose a hybrid\nmethod that couples generative diffusion models and physics-based modeling. We\nintroduce a system to condition the diffusion model with a geometry of\ninterest, allowing to produce variable fluid saturations in the same geometry.\nWhile training the model, we simultaneously generate initial conditions and\nperform physics-based simulations using these conditions. This integrated\napproach enables us to receive real-time feedback on a single compute node\nequipped with both CPUs and GPUs. By efficiently managing these processes\nwithin one compute node, we can continuously evaluate performance and stop\ntraining when the desired criteria are met. To test our model, we generate\nrealizations in a real Berea sandstone fracture which shows that our technique\nis up to 4.4 times faster than commonly used flow simulation initializations.",
        "chunk-id": 3,
        "chunk": "interest, allowing to produce variable fluid saturations in the same geometry.\nWhile training the model, we simultaneously generate initial conditions and\nperform physics-based simulations using these conditions. This integrated\napproach enables us to receive real-time feedback on a single compute node\nequipped with both CPUs and GPUs. By efficiently managing these processes",
        "authors": [
            "Jaehong Chung",
            "Agnese Marcato",
            "Eric J. Guiltinan",
            "Tapan Mukerji",
            "Hari Viswanathan",
            "Yen Ting Lin",
            "Javier E. Santos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19333v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19333v1",
        "categories": [
            "Geophysics",
            "Computational Physics",
            "Fluid Dynamics"
        ]
    },
    {
        "id": 30000029,
        "doi": null,
        "title": "Accelerating Multiphase Flow Simulations with Denoising Diffusion Model Driven Initializations",
        "abstract": "This study introduces a hybrid fluid simulation approach that integrates\ngenerative diffusion models with physics-based simulations, aiming at reducing\nthe computational costs of flow simulations while still honoring all the\nphysical properties of interest. These simulations enhance our understanding of\napplications such as assessing hydrogen and CO$_2$ storage efficiency in\nunderground reservoirs. Nevertheless, they are computationally expensive and\nthe presence of nonunique solutions can require multiple simulations within a\nsingle geometry. To overcome the computational cost hurdle, we propose a hybrid\nmethod that couples generative diffusion models and physics-based modeling. We\nintroduce a system to condition the diffusion model with a geometry of\ninterest, allowing to produce variable fluid saturations in the same geometry.\nWhile training the model, we simultaneously generate initial conditions and\nperform physics-based simulations using these conditions. This integrated\napproach enables us to receive real-time feedback on a single compute node\nequipped with both CPUs and GPUs. By efficiently managing these processes\nwithin one compute node, we can continuously evaluate performance and stop\ntraining when the desired criteria are met. To test our model, we generate\nrealizations in a real Berea sandstone fracture which shows that our technique\nis up to 4.4 times faster than commonly used flow simulation initializations.",
        "chunk-id": 4,
        "chunk": "within one compute node, we can continuously evaluate performance and stop\ntraining when the desired criteria are met. To test our model, we generate\nrealizations in a real Berea sandstone fracture which shows that our technique\nis up to 4.4 times faster than commonly used flow simulation initializations.",
        "authors": [
            "Jaehong Chung",
            "Agnese Marcato",
            "Eric J. Guiltinan",
            "Tapan Mukerji",
            "Hari Viswanathan",
            "Yen Ting Lin",
            "Javier E. Santos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19333v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19333v1",
        "categories": [
            "Geophysics",
            "Computational Physics",
            "Fluid Dynamics"
        ]
    },
    {
        "id": 30000030,
        "doi": null,
        "title": "Utility of virtual qubits in trapped-ion quantum computers",
        "abstract": "We propose encoding multiple qubits inside ions in existing trapped-ion\nquantum computers to access more qubits and to simplify circuits implementing\nstandard algorithms. By using such `virtual' qubits, some inter-ion gates can\nbe replaced by intra-ion gates, reducing the use of vibrational modes of the\nion chain, leading to less noise. We discuss specific examples such as the\nBernstein-Vazirani algorithm and random circuit sampling, using a small number\nof virtual qubits. Additionally, virtual qubits enable using larger number of\ndata qubits for an error correcting code, and we consider the repetition code\nas an example. We also lay out practical considerations to be made when\nchoosing states to encode virtual qubits in $^{137}\\mathrm{Ba}^+$ ions, and for\npreparing states and performing measurements.",
        "chunk-id": 1,
        "chunk": "We propose encoding multiple qubits inside ions in existing trapped-ion\nquantum computers to access more qubits and to simplify circuits implementing\nstandard algorithms. By using such `virtual' qubits, some inter-ion gates can\nbe replaced by intra-ion gates, reducing the use of vibrational modes of the\nion chain, leading to less noise. We discuss specific examples such as the",
        "authors": [
            "Saumya Shivam",
            "Fabian Pokorny",
            "Andres Vazquez-Brennan",
            "Ana S. Sotirova",
            "Jamie D. Leppard",
            "Sophie M. Decoppet",
            "C. J. Ballance",
            "S. L. Sondhi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19332v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19332v1",
        "categories": [
            "Quantum Physics",
            "Atomic Physics"
        ]
    },
    {
        "id": 30000030,
        "doi": null,
        "title": "Utility of virtual qubits in trapped-ion quantum computers",
        "abstract": "We propose encoding multiple qubits inside ions in existing trapped-ion\nquantum computers to access more qubits and to simplify circuits implementing\nstandard algorithms. By using such `virtual' qubits, some inter-ion gates can\nbe replaced by intra-ion gates, reducing the use of vibrational modes of the\nion chain, leading to less noise. We discuss specific examples such as the\nBernstein-Vazirani algorithm and random circuit sampling, using a small number\nof virtual qubits. Additionally, virtual qubits enable using larger number of\ndata qubits for an error correcting code, and we consider the repetition code\nas an example. We also lay out practical considerations to be made when\nchoosing states to encode virtual qubits in $^{137}\\mathrm{Ba}^+$ ions, and for\npreparing states and performing measurements.",
        "chunk-id": 2,
        "chunk": "Bernstein-Vazirani algorithm and random circuit sampling, using a small number\nof virtual qubits. Additionally, virtual qubits enable using larger number of\ndata qubits for an error correcting code, and we consider the repetition code\nas an example. We also lay out practical considerations to be made when",
        "authors": [
            "Saumya Shivam",
            "Fabian Pokorny",
            "Andres Vazquez-Brennan",
            "Ana S. Sotirova",
            "Jamie D. Leppard",
            "Sophie M. Decoppet",
            "C. J. Ballance",
            "S. L. Sondhi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19332v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19332v1",
        "categories": [
            "Quantum Physics",
            "Atomic Physics"
        ]
    },
    {
        "id": 30000030,
        "doi": null,
        "title": "Utility of virtual qubits in trapped-ion quantum computers",
        "abstract": "We propose encoding multiple qubits inside ions in existing trapped-ion\nquantum computers to access more qubits and to simplify circuits implementing\nstandard algorithms. By using such `virtual' qubits, some inter-ion gates can\nbe replaced by intra-ion gates, reducing the use of vibrational modes of the\nion chain, leading to less noise. We discuss specific examples such as the\nBernstein-Vazirani algorithm and random circuit sampling, using a small number\nof virtual qubits. Additionally, virtual qubits enable using larger number of\ndata qubits for an error correcting code, and we consider the repetition code\nas an example. We also lay out practical considerations to be made when\nchoosing states to encode virtual qubits in $^{137}\\mathrm{Ba}^+$ ions, and for\npreparing states and performing measurements.",
        "chunk-id": 3,
        "chunk": "choosing states to encode virtual qubits in $^{137}\\mathrm{Ba}^+$ ions, and for\npreparing states and performing measurements.",
        "authors": [
            "Saumya Shivam",
            "Fabian Pokorny",
            "Andres Vazquez-Brennan",
            "Ana S. Sotirova",
            "Jamie D. Leppard",
            "Sophie M. Decoppet",
            "C. J. Ballance",
            "S. L. Sondhi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:05:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19332v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19332v1",
        "categories": [
            "Quantum Physics",
            "Atomic Physics"
        ]
    },
    {
        "id": 30000031,
        "doi": null,
        "title": "Non-spinning tops are stable",
        "abstract": "We consider coupled gravitational and electromagnetic perturbations of a\nfamily of five-dimensional Einstein-Maxwell solutions that describes both\nmagnetized black strings and horizonless topological stars. We find that the\nodd perturbations of this background lead to a master equation with five\nFuchsian singularities and compute its quasinormal mode spectrum using three\nindependent methods: Leaver, WKB and numerical integration. Our analysis\nconfirms that odd perturbations always decay in time, while spherically\nsymmetric even perturbations may exhibit for certain ranges of the magnetic\nfluxes instabilities of Gregory-Laflamme type for black strings and of\nGross-Perry-Yaffe type for topological stars. This constitutes evidence that\ntopological stars and black strings are classically stable in a finite domain\nof their parameter space.",
        "chunk-id": 1,
        "chunk": "We consider coupled gravitational and electromagnetic perturbations of a\nfamily of five-dimensional Einstein-Maxwell solutions that describes both\nmagnetized black strings and horizonless topological stars. We find that the\nodd perturbations of this background lead to a master equation with five\nFuchsian singularities and compute its quasinormal mode spectrum using three",
        "authors": [
            "Iosif Bena",
            "Giorgio Di Russo",
            "Jose Francisco Morales",
            "Alejandro Ruip\u00e9rez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:01:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19330v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19330v1",
        "categories": [
            "High Energy Physics - Theory"
        ]
    },
    {
        "id": 30000031,
        "doi": null,
        "title": "Non-spinning tops are stable",
        "abstract": "We consider coupled gravitational and electromagnetic perturbations of a\nfamily of five-dimensional Einstein-Maxwell solutions that describes both\nmagnetized black strings and horizonless topological stars. We find that the\nodd perturbations of this background lead to a master equation with five\nFuchsian singularities and compute its quasinormal mode spectrum using three\nindependent methods: Leaver, WKB and numerical integration. Our analysis\nconfirms that odd perturbations always decay in time, while spherically\nsymmetric even perturbations may exhibit for certain ranges of the magnetic\nfluxes instabilities of Gregory-Laflamme type for black strings and of\nGross-Perry-Yaffe type for topological stars. This constitutes evidence that\ntopological stars and black strings are classically stable in a finite domain\nof their parameter space.",
        "chunk-id": 2,
        "chunk": "independent methods: Leaver, WKB and numerical integration. Our analysis\nconfirms that odd perturbations always decay in time, while spherically\nsymmetric even perturbations may exhibit for certain ranges of the magnetic\nfluxes instabilities of Gregory-Laflamme type for black strings and of\nGross-Perry-Yaffe type for topological stars. This constitutes evidence that",
        "authors": [
            "Iosif Bena",
            "Giorgio Di Russo",
            "Jose Francisco Morales",
            "Alejandro Ruip\u00e9rez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:01:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19330v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19330v1",
        "categories": [
            "High Energy Physics - Theory"
        ]
    },
    {
        "id": 30000031,
        "doi": null,
        "title": "Non-spinning tops are stable",
        "abstract": "We consider coupled gravitational and electromagnetic perturbations of a\nfamily of five-dimensional Einstein-Maxwell solutions that describes both\nmagnetized black strings and horizonless topological stars. We find that the\nodd perturbations of this background lead to a master equation with five\nFuchsian singularities and compute its quasinormal mode spectrum using three\nindependent methods: Leaver, WKB and numerical integration. Our analysis\nconfirms that odd perturbations always decay in time, while spherically\nsymmetric even perturbations may exhibit for certain ranges of the magnetic\nfluxes instabilities of Gregory-Laflamme type for black strings and of\nGross-Perry-Yaffe type for topological stars. This constitutes evidence that\ntopological stars and black strings are classically stable in a finite domain\nof their parameter space.",
        "chunk-id": 3,
        "chunk": "topological stars and black strings are classically stable in a finite domain\nof their parameter space.",
        "authors": [
            "Iosif Bena",
            "Giorgio Di Russo",
            "Jose Francisco Morales",
            "Alejandro Ruip\u00e9rez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:01:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19330v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19330v1",
        "categories": [
            "High Energy Physics - Theory"
        ]
    },
    {
        "id": 30000032,
        "doi": null,
        "title": "Multimodal Visual-haptic pose estimation in the presence of transient occlusion",
        "abstract": "Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in\nenvironments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The\ntechnology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot\narm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.",
        "chunk-id": 1,
        "chunk": "Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in",
        "authors": [
            "Michael Zechmair",
            "Yannick Morel"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19323v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19323v1",
        "categories": [
            "Robotics"
        ]
    },
    {
        "id": 30000032,
        "doi": null,
        "title": "Multimodal Visual-haptic pose estimation in the presence of transient occlusion",
        "abstract": "Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in\nenvironments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The\ntechnology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot\narm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.",
        "chunk-id": 2,
        "chunk": "environments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The",
        "authors": [
            "Michael Zechmair",
            "Yannick Morel"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19323v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19323v1",
        "categories": [
            "Robotics"
        ]
    },
    {
        "id": 30000032,
        "doi": null,
        "title": "Multimodal Visual-haptic pose estimation in the presence of transient occlusion",
        "abstract": "Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in\nenvironments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The\ntechnology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot\narm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.",
        "chunk-id": 3,
        "chunk": "technology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot",
        "authors": [
            "Michael Zechmair",
            "Yannick Morel"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19323v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19323v1",
        "categories": [
            "Robotics"
        ]
    },
    {
        "id": 30000032,
        "doi": null,
        "title": "Multimodal Visual-haptic pose estimation in the presence of transient occlusion",
        "abstract": "Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in\nenvironments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The\ntechnology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot\narm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.",
        "chunk-id": 4,
        "chunk": "arm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.",
        "authors": [
            "Michael Zechmair",
            "Yannick Morel"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19323v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19323v1",
        "categories": [
            "Robotics"
        ]
    },
    {
        "id": 30000033,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 1,
        "chunk": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000033,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 2,
        "chunk": "simulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000033,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 3,
        "chunk": "the art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000034,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 1,
        "chunk": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000034,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 2,
        "chunk": "simulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000034,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 3,
        "chunk": "models. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000035,
        "doi": null,
        "title": "Enhanced Data Transfer Cooperating with Artificial Triplets for Scene Graph Generation",
        "abstract": "This work focuses on training dataset enhancement of informative relational\ntriplets for Scene Graph Generation (SGG). Due to the lack of effective\nsupervision, the current SGG model predictions perform poorly for informative\nrelational triplets with inadequate training samples. Therefore, we propose two\nnovel training dataset enhancement modules: Feature Space Triplet Augmentation\n(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to\ngenerate representations of an object in relational triplets. The biased\nprediction based sampling in FSTA efficiently augments artificial triplets\nfocusing on the challenging ones. In addition, we introduce Soft Transfer,\nwhich assigns soft predicate labels to general relational triplets to make more\nsupervisions for informative predicate classes effectively. Experimental\nresults show that integrating FSTA and Soft Transfer achieve high levels of\nboth Recall and mean Recall in Visual Genome dataset. The mean of Recall and\nmean Recall is the highest among all the existing model-agnostic methods.",
        "chunk-id": 1,
        "chunk": "This work focuses on training dataset enhancement of informative relational\ntriplets for Scene Graph Generation (SGG). Due to the lack of effective\nsupervision, the current SGG model predictions perform poorly for informative\nrelational triplets with inadequate training samples. Therefore, we propose two\nnovel training dataset enhancement modules: Feature Space Triplet Augmentation",
        "authors": [
            "KuanChao Chu",
            "Satoshi Yamazaki",
            "Hideki Nakayama"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19316v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000035,
        "doi": null,
        "title": "Enhanced Data Transfer Cooperating with Artificial Triplets for Scene Graph Generation",
        "abstract": "This work focuses on training dataset enhancement of informative relational\ntriplets for Scene Graph Generation (SGG). Due to the lack of effective\nsupervision, the current SGG model predictions perform poorly for informative\nrelational triplets with inadequate training samples. Therefore, we propose two\nnovel training dataset enhancement modules: Feature Space Triplet Augmentation\n(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to\ngenerate representations of an object in relational triplets. The biased\nprediction based sampling in FSTA efficiently augments artificial triplets\nfocusing on the challenging ones. In addition, we introduce Soft Transfer,\nwhich assigns soft predicate labels to general relational triplets to make more\nsupervisions for informative predicate classes effectively. Experimental\nresults show that integrating FSTA and Soft Transfer achieve high levels of\nboth Recall and mean Recall in Visual Genome dataset. The mean of Recall and\nmean Recall is the highest among all the existing model-agnostic methods.",
        "chunk-id": 2,
        "chunk": "(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to\ngenerate representations of an object in relational triplets. The biased\nprediction based sampling in FSTA efficiently augments artificial triplets\nfocusing on the challenging ones. In addition, we introduce Soft Transfer,\nwhich assigns soft predicate labels to general relational triplets to make more",
        "authors": [
            "KuanChao Chu",
            "Satoshi Yamazaki",
            "Hideki Nakayama"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19316v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000035,
        "doi": null,
        "title": "Enhanced Data Transfer Cooperating with Artificial Triplets for Scene Graph Generation",
        "abstract": "This work focuses on training dataset enhancement of informative relational\ntriplets for Scene Graph Generation (SGG). Due to the lack of effective\nsupervision, the current SGG model predictions perform poorly for informative\nrelational triplets with inadequate training samples. Therefore, we propose two\nnovel training dataset enhancement modules: Feature Space Triplet Augmentation\n(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to\ngenerate representations of an object in relational triplets. The biased\nprediction based sampling in FSTA efficiently augments artificial triplets\nfocusing on the challenging ones. In addition, we introduce Soft Transfer,\nwhich assigns soft predicate labels to general relational triplets to make more\nsupervisions for informative predicate classes effectively. Experimental\nresults show that integrating FSTA and Soft Transfer achieve high levels of\nboth Recall and mean Recall in Visual Genome dataset. The mean of Recall and\nmean Recall is the highest among all the existing model-agnostic methods.",
        "chunk-id": 3,
        "chunk": "supervisions for informative predicate classes effectively. Experimental\nresults show that integrating FSTA and Soft Transfer achieve high levels of\nboth Recall and mean Recall in Visual Genome dataset. The mean of Recall and\nmean Recall is the highest among all the existing model-agnostic methods.",
        "authors": [
            "KuanChao Chu",
            "Satoshi Yamazaki",
            "Hideki Nakayama"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19316v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000036,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 1,
        "chunk": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000036,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 2,
        "chunk": "hard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000036,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 3,
        "chunk": "(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000036,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 4,
        "chunk": "Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000036,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 5,
        "chunk": "of tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000037,
        "doi": null,
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based\nadversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation\nwith a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We\nconduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack\nalso achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "chunk-id": 1,
        "chunk": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based",
        "authors": [
            "Zheng Fang",
            "Tao Wang",
            "Lingchen Zhao",
            "Shenyi Zhang",
            "Bowen Li",
            "Yunjie Ge",
            "Qi Li",
            "Chao Shen",
            "Qian Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:39:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19311v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19311v1",
        "categories": [
            "Cryptography and Security",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000037,
        "doi": null,
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based\nadversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation\nwith a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We\nconduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack\nalso achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "chunk-id": 2,
        "chunk": "adversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation",
        "authors": [
            "Zheng Fang",
            "Tao Wang",
            "Lingchen Zhao",
            "Shenyi Zhang",
            "Bowen Li",
            "Yunjie Ge",
            "Qi Li",
            "Chao Shen",
            "Qian Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:39:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19311v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19311v1",
        "categories": [
            "Cryptography and Security",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000037,
        "doi": null,
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based\nadversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation\nwith a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We\nconduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack\nalso achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "chunk-id": 3,
        "chunk": "with a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We",
        "authors": [
            "Zheng Fang",
            "Tao Wang",
            "Lingchen Zhao",
            "Shenyi Zhang",
            "Bowen Li",
            "Yunjie Ge",
            "Qi Li",
            "Chao Shen",
            "Qian Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:39:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19311v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19311v1",
        "categories": [
            "Cryptography and Security",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000037,
        "doi": null,
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based\nadversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation\nwith a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We\nconduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack\nalso achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "chunk-id": 4,
        "chunk": "conduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack",
        "authors": [
            "Zheng Fang",
            "Tao Wang",
            "Lingchen Zhao",
            "Shenyi Zhang",
            "Bowen Li",
            "Yunjie Ge",
            "Qi Li",
            "Chao Shen",
            "Qian Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:39:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19311v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19311v1",
        "categories": [
            "Cryptography and Security",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000037,
        "doi": null,
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability\nof ASR systems, revealing that black-box adversarial example attacks pose\nsignificant threats to real-world ASR systems. However, most existing black-box\nattacks rely on queries to the target ASRs, which is impractical when queries\nare not permitted. In this paper, we propose ZQ-Attack, a transfer-based\nadversarial attack on ASR systems in the zero-query black-box setting. Through\na comprehensive review and categorization of modern ASR technologies, we first\nmeticulously select surrogate ASRs of diverse types to generate adversarial\nexamples. Following this, ZQ-Attack initializes the adversarial perturbation\nwith a scaled target command audio, rendering it relatively imperceptible while\nmaintaining effectiveness. Subsequently, to achieve high transferability of\nadversarial perturbations, we propose a sequential ensemble optimization\nalgorithm, which iteratively optimizes the adversarial perturbation on each\nsurrogate model, leveraging collaborative information from other models. We\nconduct extensive experiments to evaluate ZQ-Attack. In the over-the-line\nsetting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an\naverage signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition\nservices, and attains an average SRoA of 100% and SNR of 19.67dB on 16\nopen-source ASRs. For commercial intelligent voice control devices, ZQ-Attack\nalso achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "chunk-id": 5,
        "chunk": "also achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air\nsetting.",
        "authors": [
            "Zheng Fang",
            "Tao Wang",
            "Lingchen Zhao",
            "Shenyi Zhang",
            "Bowen Li",
            "Yunjie Ge",
            "Qi Li",
            "Chao Shen",
            "Qian Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:39:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19311v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19311v1",
        "categories": [
            "Cryptography and Security",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 30000038,
        "doi": null,
        "title": "The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning",
        "abstract": "Understanding commonsense causality is a unique mark of intelligence for\nhumans. It helps people understand the principles of the real world better and\nbenefits the decision-making process related to causation. For instance,\ncommonsense causality is crucial in judging whether a defendant's action causes\nthe plaintiff's loss in determining legal liability. Despite its significance,\na systematic exploration of this topic is notably lacking. Our comprehensive\nsurvey bridges this gap by focusing on taxonomies, benchmarks, acquisition\nmethods, qualitative reasoning, and quantitative measurements in commonsense\ncausality, synthesizing insights from over 200 representative articles. Our\nwork aims to provide a systematic overview, update scholars on recent\nadvancements, provide a pragmatic guide for beginners, and highlight promising\nfuture research directions in this vital field.",
        "chunk-id": 1,
        "chunk": "Understanding commonsense causality is a unique mark of intelligence for\nhumans. It helps people understand the principles of the real world better and\nbenefits the decision-making process related to causation. For instance,\ncommonsense causality is crucial in judging whether a defendant's action causes\nthe plaintiff's loss in determining legal liability. Despite its significance,",
        "authors": [
            "Shaobo Cui",
            "Zhijing Jin",
            "Bernhard Sch\u00f6lkopf",
            "Boi Faltings"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:30:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000038,
        "doi": null,
        "title": "The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning",
        "abstract": "Understanding commonsense causality is a unique mark of intelligence for\nhumans. It helps people understand the principles of the real world better and\nbenefits the decision-making process related to causation. For instance,\ncommonsense causality is crucial in judging whether a defendant's action causes\nthe plaintiff's loss in determining legal liability. Despite its significance,\na systematic exploration of this topic is notably lacking. Our comprehensive\nsurvey bridges this gap by focusing on taxonomies, benchmarks, acquisition\nmethods, qualitative reasoning, and quantitative measurements in commonsense\ncausality, synthesizing insights from over 200 representative articles. Our\nwork aims to provide a systematic overview, update scholars on recent\nadvancements, provide a pragmatic guide for beginners, and highlight promising\nfuture research directions in this vital field.",
        "chunk-id": 2,
        "chunk": "a systematic exploration of this topic is notably lacking. Our comprehensive\nsurvey bridges this gap by focusing on taxonomies, benchmarks, acquisition\nmethods, qualitative reasoning, and quantitative measurements in commonsense\ncausality, synthesizing insights from over 200 representative articles. Our\nwork aims to provide a systematic overview, update scholars on recent",
        "authors": [
            "Shaobo Cui",
            "Zhijing Jin",
            "Bernhard Sch\u00f6lkopf",
            "Boi Faltings"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:30:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000038,
        "doi": null,
        "title": "The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning",
        "abstract": "Understanding commonsense causality is a unique mark of intelligence for\nhumans. It helps people understand the principles of the real world better and\nbenefits the decision-making process related to causation. For instance,\ncommonsense causality is crucial in judging whether a defendant's action causes\nthe plaintiff's loss in determining legal liability. Despite its significance,\na systematic exploration of this topic is notably lacking. Our comprehensive\nsurvey bridges this gap by focusing on taxonomies, benchmarks, acquisition\nmethods, qualitative reasoning, and quantitative measurements in commonsense\ncausality, synthesizing insights from over 200 representative articles. Our\nwork aims to provide a systematic overview, update scholars on recent\nadvancements, provide a pragmatic guide for beginners, and highlight promising\nfuture research directions in this vital field.",
        "chunk-id": 3,
        "chunk": "advancements, provide a pragmatic guide for beginners, and highlight promising\nfuture research directions in this vital field.",
        "authors": [
            "Shaobo Cui",
            "Zhijing Jin",
            "Bernhard Sch\u00f6lkopf",
            "Boi Faltings"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:30:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 1,
        "chunk": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 2,
        "chunk": "reliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 3,
        "chunk": "identify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 4,
        "chunk": "measurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 5,
        "chunk": "explore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000039,
        "doi": null,
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to\nunderstanding what is censored, and where. Prior censorship work however have\nidentified significant inconsistencies in their results; experiments show\nunexplained non-determinism thought to be caused by censor load, end-host\ngeographic diversity, or incomplete censorship -- inconsistencies which impede\nreliable, repeatable and correct understanding of global censorship. In this\nwork we investigate the extent to which Equal-cost Multi-path (ECMP) routing is\nthe cause for these inconsistencies, developing methods to measure and\ncompensate for them. We find ECMP routing significantly changes observed\ncensorship across protocols, censor mechanisms, and in 17 countries. We\nidentify that previously observed non-determinism or regional variations are\nattributable to measurements between fixed end-hosts taking different routes\nbased on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source\nport leads to differences in observed censorship. To achieve this we develop\nnew route-stable censorship measurement methods that allow consistent\nmeasurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields\ncensorship changes across 42% of IPs and 51% of ASes, but that impact is not\nuniform. We identify numerous causes of the behavior, ranging from likely\nfailed infrastructure, to routes to the same end-host taking geographically\ndiverse paths which experience differences in censorship en-route. Finally, we\nexplore our results in the context of prior global measurement studies,\nexploring first the applicability of our findings to prior observed variations,\nand then demonstrating how specific experiments from two studies could be\nimpacted by, and specific results are explainable by, ECMP routing. Our work\npoints to methods for improving future studies, reducing inconsistencies and\nincreasing repeatability.",
        "chunk-id": 6,
        "chunk": "increasing repeatability.",
        "authors": [
            "Abhishek Bhaskar",
            "Paul Pearce"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:21:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19304v1",
        "categories": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ]
    },
    {
        "id": 30000040,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 1,
        "chunk": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000040,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 2,
        "chunk": "climate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000040,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 3,
        "chunk": "coordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000040,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 4,
        "chunk": "ecosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000041,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 1,
        "chunk": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000041,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 2,
        "chunk": "reducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000041,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 3,
        "chunk": "compression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000041,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 4,
        "chunk": "compression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000042,
        "doi": null,
        "title": "PNeRV: A Polynomial Neural Representation for Videos",
        "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural\nRepresentation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme\nthat ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks\nlike compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.",
        "chunk-id": 1,
        "chunk": "Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural",
        "authors": [
            "Sonam Gupta",
            "Snehal Singh Tomar",
            "Grigorios G Chrysos",
            "Sukhendu Das",
            "A. N. Rajagopalan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:15:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19299v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19299v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000042,
        "doi": null,
        "title": "PNeRV: A Polynomial Neural Representation for Videos",
        "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural\nRepresentation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme\nthat ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks\nlike compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.",
        "chunk-id": 2,
        "chunk": "Representation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme",
        "authors": [
            "Sonam Gupta",
            "Snehal Singh Tomar",
            "Grigorios G Chrysos",
            "Sukhendu Das",
            "A. N. Rajagopalan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:15:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19299v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19299v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000042,
        "doi": null,
        "title": "PNeRV: A Polynomial Neural Representation for Videos",
        "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural\nRepresentation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme\nthat ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks\nlike compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.",
        "chunk-id": 3,
        "chunk": "that ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks",
        "authors": [
            "Sonam Gupta",
            "Snehal Singh Tomar",
            "Grigorios G Chrysos",
            "Sukhendu Das",
            "A. N. Rajagopalan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:15:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19299v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19299v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000042,
        "doi": null,
        "title": "PNeRV: A Polynomial Neural Representation for Videos",
        "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural\nRepresentation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme\nthat ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks\nlike compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.",
        "chunk-id": 4,
        "chunk": "like compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.",
        "authors": [
            "Sonam Gupta",
            "Snehal Singh Tomar",
            "Grigorios G Chrysos",
            "Sukhendu Das",
            "A. N. Rajagopalan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:15:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19299v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19299v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000043,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 1,
        "chunk": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000043,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 2,
        "chunk": "under the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000043,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 3,
        "chunk": "components in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000043,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 4,
        "chunk": "flexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 30000044,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 1,
        "chunk": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000044,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 2,
        "chunk": "demonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000044,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 3,
        "chunk": "approach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000045,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 1,
        "chunk": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000045,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 2,
        "chunk": "Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000045,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 3,
        "chunk": "Turbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000045,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 4,
        "chunk": "highlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 30000046,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 1,
        "chunk": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 30000046,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 2,
        "chunk": "application areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 30000046,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 3,
        "chunk": "algorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 30000047,
        "doi": null,
        "title": "Joint Channel and Data Estimation for Multiuser Extremely Large-Scale MIMO Systems",
        "abstract": "This paper proposes a joint channel and data estimation (JCDE) algorithm for\nuplink multiuser extremely large-scale multiple-input-multiple-output (XL-MIMO)\nsystems. The initial channel estimation is formulated as a sparse\nreconstruction problem based on the angle and distance sparsity under the\nnear-field propagation condition. This problem is solved using non-orthogonal\npilots through an efficient low complexity two-stage compressed sensing\nalgorithm. Furthermore, the initial channel estimates are refined by employing\na JCDE framework driven by both non-orthogonal pilots and estimated data. The\nJCDE problem is solved by sequential expectation propagation (EP) algorithms,\nwhere the channel and data are alternately updated in an iterative manner. In\nthe channel estimation phase, integrating Bayesian inference with a model-based\ndeterministic approach provides precise estimations to effectively exploit the\nnear-field characteristics in the beam-domain. In the data estimation phase, a\nlinear minimum mean square error (LMMSE)-based filter is designed at each\nsub-array to address the correlation due to energy leakage in the beam-domain\narising from the near-field effects. Numerical simulations reveal that the\nproposed initial channel estimation and JCDE algorithm outperforms the\nstate-ofthe-art approaches in terms of channel estimation, data detection, and\ncomputational complexity.",
        "chunk-id": 1,
        "chunk": "This paper proposes a joint channel and data estimation (JCDE) algorithm for\nuplink multiuser extremely large-scale multiple-input-multiple-output (XL-MIMO)\nsystems. The initial channel estimation is formulated as a sparse\nreconstruction problem based on the angle and distance sparsity under the\nnear-field propagation condition. This problem is solved using non-orthogonal",
        "authors": [
            "Kabuto Arai",
            "Koji Ishibashi",
            "Hiroki Iimori",
            "Valente Klaine",
            "Szabolcs Malomsoky"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19289v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19289v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000047,
        "doi": null,
        "title": "Joint Channel and Data Estimation for Multiuser Extremely Large-Scale MIMO Systems",
        "abstract": "This paper proposes a joint channel and data estimation (JCDE) algorithm for\nuplink multiuser extremely large-scale multiple-input-multiple-output (XL-MIMO)\nsystems. The initial channel estimation is formulated as a sparse\nreconstruction problem based on the angle and distance sparsity under the\nnear-field propagation condition. This problem is solved using non-orthogonal\npilots through an efficient low complexity two-stage compressed sensing\nalgorithm. Furthermore, the initial channel estimates are refined by employing\na JCDE framework driven by both non-orthogonal pilots and estimated data. The\nJCDE problem is solved by sequential expectation propagation (EP) algorithms,\nwhere the channel and data are alternately updated in an iterative manner. In\nthe channel estimation phase, integrating Bayesian inference with a model-based\ndeterministic approach provides precise estimations to effectively exploit the\nnear-field characteristics in the beam-domain. In the data estimation phase, a\nlinear minimum mean square error (LMMSE)-based filter is designed at each\nsub-array to address the correlation due to energy leakage in the beam-domain\narising from the near-field effects. Numerical simulations reveal that the\nproposed initial channel estimation and JCDE algorithm outperforms the\nstate-ofthe-art approaches in terms of channel estimation, data detection, and\ncomputational complexity.",
        "chunk-id": 2,
        "chunk": "pilots through an efficient low complexity two-stage compressed sensing\nalgorithm. Furthermore, the initial channel estimates are refined by employing\na JCDE framework driven by both non-orthogonal pilots and estimated data. The\nJCDE problem is solved by sequential expectation propagation (EP) algorithms,\nwhere the channel and data are alternately updated in an iterative manner. In",
        "authors": [
            "Kabuto Arai",
            "Koji Ishibashi",
            "Hiroki Iimori",
            "Valente Klaine",
            "Szabolcs Malomsoky"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19289v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19289v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000047,
        "doi": null,
        "title": "Joint Channel and Data Estimation for Multiuser Extremely Large-Scale MIMO Systems",
        "abstract": "This paper proposes a joint channel and data estimation (JCDE) algorithm for\nuplink multiuser extremely large-scale multiple-input-multiple-output (XL-MIMO)\nsystems. The initial channel estimation is formulated as a sparse\nreconstruction problem based on the angle and distance sparsity under the\nnear-field propagation condition. This problem is solved using non-orthogonal\npilots through an efficient low complexity two-stage compressed sensing\nalgorithm. Furthermore, the initial channel estimates are refined by employing\na JCDE framework driven by both non-orthogonal pilots and estimated data. The\nJCDE problem is solved by sequential expectation propagation (EP) algorithms,\nwhere the channel and data are alternately updated in an iterative manner. In\nthe channel estimation phase, integrating Bayesian inference with a model-based\ndeterministic approach provides precise estimations to effectively exploit the\nnear-field characteristics in the beam-domain. In the data estimation phase, a\nlinear minimum mean square error (LMMSE)-based filter is designed at each\nsub-array to address the correlation due to energy leakage in the beam-domain\narising from the near-field effects. Numerical simulations reveal that the\nproposed initial channel estimation and JCDE algorithm outperforms the\nstate-ofthe-art approaches in terms of channel estimation, data detection, and\ncomputational complexity.",
        "chunk-id": 3,
        "chunk": "the channel estimation phase, integrating Bayesian inference with a model-based\ndeterministic approach provides precise estimations to effectively exploit the\nnear-field characteristics in the beam-domain. In the data estimation phase, a\nlinear minimum mean square error (LMMSE)-based filter is designed at each",
        "authors": [
            "Kabuto Arai",
            "Koji Ishibashi",
            "Hiroki Iimori",
            "Valente Klaine",
            "Szabolcs Malomsoky"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19289v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19289v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000047,
        "doi": null,
        "title": "Joint Channel and Data Estimation for Multiuser Extremely Large-Scale MIMO Systems",
        "abstract": "This paper proposes a joint channel and data estimation (JCDE) algorithm for\nuplink multiuser extremely large-scale multiple-input-multiple-output (XL-MIMO)\nsystems. The initial channel estimation is formulated as a sparse\nreconstruction problem based on the angle and distance sparsity under the\nnear-field propagation condition. This problem is solved using non-orthogonal\npilots through an efficient low complexity two-stage compressed sensing\nalgorithm. Furthermore, the initial channel estimates are refined by employing\na JCDE framework driven by both non-orthogonal pilots and estimated data. The\nJCDE problem is solved by sequential expectation propagation (EP) algorithms,\nwhere the channel and data are alternately updated in an iterative manner. In\nthe channel estimation phase, integrating Bayesian inference with a model-based\ndeterministic approach provides precise estimations to effectively exploit the\nnear-field characteristics in the beam-domain. In the data estimation phase, a\nlinear minimum mean square error (LMMSE)-based filter is designed at each\nsub-array to address the correlation due to energy leakage in the beam-domain\narising from the near-field effects. Numerical simulations reveal that the\nproposed initial channel estimation and JCDE algorithm outperforms the\nstate-ofthe-art approaches in terms of channel estimation, data detection, and\ncomputational complexity.",
        "chunk-id": 4,
        "chunk": "sub-array to address the correlation due to energy leakage in the beam-domain\narising from the near-field effects. Numerical simulations reveal that the\nproposed initial channel estimation and JCDE algorithm outperforms the\nstate-ofthe-art approaches in terms of channel estimation, data detection, and\ncomputational complexity.",
        "authors": [
            "Kabuto Arai",
            "Koji Ishibashi",
            "Hiroki Iimori",
            "Valente Klaine",
            "Szabolcs Malomsoky"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19289v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19289v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000048,
        "doi": null,
        "title": "Task-splitting in home healthcare routing and scheduling",
        "abstract": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts\nmay have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.\nThese formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement\nheuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and\nallows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "chunk-id": 1,
        "chunk": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts",
        "authors": [
            "Loek van Montfort",
            "Wout Dullaert",
            "Markus Leitner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:03:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19288v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19288v1",
        "categories": [
            "Optimization and Control"
        ]
    },
    {
        "id": 30000048,
        "doi": null,
        "title": "Task-splitting in home healthcare routing and scheduling",
        "abstract": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts\nmay have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.\nThese formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement\nheuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and\nallows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "chunk-id": 2,
        "chunk": "may have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.",
        "authors": [
            "Loek van Montfort",
            "Wout Dullaert",
            "Markus Leitner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:03:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19288v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19288v1",
        "categories": [
            "Optimization and Control"
        ]
    },
    {
        "id": 30000048,
        "doi": null,
        "title": "Task-splitting in home healthcare routing and scheduling",
        "abstract": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts\nmay have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.\nThese formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement\nheuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and\nallows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "chunk-id": 3,
        "chunk": "These formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement",
        "authors": [
            "Loek van Montfort",
            "Wout Dullaert",
            "Markus Leitner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:03:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19288v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19288v1",
        "categories": [
            "Optimization and Control"
        ]
    },
    {
        "id": 30000048,
        "doi": null,
        "title": "Task-splitting in home healthcare routing and scheduling",
        "abstract": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts\nmay have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.\nThese formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement\nheuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and\nallows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "chunk-id": 4,
        "chunk": "heuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and",
        "authors": [
            "Loek van Montfort",
            "Wout Dullaert",
            "Markus Leitner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:03:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19288v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19288v1",
        "categories": [
            "Optimization and Control"
        ]
    },
    {
        "id": 30000048,
        "doi": null,
        "title": "Task-splitting in home healthcare routing and scheduling",
        "abstract": "This paper introduces the concept of task-splitting into home healthcare\n(HHC) routing and scheduling. It focuses on the design of routes and timetables\nfor caregivers providing services at patients' homes. Task-splitting is the\ndivision of a (lengthy) patient visit into separate visits that can be\nperformed by different caregivers at different times. The resulting split parts\nmay have reduced caregiver qualification requirements, relaxed visiting time\nwindows, or a shorter/longer combined duration. However, additional temporal\ndependencies can arise between them. To incorporate task-splitting decisions\ninto the planning process, we introduce two different mixed integer linear\nprogramming formulations, a Miller-Tucker-Zemlin and a time-indexed variant.\nThese formulations aim to minimize operational costs while simultaneously\ndeciding which visits to split and imposing a potentially wide range of\ntemporal dependencies. We also propose pre-processing routines for the\ntime-indexed formulation and two heuristic procedures. These methods are\nembedded into the branch-and-bound approach as primal and improvement\nheuristics. The results of our computational study demonstrate the additional\ncomputational difficulty introduced by task-splitting and the associated\nadditional synchronization, and the usefulness of the proposed heuristic\nprocedures. From a planning perspective, our results indicate that introducing\ntask-splitting reduces staff requirements, decreases HHC operational costs, and\nallows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "chunk-id": 5,
        "chunk": "allows caregivers to spend relatively more time on tasks aligned with their\nqualifications. Moreover, we observe that the potential of task-splitting is\nnot specific to the chosen planning objective; it can also be beneficial when\nminimizing travel time instead.",
        "authors": [
            "Loek van Montfort",
            "Wout Dullaert",
            "Markus Leitner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:03:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19288v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19288v1",
        "categories": [
            "Optimization and Control"
        ]
    },
    {
        "id": 30000049,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 1,
        "chunk": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 30000049,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 2,
        "chunk": "PubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 30000049,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 3,
        "chunk": "creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 30000049,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 4,
        "chunk": "data quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 30000050,
        "doi": null,
        "title": "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation",
        "abstract": "Existing metrics for evaluating the factuality of long-form text, such as\nFACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input\ntext into \"atomic claims\" and verify each against a knowledge base like\nWikipedia. These metrics are not suitable for most generation tasks because\nthey assume that every claim is verifiable (i.e., can plausibly be proven true\nor false). We address this issue with VERISCORE, a metric for diverse long-form\ngeneration tasks that contain both verifiable and unverifiable content.\nVERISCORE can be effectively implemented with either closed or fine-tuned\nopen-weight language models, and human evaluation confirms that VERISCORE's\nextracted claims are more sensible than those from competing methods across\neight different long-form tasks. We use VERISCORE to evaluate generations from\n16 different models across multiple long-form tasks and find that while GPT-4o\nis the best-performing model overall, open-weight models such as Mixtral-8x22\nare closing the gap. We show that an LM's VERISCORE on one task (e.g.,\nbiography generation) does not necessarily correlate to its VERISCORE on a\ndifferent task (e.g., long-form QA), highlighting the need for expanding\nfactuality evaluation across tasks with varying fact density.",
        "chunk-id": 1,
        "chunk": "Existing metrics for evaluating the factuality of long-form text, such as\nFACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input\ntext into \"atomic claims\" and verify each against a knowledge base like\nWikipedia. These metrics are not suitable for most generation tasks because\nthey assume that every claim is verifiable (i.e., can plausibly be proven true",
        "authors": [
            "Yixiao Song",
            "Yekyung Kim",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:43:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19276v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19276v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000050,
        "doi": null,
        "title": "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation",
        "abstract": "Existing metrics for evaluating the factuality of long-form text, such as\nFACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input\ntext into \"atomic claims\" and verify each against a knowledge base like\nWikipedia. These metrics are not suitable for most generation tasks because\nthey assume that every claim is verifiable (i.e., can plausibly be proven true\nor false). We address this issue with VERISCORE, a metric for diverse long-form\ngeneration tasks that contain both verifiable and unverifiable content.\nVERISCORE can be effectively implemented with either closed or fine-tuned\nopen-weight language models, and human evaluation confirms that VERISCORE's\nextracted claims are more sensible than those from competing methods across\neight different long-form tasks. We use VERISCORE to evaluate generations from\n16 different models across multiple long-form tasks and find that while GPT-4o\nis the best-performing model overall, open-weight models such as Mixtral-8x22\nare closing the gap. We show that an LM's VERISCORE on one task (e.g.,\nbiography generation) does not necessarily correlate to its VERISCORE on a\ndifferent task (e.g., long-form QA), highlighting the need for expanding\nfactuality evaluation across tasks with varying fact density.",
        "chunk-id": 2,
        "chunk": "or false). We address this issue with VERISCORE, a metric for diverse long-form\ngeneration tasks that contain both verifiable and unverifiable content.\nVERISCORE can be effectively implemented with either closed or fine-tuned\nopen-weight language models, and human evaluation confirms that VERISCORE's\nextracted claims are more sensible than those from competing methods across",
        "authors": [
            "Yixiao Song",
            "Yekyung Kim",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:43:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19276v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19276v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000050,
        "doi": null,
        "title": "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation",
        "abstract": "Existing metrics for evaluating the factuality of long-form text, such as\nFACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input\ntext into \"atomic claims\" and verify each against a knowledge base like\nWikipedia. These metrics are not suitable for most generation tasks because\nthey assume that every claim is verifiable (i.e., can plausibly be proven true\nor false). We address this issue with VERISCORE, a metric for diverse long-form\ngeneration tasks that contain both verifiable and unverifiable content.\nVERISCORE can be effectively implemented with either closed or fine-tuned\nopen-weight language models, and human evaluation confirms that VERISCORE's\nextracted claims are more sensible than those from competing methods across\neight different long-form tasks. We use VERISCORE to evaluate generations from\n16 different models across multiple long-form tasks and find that while GPT-4o\nis the best-performing model overall, open-weight models such as Mixtral-8x22\nare closing the gap. We show that an LM's VERISCORE on one task (e.g.,\nbiography generation) does not necessarily correlate to its VERISCORE on a\ndifferent task (e.g., long-form QA), highlighting the need for expanding\nfactuality evaluation across tasks with varying fact density.",
        "chunk-id": 3,
        "chunk": "eight different long-form tasks. We use VERISCORE to evaluate generations from\n16 different models across multiple long-form tasks and find that while GPT-4o\nis the best-performing model overall, open-weight models such as Mixtral-8x22\nare closing the gap. We show that an LM's VERISCORE on one task (e.g.,\nbiography generation) does not necessarily correlate to its VERISCORE on a",
        "authors": [
            "Yixiao Song",
            "Yekyung Kim",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:43:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19276v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19276v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000050,
        "doi": null,
        "title": "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation",
        "abstract": "Existing metrics for evaluating the factuality of long-form text, such as\nFACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input\ntext into \"atomic claims\" and verify each against a knowledge base like\nWikipedia. These metrics are not suitable for most generation tasks because\nthey assume that every claim is verifiable (i.e., can plausibly be proven true\nor false). We address this issue with VERISCORE, a metric for diverse long-form\ngeneration tasks that contain both verifiable and unverifiable content.\nVERISCORE can be effectively implemented with either closed or fine-tuned\nopen-weight language models, and human evaluation confirms that VERISCORE's\nextracted claims are more sensible than those from competing methods across\neight different long-form tasks. We use VERISCORE to evaluate generations from\n16 different models across multiple long-form tasks and find that while GPT-4o\nis the best-performing model overall, open-weight models such as Mixtral-8x22\nare closing the gap. We show that an LM's VERISCORE on one task (e.g.,\nbiography generation) does not necessarily correlate to its VERISCORE on a\ndifferent task (e.g., long-form QA), highlighting the need for expanding\nfactuality evaluation across tasks with varying fact density.",
        "chunk-id": 4,
        "chunk": "different task (e.g., long-form QA), highlighting the need for expanding\nfactuality evaluation across tasks with varying fact density.",
        "authors": [
            "Yixiao Song",
            "Yekyung Kim",
            "Mohit Iyyer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:43:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19276v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19276v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000051,
        "doi": null,
        "title": "Insights into the Structured Coordination Game with Neutral Options through Simulation",
        "abstract": "Coordination games have been of interest to game theorists, economists, and\necologists for many years to study such problems as the emergence of local\nconventions and the evolution of cooperative behavior. Approaches for\nunderstanding the coordination game with discrete structure have been limited\nin scope, often relying on symmetric reduction of the state space, or other\nconstraints which limit the power of the model to give insight into desired\napplications. In this paper, we introduce a new way of thinking about\nequilibria of the structured coordination game with neutral strategies by means\nof graph partitioning. We begin with a few elementary game theoretical results\nand then catalogue all the Nash equilibria of the coordination game with\nneutral options for graphs with seven or fewer vertices. We extend our\nobservations through the use of simulation on larger Erd\\H{o}s-R\\'enyi random\ngraphs to form the basis for proposing some conjectures about the general\nrelationships among edge density, cluster number, and consensus stability.",
        "chunk-id": 1,
        "chunk": "Coordination games have been of interest to game theorists, economists, and\necologists for many years to study such problems as the emergence of local\nconventions and the evolution of cooperative behavior. Approaches for\nunderstanding the coordination game with discrete structure have been limited\nin scope, often relying on symmetric reduction of the state space, or other",
        "authors": [
            "John S. McAlister",
            "Nina H. Fefferman"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:39:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19273v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19273v1",
        "categories": [
            "Computer Science and Game Theory",
            "Dynamical Systems",
            "Dynamic games, Games involving graphs "
        ]
    },
    {
        "id": 30000051,
        "doi": null,
        "title": "Insights into the Structured Coordination Game with Neutral Options through Simulation",
        "abstract": "Coordination games have been of interest to game theorists, economists, and\necologists for many years to study such problems as the emergence of local\nconventions and the evolution of cooperative behavior. Approaches for\nunderstanding the coordination game with discrete structure have been limited\nin scope, often relying on symmetric reduction of the state space, or other\nconstraints which limit the power of the model to give insight into desired\napplications. In this paper, we introduce a new way of thinking about\nequilibria of the structured coordination game with neutral strategies by means\nof graph partitioning. We begin with a few elementary game theoretical results\nand then catalogue all the Nash equilibria of the coordination game with\nneutral options for graphs with seven or fewer vertices. We extend our\nobservations through the use of simulation on larger Erd\\H{o}s-R\\'enyi random\ngraphs to form the basis for proposing some conjectures about the general\nrelationships among edge density, cluster number, and consensus stability.",
        "chunk-id": 2,
        "chunk": "constraints which limit the power of the model to give insight into desired\napplications. In this paper, we introduce a new way of thinking about\nequilibria of the structured coordination game with neutral strategies by means\nof graph partitioning. We begin with a few elementary game theoretical results\nand then catalogue all the Nash equilibria of the coordination game with",
        "authors": [
            "John S. McAlister",
            "Nina H. Fefferman"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:39:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19273v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19273v1",
        "categories": [
            "Computer Science and Game Theory",
            "Dynamical Systems",
            "Dynamic games, Games involving graphs "
        ]
    },
    {
        "id": 30000051,
        "doi": null,
        "title": "Insights into the Structured Coordination Game with Neutral Options through Simulation",
        "abstract": "Coordination games have been of interest to game theorists, economists, and\necologists for many years to study such problems as the emergence of local\nconventions and the evolution of cooperative behavior. Approaches for\nunderstanding the coordination game with discrete structure have been limited\nin scope, often relying on symmetric reduction of the state space, or other\nconstraints which limit the power of the model to give insight into desired\napplications. In this paper, we introduce a new way of thinking about\nequilibria of the structured coordination game with neutral strategies by means\nof graph partitioning. We begin with a few elementary game theoretical results\nand then catalogue all the Nash equilibria of the coordination game with\nneutral options for graphs with seven or fewer vertices. We extend our\nobservations through the use of simulation on larger Erd\\H{o}s-R\\'enyi random\ngraphs to form the basis for proposing some conjectures about the general\nrelationships among edge density, cluster number, and consensus stability.",
        "chunk-id": 3,
        "chunk": "neutral options for graphs with seven or fewer vertices. We extend our\nobservations through the use of simulation on larger Erd\\H{o}s-R\\'enyi random\ngraphs to form the basis for proposing some conjectures about the general\nrelationships among edge density, cluster number, and consensus stability.",
        "authors": [
            "John S. McAlister",
            "Nina H. Fefferman"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:39:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19273v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19273v1",
        "categories": [
            "Computer Science and Game Theory",
            "Dynamical Systems",
            "Dynamic games, Games involving graphs "
        ]
    },
    {
        "id": 30000052,
        "doi": null,
        "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
        "abstract": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought\nafter. Typically, LLMs are trained on a fixed dataset and then deployed.\nHowever, the training data continually becomes outdated. Enable automatic\ntraining of AI using web data involves significant concerns regarding data\nquality and safety due to bias, spam, and other unsafe or unwanted text. Pure\ndata is essential for producing reliable models. Training a model on impure\ndata may result in undesirable outcomes. This research proposes a system that\ncollects web data and automatically filters out unwanted text with the\nassistance of existing trusted AI models. In the experiment, a small sample of\nweb data was collected and filtered, demonstrating the system's effectiveness\nin purifying the data.",
        "chunk-id": 1,
        "chunk": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought\nafter. Typically, LLMs are trained on a fixed dataset and then deployed.\nHowever, the training data continually becomes outdated. Enable automatic\ntraining of AI using web data involves significant concerns regarding data\nquality and safety due to bias, spam, and other unsafe or unwanted text. Pure",
        "authors": [
            "Praneeth Vadlapati"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000052,
        "doi": null,
        "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
        "abstract": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought\nafter. Typically, LLMs are trained on a fixed dataset and then deployed.\nHowever, the training data continually becomes outdated. Enable automatic\ntraining of AI using web data involves significant concerns regarding data\nquality and safety due to bias, spam, and other unsafe or unwanted text. Pure\ndata is essential for producing reliable models. Training a model on impure\ndata may result in undesirable outcomes. This research proposes a system that\ncollects web data and automatically filters out unwanted text with the\nassistance of existing trusted AI models. In the experiment, a small sample of\nweb data was collected and filtered, demonstrating the system's effectiveness\nin purifying the data.",
        "chunk-id": 2,
        "chunk": "data is essential for producing reliable models. Training a model on impure\ndata may result in undesirable outcomes. This research proposes a system that\ncollects web data and automatically filters out unwanted text with the\nassistance of existing trusted AI models. In the experiment, a small sample of\nweb data was collected and filtered, demonstrating the system's effectiveness",
        "authors": [
            "Praneeth Vadlapati"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000052,
        "doi": null,
        "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
        "abstract": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought\nafter. Typically, LLMs are trained on a fixed dataset and then deployed.\nHowever, the training data continually becomes outdated. Enable automatic\ntraining of AI using web data involves significant concerns regarding data\nquality and safety due to bias, spam, and other unsafe or unwanted text. Pure\ndata is essential for producing reliable models. Training a model on impure\ndata may result in undesirable outcomes. This research proposes a system that\ncollects web data and automatically filters out unwanted text with the\nassistance of existing trusted AI models. In the experiment, a small sample of\nweb data was collected and filtered, demonstrating the system's effectiveness\nin purifying the data.",
        "chunk-id": 3,
        "chunk": "in purifying the data.",
        "authors": [
            "Praneeth Vadlapati"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 1,
        "chunk": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 2,
        "chunk": "vehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 3,
        "chunk": "weights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 4,
        "chunk": "signalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 5,
        "chunk": "stable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000053,
        "doi": null,
        "title": "OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles",
        "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach\nthat has been shown to maximize throughput for private vehicles. However,\nMP-based signal control algorithms do not differentiate the movement of transit\nvehicles from private vehicles or between high and single-occupancy private\nvehicles. Prioritizing the movement of transit or other high occupancy vehicles\n(HOVs) is vital to reduce congestion and improve the reliability and efficiency\nof transit operations. This study proposes OCC-MP: a novel MP-based algorithm\nthat considers both vehicle queues and passenger occupancies in computing the\nweights of movements. By weighing movements with higher passenger occupancies\nmore heavily, transit and other HOVs are implicitly provided with priority,\nwhile accounting for any negative impacts of that priority on single occupancy\nvehicles. And, unlike rule-based transit signal priority (TSP) strategies,\nOCC-MP more naturally also accommodates conflicting transit routes at a\nsignalized intersection and facilitates their movement, even in mixed traffic\nwithout dedicated lanes. Simulations on a grid network under varying demands\nand transit configurations demonstrate the effectiveness of OCC-MP at providing\nTSP while simultaneously reducing the negative impact imparted onto lower\noccupancy private vehicles. Furthermore, OCC-MP is shown to have a larger\nstable region for demand compared to rule-based TSP strategies integrated into\nthe MP framework. The performance of OCC-MP is also shown to be robust to\nerrors in passenger occupancy information from transit vehicles and can be\napplied when passenger occupancies of private vehicles are not available.\nFinally, OCC-MP can be applied in a partially connected vehicle (CV)\nenvironment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "chunk-id": 6,
        "chunk": "environment when a subset of vehicles is able to provide information to the\nsignal controller, outperforming baseline methods at low CV penetration rates.",
        "authors": [
            "Tanveer Ahmed",
            "Hao Liu",
            "Vikash V. Gayah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:36:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19269v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19269v1",
        "categories": [
            "Systems and Control",
            "Systems and Control"
        ]
    },
    {
        "id": 30000054,
        "doi": null,
        "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
        "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io",
        "chunk-id": 1,
        "chunk": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we",
        "authors": [
            "Yue Fan",
            "Lei Ding",
            "Ching-Chen Kuo",
            "Shan Jiang",
            "Yang Zhao",
            "Xinze Guan",
            "Jie Yang",
            "Yi Zhang",
            "Xin Eric Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:34:16+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19263v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19263v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000054,
        "doi": null,
        "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
        "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io",
        "chunk-id": 2,
        "chunk": "name the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the",
        "authors": [
            "Yue Fan",
            "Lei Ding",
            "Ching-Chen Kuo",
            "Shan Jiang",
            "Yang Zhao",
            "Xinze Guan",
            "Jie Yang",
            "Yi Zhang",
            "Xin Eric Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:34:16+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19263v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19263v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000054,
        "doi": null,
        "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
        "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io",
        "chunk-id": 3,
        "chunk": "corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other",
        "authors": [
            "Yue Fan",
            "Lei Ding",
            "Ching-Chen Kuo",
            "Shan Jiang",
            "Yang Zhao",
            "Xinze Guan",
            "Jie Yang",
            "Yi Zhang",
            "Xin Eric Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:34:16+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19263v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19263v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000054,
        "doi": null,
        "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
        "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io",
        "chunk-id": 4,
        "chunk": "screen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:",
        "authors": [
            "Yue Fan",
            "Lei Ding",
            "Ching-Chen Kuo",
            "Shan Jiang",
            "Yang Zhao",
            "Xinze Guan",
            "Jie Yang",
            "Yi Zhang",
            "Xin Eric Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:34:16+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19263v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19263v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000054,
        "doi": null,
        "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
        "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io",
        "chunk-id": 5,
        "chunk": "screen-point-and-read.github.io",
        "authors": [
            "Yue Fan",
            "Lei Ding",
            "Ching-Chen Kuo",
            "Shan Jiang",
            "Yang Zhao",
            "Xinze Guan",
            "Jie Yang",
            "Yi Zhang",
            "Xin Eric Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:34:16+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19263v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19263v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000055,
        "doi": null,
        "title": "Commodification of Compute",
        "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
        "chunk-id": 1,
        "chunk": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and",
        "authors": [
            "Jesper Kristensen",
            "David Wender",
            "Carl Anthony"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:32:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19261v1",
        "categories": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence",
            "Computers and Society",
            "Emerging Technologies",
            "General Economics",
            "Economics"
        ]
    },
    {
        "id": 30000055,
        "doi": null,
        "title": "Commodification of Compute",
        "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
        "chunk-id": 2,
        "chunk": "price volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a",
        "authors": [
            "Jesper Kristensen",
            "David Wender",
            "Carl Anthony"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:32:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19261v1",
        "categories": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence",
            "Computers and Society",
            "Emerging Technologies",
            "General Economics",
            "Economics"
        ]
    },
    {
        "id": 30000055,
        "doi": null,
        "title": "Commodification of Compute",
        "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
        "chunk-id": 3,
        "chunk": "layered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates",
        "authors": [
            "Jesper Kristensen",
            "David Wender",
            "Carl Anthony"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:32:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19261v1",
        "categories": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence",
            "Computers and Society",
            "Emerging Technologies",
            "General Economics",
            "Economics"
        ]
    },
    {
        "id": 30000055,
        "doi": null,
        "title": "Commodification of Compute",
        "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
        "chunk-id": 4,
        "chunk": "innovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering",
        "authors": [
            "Jesper Kristensen",
            "David Wender",
            "Carl Anthony"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:32:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19261v1",
        "categories": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence",
            "Computers and Society",
            "Emerging Technologies",
            "General Economics",
            "Economics"
        ]
    },
    {
        "id": 30000055,
        "doi": null,
        "title": "Commodification of Compute",
        "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
        "chunk-id": 5,
        "chunk": "solution poised to drive the next wave of innovation in commodities and\ncompute.",
        "authors": [
            "Jesper Kristensen",
            "David Wender",
            "Carl Anthony"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:32:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19261v1",
        "categories": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence",
            "Computers and Society",
            "Emerging Technologies",
            "General Economics",
            "Economics"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 1,
        "chunk": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 2,
        "chunk": "geometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 3,
        "chunk": "directions:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 4,
        "chunk": "ratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 5,
        "chunk": "classical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000056,
        "doi": null,
        "title": "Online sorting and online TSP: randomized, stochastic, and high-dimensional",
        "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to\nbe placed (immediately and irrevocably) into empty cells of a size-$n$ array.\nThe goal is to minimize the sum of absolute differences between items in\nconsecutive cells. This natural problem was recently introduced by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online\ngeometric packing problems. They showed that when the items are reals from the\ninterval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no\ndeterministic algorithm can improve this ratio asymptotically.\n  In this paper, we extend and generalize the study of online sorting in three\ndirections:\n  - randomized: we settle the open question of Aamand et al. by showing that\nthe $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be\nimproved even with the use of randomness;\n  - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at\nrandom from an interval, and give an algorithm with an improved competitive\nratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between\nonline sorting and the design of efficient hash tables;\n  - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online\nsorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed\n$d$, in an adversarial model. This can be viewed as an online variant of the\nclassical TSP problem where tasks (cities to visit) are revealed one by one and\nthe salesperson assigns each task (immediately and irrevocably) to its\ntimeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness\nresult for uniform metrics, i.e., where items are of different types and the\ngoal is to order them so as to minimize the number of switches between\nconsecutive items of different types.",
        "chunk-id": 6,
        "chunk": "consecutive items of different types.",
        "authors": [
            "Mikkel Abrahamsen",
            "Ioana O. Bercea",
            "Lorenzo Beretta",
            "Jonas Klausen",
            "L\u00e1szl\u00f3 Kozma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19257v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19257v1",
        "categories": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ]
    },
    {
        "id": 30000057,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 1,
        "chunk": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000057,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 2,
        "chunk": "frameworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000057,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 3,
        "chunk": "data quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000057,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 4,
        "chunk": "Reusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000058,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 1,
        "chunk": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 30000058,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 2,
        "chunk": "structural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 30000058,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 3,
        "chunk": "SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 30000058,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 4,
        "chunk": "spatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 30000058,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 5,
        "chunk": "On 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 30000059,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 1,
        "chunk": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000059,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 2,
        "chunk": "multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000059,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 3,
        "chunk": "optimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000059,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 4,
        "chunk": "scenarios. The code will be made available at https://aka.ms/autorag.",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000060,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 1,
        "chunk": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000060,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 2,
        "chunk": "methods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000060,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 3,
        "chunk": "Image Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000060,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 4,
        "chunk": "inter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000060,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 5,
        "chunk": "state-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000061,
        "doi": null,
        "title": "An Interpretable and Efficient Sleep Staging Algorithm: DetectsleepNet",
        "abstract": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep\nspecialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior\nknowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an\nefficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of\nmodels. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "chunk-id": 1,
        "chunk": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep",
        "authors": [
            "Shengwei Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:13:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19246v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19246v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000061,
        "doi": null,
        "title": "An Interpretable and Efficient Sleep Staging Algorithm: DetectsleepNet",
        "abstract": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep\nspecialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior\nknowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an\nefficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of\nmodels. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "chunk-id": 2,
        "chunk": "specialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior",
        "authors": [
            "Shengwei Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:13:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19246v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19246v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000061,
        "doi": null,
        "title": "An Interpretable and Efficient Sleep Staging Algorithm: DetectsleepNet",
        "abstract": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep\nspecialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior\nknowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an\nefficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of\nmodels. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "chunk-id": 3,
        "chunk": "knowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an",
        "authors": [
            "Shengwei Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:13:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19246v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19246v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000061,
        "doi": null,
        "title": "An Interpretable and Efficient Sleep Staging Algorithm: DetectsleepNet",
        "abstract": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep\nspecialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior\nknowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an\nefficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of\nmodels. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "chunk-id": 4,
        "chunk": "efficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of",
        "authors": [
            "Shengwei Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:13:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19246v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19246v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000061,
        "doi": null,
        "title": "An Interpretable and Efficient Sleep Staging Algorithm: DetectsleepNet",
        "abstract": "Sleep quality directly impacts human health and quality of life, so accurate\nsleep staging is essential for assessing sleep quality. However, most\ntraditional methods are inefficient and time-consuming due to segmenting\ndifferent sleep cycles by manual labeling. In contrast, automated sleep staging\ntechnology not only directly assesses sleep quality but also helps sleep\nspecialists analyze sleep status, significantly improving efficiency and\nreducing the cost of sleep monitoring, especially for continuous sleep\nmonitoring. Most of the existing models, however, are deficient in\ncomputational efficiency, lightweight design, and model interpretability. In\nthis paper, we propose a neural network architecture based on the prior\nknowledge of sleep experts. Specifically, 1) Propose an end-to-end model named\nDetectsleepNet that uses single-channel EEG signals without additional data\nprocessing, which has achieved an impressive 80.9% accuracy on the SHHS dataset\nand an outstanding 88.0% accuracy on the Physio2018 dataset. 2) Constructure an\nefficient lightweight sleep staging model named DetectsleepNet-tiny based on\nDetectsleepNet, which has just 6% of the parameter numbers of existing models,\nbut its accuracy exceeds 99% of state-of-the-art models, 3) Introducing a\nspecific inference header to assess the attention given to a specific EEG\nsegment in each sleep frame, enhancing the transparency in the decisions of\nmodels. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "chunk-id": 5,
        "chunk": "models. Our model comprises fewer parameters compared to existing ones and\nulteriorly explores the interpretability of the model to facilitate its\napplication in healthcare. The code is available at\nhttps://github.com/komdec/DetectSleepNet.git.",
        "authors": [
            "Shengwei Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:13:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19246v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19246v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 30000062,
        "doi": null,
        "title": "Stiefel-Whitney Classes for Finite Special Linear Groups of Even Rank",
        "abstract": "We compute the total Stiefel-Whitney Classes (SWCs) for orthogonal\nrepresentations of special linear groups $\\text{SL}(n,q)$ when $n$ and $q$ are\nodd. These classes are expressed in terms of character values at diagonal\nelements of order $2$. We give several consequences, and work out the $4$th SWC\nexplicitly, and the $8$th SWC when the $4$th vanishes.",
        "chunk-id": 1,
        "chunk": "We compute the total Stiefel-Whitney Classes (SWCs) for orthogonal\nrepresentations of special linear groups $\\text{SL}(n,q)$ when $n$ and $q$ are\nodd. These classes are expressed in terms of character values at diagonal\nelements of order $2$. We give several consequences, and work out the $4$th SWC\nexplicitly, and the $8$th SWC when the $4$th vanishes.",
        "authors": [
            "Neha Malik",
            "Steven Spallone"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:06:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19241v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19241v1",
        "categories": [
            "Representation Theory",
            "Linear algebraic groups over finite fields, Homology of classifying spaces and characteristic classes in algebraic topology"
        ]
    },
    {
        "id": 30000063,
        "doi": null,
        "title": "ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI",
        "abstract": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "chunk-id": 1,
        "chunk": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized",
        "authors": [
            "Gianluca Giacchi",
            "Isidoros Iakovidis",
            "Bastien Milani",
            "Matthias Stuber",
            "Micah Murray",
            "Benedetta Franceschiello"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:02:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19239v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Medical Physics",
            "Biomedical imaging and signal processing, Ridge regression; shrinkage estimators (Lasso), Numerical optimization and variational techniques",
            "Compression (Coding),Reconstruction,PHYSICAL SCIENCES AND ENGINEERING"
        ]
    },
    {
        "id": 30000063,
        "doi": null,
        "title": "ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI",
        "abstract": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "chunk-id": 2,
        "chunk": "LASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques",
        "authors": [
            "Gianluca Giacchi",
            "Isidoros Iakovidis",
            "Bastien Milani",
            "Matthias Stuber",
            "Micah Murray",
            "Benedetta Franceschiello"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:02:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19239v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Medical Physics",
            "Biomedical imaging and signal processing, Ridge regression; shrinkage estimators (Lasso), Numerical optimization and variational techniques",
            "Compression (Coding),Reconstruction,PHYSICAL SCIENCES AND ENGINEERING"
        ]
    },
    {
        "id": 30000063,
        "doi": null,
        "title": "ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI",
        "abstract": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "chunk-id": 3,
        "chunk": "to choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these",
        "authors": [
            "Gianluca Giacchi",
            "Isidoros Iakovidis",
            "Bastien Milani",
            "Matthias Stuber",
            "Micah Murray",
            "Benedetta Franceschiello"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:02:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19239v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Medical Physics",
            "Biomedical imaging and signal processing, Ridge regression; shrinkage estimators (Lasso), Numerical optimization and variational techniques",
            "Compression (Coding),Reconstruction,PHYSICAL SCIENCES AND ENGINEERING"
        ]
    },
    {
        "id": 30000063,
        "doi": null,
        "title": "ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI",
        "abstract": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "chunk-id": 4,
        "chunk": "parameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it",
        "authors": [
            "Gianluca Giacchi",
            "Isidoros Iakovidis",
            "Bastien Milani",
            "Matthias Stuber",
            "Micah Murray",
            "Benedetta Franceschiello"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:02:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19239v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Medical Physics",
            "Biomedical imaging and signal processing, Ridge regression; shrinkage estimators (Lasso), Numerical optimization and variational techniques",
            "Compression (Coding),Reconstruction,PHYSICAL SCIENCES AND ENGINEERING"
        ]
    },
    {
        "id": 30000063,
        "doi": null,
        "title": "ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI",
        "abstract": "Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "chunk-id": 5,
        "chunk": "extends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.",
        "authors": [
            "Gianluca Giacchi",
            "Isidoros Iakovidis",
            "Bastien Milani",
            "Matthias Stuber",
            "Micah Murray",
            "Benedetta Franceschiello"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:02:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19239v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Medical Physics",
            "Biomedical imaging and signal processing, Ridge regression; shrinkage estimators (Lasso), Numerical optimization and variational techniques",
            "Compression (Coding),Reconstruction,PHYSICAL SCIENCES AND ENGINEERING"
        ]
    },
    {
        "id": 30000064,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 1,
        "chunk": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000064,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 2,
        "chunk": "and there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000064,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 3,
        "chunk": "justifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000064,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 4,
        "chunk": "well as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 30000065,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 1,
        "chunk": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 30000065,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 2,
        "chunk": "human-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 30000065,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 3,
        "chunk": "proprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 30000066,
        "doi": null,
        "title": "Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions",
        "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
        "chunk-id": 1,
        "chunk": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by",
        "authors": [
            "Minghan Li",
            "Heng Li",
            "Zhi-Qi Cheng",
            "Yifei Dong",
            "Yuxuan Zhou",
            "Jun-Yan He",
            "Qi Dai",
            "Teruko Mitamura",
            "Alexander G. Hauptmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19236v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19236v1",
        "categories": [
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Robotics"
        ]
    },
    {
        "id": 30000066,
        "doi": null,
        "title": "Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions",
        "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
        "chunk-id": 2,
        "chunk": "incorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and",
        "authors": [
            "Minghan Li",
            "Heng Li",
            "Zhi-Qi Cheng",
            "Yifei Dong",
            "Yuxuan Zhou",
            "Jun-Yan He",
            "Qi Dai",
            "Teruko Mitamura",
            "Alexander G. Hauptmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19236v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19236v1",
        "categories": [
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Robotics"
        ]
    },
    {
        "id": 30000066,
        "doi": null,
        "title": "Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions",
        "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
        "chunk-id": 3,
        "chunk": "Non-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'",
        "authors": [
            "Minghan Li",
            "Heng Li",
            "Zhi-Qi Cheng",
            "Yifei Dong",
            "Yuxuan Zhou",
            "Jun-Yan He",
            "Qi Dai",
            "Teruko Mitamura",
            "Alexander G. Hauptmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19236v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19236v1",
        "categories": [
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Robotics"
        ]
    },
    {
        "id": 30000066,
        "doi": null,
        "title": "Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions",
        "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
        "chunk-id": 4,
        "chunk": "real-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
        "authors": [
            "Minghan Li",
            "Heng Li",
            "Zhi-Qi Cheng",
            "Yifei Dong",
            "Yuxuan Zhou",
            "Jun-Yan He",
            "Qi Dai",
            "Teruko Mitamura",
            "Alexander G. Hauptmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19236v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19236v1",
        "categories": [
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Robotics"
        ]
    },
    {
        "id": 30000067,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 1,
        "chunk": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000067,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 2,
        "chunk": "systems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000067,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 3,
        "chunk": "using only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000067,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 4,
        "chunk": "We then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000068,
        "doi": null,
        "title": "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs",
        "abstract": "Minimal pairs are a well-established approach to evaluating the grammatical\nknowledge of language models. However, existing resources for minimal pairs\naddress a limited number of languages and lack diversity of language-specific\ngrammatical phenomena. This paper introduces the Russian Benchmark of\nLinguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that\ndiffer in grammaticality and isolate a morphological, syntactic, or semantic\nphenomenon. In contrast to existing benchmarks of linguistic minimal pairs,\nRuBLiMP is created by applying linguistic perturbations to automatically\nannotated sentences from open text corpora and carefully curating test data. We\ndescribe the data collection protocol and present the results of evaluating 25\nlanguage models in various scenarios. We find that the widely used language\nmodels for Russian are sensitive to morphological and agreement-oriented\ncontrasts but fall behind humans on phenomena requiring understanding of\nstructural relations, negation, transitivity, and tense. RuBLiMP, the codebase,\nand other materials are publicly available.",
        "chunk-id": 1,
        "chunk": "Minimal pairs are a well-established approach to evaluating the grammatical\nknowledge of language models. However, existing resources for minimal pairs\naddress a limited number of languages and lack diversity of language-specific\ngrammatical phenomena. This paper introduces the Russian Benchmark of\nLinguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that",
        "authors": [
            "Ekaterina Taktasheva",
            "Maxim Bazhukov",
            "Kirill Koncha",
            "Alena Fenogenova",
            "Ekaterina Artemova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:55:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19232v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19232v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000068,
        "doi": null,
        "title": "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs",
        "abstract": "Minimal pairs are a well-established approach to evaluating the grammatical\nknowledge of language models. However, existing resources for minimal pairs\naddress a limited number of languages and lack diversity of language-specific\ngrammatical phenomena. This paper introduces the Russian Benchmark of\nLinguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that\ndiffer in grammaticality and isolate a morphological, syntactic, or semantic\nphenomenon. In contrast to existing benchmarks of linguistic minimal pairs,\nRuBLiMP is created by applying linguistic perturbations to automatically\nannotated sentences from open text corpora and carefully curating test data. We\ndescribe the data collection protocol and present the results of evaluating 25\nlanguage models in various scenarios. We find that the widely used language\nmodels for Russian are sensitive to morphological and agreement-oriented\ncontrasts but fall behind humans on phenomena requiring understanding of\nstructural relations, negation, transitivity, and tense. RuBLiMP, the codebase,\nand other materials are publicly available.",
        "chunk-id": 2,
        "chunk": "differ in grammaticality and isolate a morphological, syntactic, or semantic\nphenomenon. In contrast to existing benchmarks of linguistic minimal pairs,\nRuBLiMP is created by applying linguistic perturbations to automatically\nannotated sentences from open text corpora and carefully curating test data. We\ndescribe the data collection protocol and present the results of evaluating 25",
        "authors": [
            "Ekaterina Taktasheva",
            "Maxim Bazhukov",
            "Kirill Koncha",
            "Alena Fenogenova",
            "Ekaterina Artemova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:55:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19232v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19232v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000068,
        "doi": null,
        "title": "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs",
        "abstract": "Minimal pairs are a well-established approach to evaluating the grammatical\nknowledge of language models. However, existing resources for minimal pairs\naddress a limited number of languages and lack diversity of language-specific\ngrammatical phenomena. This paper introduces the Russian Benchmark of\nLinguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that\ndiffer in grammaticality and isolate a morphological, syntactic, or semantic\nphenomenon. In contrast to existing benchmarks of linguistic minimal pairs,\nRuBLiMP is created by applying linguistic perturbations to automatically\nannotated sentences from open text corpora and carefully curating test data. We\ndescribe the data collection protocol and present the results of evaluating 25\nlanguage models in various scenarios. We find that the widely used language\nmodels for Russian are sensitive to morphological and agreement-oriented\ncontrasts but fall behind humans on phenomena requiring understanding of\nstructural relations, negation, transitivity, and tense. RuBLiMP, the codebase,\nand other materials are publicly available.",
        "chunk-id": 3,
        "chunk": "language models in various scenarios. We find that the widely used language\nmodels for Russian are sensitive to morphological and agreement-oriented\ncontrasts but fall behind humans on phenomena requiring understanding of\nstructural relations, negation, transitivity, and tense. RuBLiMP, the codebase,\nand other materials are publicly available.",
        "authors": [
            "Ekaterina Taktasheva",
            "Maxim Bazhukov",
            "Kirill Koncha",
            "Alena Fenogenova",
            "Ekaterina Artemova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:55:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19232v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19232v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000069,
        "doi": null,
        "title": "Spiking Convolutional Neural Networks for Text Classification",
        "abstract": "Spiking neural networks (SNNs) offer a promising pathway to implement deep\nneural networks (DNNs) in a more energy-efficient manner since their neurons\nare sparsely activated and inferences are event-driven. However, there have\nbeen very few works that have demonstrated the efficacy of SNNs in language\ntasks partially because it is non-trivial to represent words in the forms of\nspikes and to deal with variable-length texts by SNNs. This work presents a\n\"conversion + fine-tuning\" two-step method for training SNNs for text\nclassification and proposes a simple but effective way to encode pre-trained\nword embeddings as spike trains. We show empirically that after fine-tuning\nwith surrogate gradients, the converted SNNs achieve comparable results to\ntheir DNN counterparts with much less energy consumption across multiple\ndatasets for both English and Chinese. We also show that such SNNs are more\nrobust to adversarial attacks than DNNs.",
        "chunk-id": 1,
        "chunk": "Spiking neural networks (SNNs) offer a promising pathway to implement deep\nneural networks (DNNs) in a more energy-efficient manner since their neurons\nare sparsely activated and inferences are event-driven. However, there have\nbeen very few works that have demonstrated the efficacy of SNNs in language\ntasks partially because it is non-trivial to represent words in the forms of",
        "authors": [
            "Changze Lv",
            "Jianhan Xu",
            "Xiaoqing Zheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19230v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Computation and Language"
        ]
    },
    {
        "id": 30000069,
        "doi": null,
        "title": "Spiking Convolutional Neural Networks for Text Classification",
        "abstract": "Spiking neural networks (SNNs) offer a promising pathway to implement deep\nneural networks (DNNs) in a more energy-efficient manner since their neurons\nare sparsely activated and inferences are event-driven. However, there have\nbeen very few works that have demonstrated the efficacy of SNNs in language\ntasks partially because it is non-trivial to represent words in the forms of\nspikes and to deal with variable-length texts by SNNs. This work presents a\n\"conversion + fine-tuning\" two-step method for training SNNs for text\nclassification and proposes a simple but effective way to encode pre-trained\nword embeddings as spike trains. We show empirically that after fine-tuning\nwith surrogate gradients, the converted SNNs achieve comparable results to\ntheir DNN counterparts with much less energy consumption across multiple\ndatasets for both English and Chinese. We also show that such SNNs are more\nrobust to adversarial attacks than DNNs.",
        "chunk-id": 2,
        "chunk": "spikes and to deal with variable-length texts by SNNs. This work presents a\n\"conversion + fine-tuning\" two-step method for training SNNs for text\nclassification and proposes a simple but effective way to encode pre-trained\nword embeddings as spike trains. We show empirically that after fine-tuning\nwith surrogate gradients, the converted SNNs achieve comparable results to",
        "authors": [
            "Changze Lv",
            "Jianhan Xu",
            "Xiaoqing Zheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19230v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Computation and Language"
        ]
    },
    {
        "id": 30000069,
        "doi": null,
        "title": "Spiking Convolutional Neural Networks for Text Classification",
        "abstract": "Spiking neural networks (SNNs) offer a promising pathway to implement deep\nneural networks (DNNs) in a more energy-efficient manner since their neurons\nare sparsely activated and inferences are event-driven. However, there have\nbeen very few works that have demonstrated the efficacy of SNNs in language\ntasks partially because it is non-trivial to represent words in the forms of\nspikes and to deal with variable-length texts by SNNs. This work presents a\n\"conversion + fine-tuning\" two-step method for training SNNs for text\nclassification and proposes a simple but effective way to encode pre-trained\nword embeddings as spike trains. We show empirically that after fine-tuning\nwith surrogate gradients, the converted SNNs achieve comparable results to\ntheir DNN counterparts with much less energy consumption across multiple\ndatasets for both English and Chinese. We also show that such SNNs are more\nrobust to adversarial attacks than DNNs.",
        "chunk-id": 3,
        "chunk": "their DNN counterparts with much less energy consumption across multiple\ndatasets for both English and Chinese. We also show that such SNNs are more\nrobust to adversarial attacks than DNNs.",
        "authors": [
            "Changze Lv",
            "Jianhan Xu",
            "Xiaoqing Zheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19230v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Computation and Language"
        ]
    },
    {
        "id": 30000070,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 1,
        "chunk": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000070,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 2,
        "chunk": "\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 2,
        "chunk": "to lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 3,
        "chunk": "with student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 4,
        "chunk": "finally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 5,
        "chunk": "thoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000071,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 6,
        "chunk": "experiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000072,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 30000072,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 2,
        "chunk": "propose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 30000072,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 3,
        "chunk": "educational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 30000072,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 4,
        "chunk": "multi-agent systems in virtual classroom teaching.",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 30000073,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 1,
        "chunk": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000073,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 2,
        "chunk": "focus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000073,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 3,
        "chunk": "are commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000073,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 4,
        "chunk": "However, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000073,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 5,
        "chunk": "act as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000074,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 1,
        "chunk": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000074,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 2,
        "chunk": "effectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000074,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 3,
        "chunk": "exhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 30000075,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 1,
        "chunk": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000075,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 2,
        "chunk": "machine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000075,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 3,
        "chunk": "databases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000075,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 4,
        "chunk": "detection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000076,
        "doi": null,
        "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
        "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "chunk-id": 1,
        "chunk": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the",
        "authors": [
            "Zhimin Shao",
            "Jialang Xu",
            "Danail Stoyanov",
            "Evangelos B. Mazomenos",
            "Yueming Jin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:43:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19217v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Robotics"
        ]
    },
    {
        "id": 30000076,
        "doi": null,
        "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
        "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "chunk-id": 2,
        "chunk": "rich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from",
        "authors": [
            "Zhimin Shao",
            "Jialang Xu",
            "Danail Stoyanov",
            "Evangelos B. Mazomenos",
            "Yueming Jin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:43:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19217v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Robotics"
        ]
    },
    {
        "id": 30000076,
        "doi": null,
        "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
        "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "chunk-id": 3,
        "chunk": "surgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with",
        "authors": [
            "Zhimin Shao",
            "Jialang Xu",
            "Danail Stoyanov",
            "Evangelos B. Mazomenos",
            "Yueming Jin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:43:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19217v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Robotics"
        ]
    },
    {
        "id": 30000076,
        "doi": null,
        "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
        "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "chunk-id": 4,
        "chunk": "both slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,",
        "authors": [
            "Zhimin Shao",
            "Jialang Xu",
            "Danail Stoyanov",
            "Evangelos B. Mazomenos",
            "Yueming Jin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:43:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19217v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Robotics"
        ]
    },
    {
        "id": 30000076,
        "doi": null,
        "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
        "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "chunk-id": 5,
        "chunk": "and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
        "authors": [
            "Zhimin Shao",
            "Jialang Xu",
            "Danail Stoyanov",
            "Evangelos B. Mazomenos",
            "Yueming Jin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:43:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19217v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Robotics"
        ]
    },
    {
        "id": 30000077,
        "doi": null,
        "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
        "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel\nadaptive RAG model that extracts self-aware uncertainty of LLMs from their\ninternal states. SeaKR activates retrieval when the LLMs present high\nself-aware uncertainty for generation. To effectively integrate retrieved\nknowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty\nto preserve the snippet that reduces their uncertainty to the utmost. To\nfacilitate solving complex tasks that require multiple retrievals, SeaKR\nutilizes their self-aware uncertainty to choose among different reasoning\nstrategies. Our experiments on both complex and simple Question Answering\ndatasets show that SeaKR outperforms existing adaptive RAG methods. We release\nour code at https://github.com/THU-KEG/SeaKR.",
        "chunk-id": 1,
        "chunk": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel\nadaptive RAG model that extracts self-aware uncertainty of LLMs from their\ninternal states. SeaKR activates retrieval when the LLMs present high\nself-aware uncertainty for generation. To effectively integrate retrieved\nknowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty",
        "authors": [
            "Zijun Yao",
            "Weijian Qi",
            "Liangming Pan",
            "Shulin Cao",
            "Linmei Hu",
            "Weichuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:38:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19215v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19215v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000077,
        "doi": null,
        "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
        "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel\nadaptive RAG model that extracts self-aware uncertainty of LLMs from their\ninternal states. SeaKR activates retrieval when the LLMs present high\nself-aware uncertainty for generation. To effectively integrate retrieved\nknowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty\nto preserve the snippet that reduces their uncertainty to the utmost. To\nfacilitate solving complex tasks that require multiple retrievals, SeaKR\nutilizes their self-aware uncertainty to choose among different reasoning\nstrategies. Our experiments on both complex and simple Question Answering\ndatasets show that SeaKR outperforms existing adaptive RAG methods. We release\nour code at https://github.com/THU-KEG/SeaKR.",
        "chunk-id": 2,
        "chunk": "to preserve the snippet that reduces their uncertainty to the utmost. To\nfacilitate solving complex tasks that require multiple retrievals, SeaKR\nutilizes their self-aware uncertainty to choose among different reasoning\nstrategies. Our experiments on both complex and simple Question Answering\ndatasets show that SeaKR outperforms existing adaptive RAG methods. We release",
        "authors": [
            "Zijun Yao",
            "Weijian Qi",
            "Liangming Pan",
            "Shulin Cao",
            "Linmei Hu",
            "Weichuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:38:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19215v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19215v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000077,
        "doi": null,
        "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
        "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel\nadaptive RAG model that extracts self-aware uncertainty of LLMs from their\ninternal states. SeaKR activates retrieval when the LLMs present high\nself-aware uncertainty for generation. To effectively integrate retrieved\nknowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty\nto preserve the snippet that reduces their uncertainty to the utmost. To\nfacilitate solving complex tasks that require multiple retrievals, SeaKR\nutilizes their self-aware uncertainty to choose among different reasoning\nstrategies. Our experiments on both complex and simple Question Answering\ndatasets show that SeaKR outperforms existing adaptive RAG methods. We release\nour code at https://github.com/THU-KEG/SeaKR.",
        "chunk-id": 3,
        "chunk": "our code at https://github.com/THU-KEG/SeaKR.",
        "authors": [
            "Zijun Yao",
            "Weijian Qi",
            "Liangming Pan",
            "Shulin Cao",
            "Linmei Hu",
            "Weichuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:38:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19215v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19215v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000078,
        "doi": null,
        "title": "Bessel Models for Representations of $GSp(4, q)$",
        "abstract": "We compute the Bessel models of irreducible representations of the finite\ngroup $GSp(4, q)$.",
        "chunk-id": 1,
        "chunk": "We compute the Bessel models of irreducible representations of the finite\ngroup $GSp(4, q)$.",
        "authors": [
            "Jonathan Cohen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:22:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19203v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19203v1",
        "categories": [
            "Representation Theory",
            "Number Theory",
            "Representations of finite groups of Lie type"
        ]
    },
    {
        "id": 30000079,
        "doi": null,
        "title": "Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics",
        "abstract": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics\nthat make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir\ncomputing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for\nprediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired\ncomputational architecture.",
        "chunk-id": 1,
        "chunk": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics",
        "authors": [
            "Hanna M. Tolle",
            "Andrea I Luppi",
            "Anil K. Seth",
            "Pedro A. M. Mediano"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:19:30+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19201v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19201v1",
        "categories": [
            "Neurons and Cognition"
        ]
    },
    {
        "id": 30000079,
        "doi": null,
        "title": "Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics",
        "abstract": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics\nthat make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir\ncomputing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for\nprediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired\ncomputational architecture.",
        "chunk-id": 2,
        "chunk": "that make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir",
        "authors": [
            "Hanna M. Tolle",
            "Andrea I Luppi",
            "Anil K. Seth",
            "Pedro A. M. Mediano"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:19:30+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19201v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19201v1",
        "categories": [
            "Neurons and Cognition"
        ]
    },
    {
        "id": 30000079,
        "doi": null,
        "title": "Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics",
        "abstract": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics\nthat make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir\ncomputing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for\nprediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired\ncomputational architecture.",
        "chunk-id": 3,
        "chunk": "computing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for",
        "authors": [
            "Hanna M. Tolle",
            "Andrea I Luppi",
            "Anil K. Seth",
            "Pedro A. M. Mediano"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:19:30+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19201v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19201v1",
        "categories": [
            "Neurons and Cognition"
        ]
    },
    {
        "id": 30000079,
        "doi": null,
        "title": "Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics",
        "abstract": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics\nthat make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir\ncomputing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for\nprediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired\ncomputational architecture.",
        "chunk-id": 4,
        "chunk": "prediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired",
        "authors": [
            "Hanna M. Tolle",
            "Andrea I Luppi",
            "Anil K. Seth",
            "Pedro A. M. Mediano"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:19:30+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19201v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19201v1",
        "categories": [
            "Neurons and Cognition"
        ]
    },
    {
        "id": 30000079,
        "doi": null,
        "title": "Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics",
        "abstract": "Biological neural networks can perform complex computations to predict their\nenvironment, far above the limited predictive capabilities of individual\nneurons. While conventional approaches to understanding these computations\noften focus on isolating the contributions of single neurons, here we argue\nthat a deeper understanding requires considering emergent dynamics - dynamics\nthat make the whole system \"more than the sum of its parts\". Specifically, we\nexamine the relationship between prediction performance and emergence by\nleveraging recent quantitative metrics of emergence, derived from Partial\nInformation Decomposition, and by modelling the prediction of environmental\ndynamics in a bio-inspired computational framework known as reservoir\ncomputing. Notably, we reveal a bidirectional coupling between prediction\nperformance and emergence, which generalises across task environments and\nreservoir network topologies, and is recapitulated by three key results: 1)\nOptimising hyperparameters for performance enhances emergent dynamics, and vice\nversa; 2) Emergent dynamics represent a near sufficient criterion for\nprediction success in all task environments, and an almost necessary criterion\nin most environments; 3) Training reservoir computers on larger datasets\nresults in stronger emergent dynamics, which contain task-relevant information\ncrucial for performance. Overall, our study points to a pivotal role of\nemergence in facilitating environmental predictions in a bio-inspired\ncomputational architecture.",
        "chunk-id": 5,
        "chunk": "computational architecture.",
        "authors": [
            "Hanna M. Tolle",
            "Andrea I Luppi",
            "Anil K. Seth",
            "Pedro A. M. Mediano"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:19:30+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19201v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19201v1",
        "categories": [
            "Neurons and Cognition"
        ]
    },
    {
        "id": 30000080,
        "doi": null,
        "title": "Light and strange vector resonances from lattice QCD at physical quark masses",
        "abstract": "We present the first ab initio calculation at physical quark masses of\nscattering amplitudes describing the lightest pseudoscalar mesons interacting\nvia the strong force in the vector channel. Using lattice quantum\nchromodynamics, we postdict the defining parameters for two short-lived\nresonances, the $\\rho(770)$ and $K^*(892)$, which manifest as complex energy\npoles in $\\pi \\pi$ and $K \\pi$ scattering amplitudes, respectively. The\ncalculation proceeds by first computing the finite-volume energy spectrum of\nthe two-hadron systems, and then determining the amplitudes from the energies\nusing the L\\\"uscher formalism. The error budget includes a data-driven\nsystematic error, obtained by scanning possible fit ranges and fit models to\nextract the spectrum from Euclidean correlators, as well as the scattering\namplitudes from the latter. The final results, obtained by analytically\ncontinuing multiple parameterizations into the complex energy plane, are\n$M_\\rho = 796(5)(50)~\\mathrm{MeV}$, $\\Gamma_\\rho = 192(10)(31)~\\mathrm{MeV}$,\n$M_{K^*} = 893(2)(54)~\\mathrm{MeV}$ and $\\Gamma_{K^*} =\n51(2)(11)~\\mathrm{MeV}$, where the subscript indicates the resonance and $M$\nand $\\Gamma$ stand for the mass and width, respectively, and where the first\nbracket indicates the statistical and the second bracket the systematic\nuncertainty.",
        "chunk-id": 1,
        "chunk": "We present the first ab initio calculation at physical quark masses of\nscattering amplitudes describing the lightest pseudoscalar mesons interacting\nvia the strong force in the vector channel. Using lattice quantum\nchromodynamics, we postdict the defining parameters for two short-lived\nresonances, the $\\rho(770)$ and $K^*(892)$, which manifest as complex energy",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19194v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19194v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000080,
        "doi": null,
        "title": "Light and strange vector resonances from lattice QCD at physical quark masses",
        "abstract": "We present the first ab initio calculation at physical quark masses of\nscattering amplitudes describing the lightest pseudoscalar mesons interacting\nvia the strong force in the vector channel. Using lattice quantum\nchromodynamics, we postdict the defining parameters for two short-lived\nresonances, the $\\rho(770)$ and $K^*(892)$, which manifest as complex energy\npoles in $\\pi \\pi$ and $K \\pi$ scattering amplitudes, respectively. The\ncalculation proceeds by first computing the finite-volume energy spectrum of\nthe two-hadron systems, and then determining the amplitudes from the energies\nusing the L\\\"uscher formalism. The error budget includes a data-driven\nsystematic error, obtained by scanning possible fit ranges and fit models to\nextract the spectrum from Euclidean correlators, as well as the scattering\namplitudes from the latter. The final results, obtained by analytically\ncontinuing multiple parameterizations into the complex energy plane, are\n$M_\\rho = 796(5)(50)~\\mathrm{MeV}$, $\\Gamma_\\rho = 192(10)(31)~\\mathrm{MeV}$,\n$M_{K^*} = 893(2)(54)~\\mathrm{MeV}$ and $\\Gamma_{K^*} =\n51(2)(11)~\\mathrm{MeV}$, where the subscript indicates the resonance and $M$\nand $\\Gamma$ stand for the mass and width, respectively, and where the first\nbracket indicates the statistical and the second bracket the systematic\nuncertainty.",
        "chunk-id": 2,
        "chunk": "poles in $\\pi \\pi$ and $K \\pi$ scattering amplitudes, respectively. The\ncalculation proceeds by first computing the finite-volume energy spectrum of\nthe two-hadron systems, and then determining the amplitudes from the energies\nusing the L\\\"uscher formalism. The error budget includes a data-driven\nsystematic error, obtained by scanning possible fit ranges and fit models to",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19194v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19194v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000080,
        "doi": null,
        "title": "Light and strange vector resonances from lattice QCD at physical quark masses",
        "abstract": "We present the first ab initio calculation at physical quark masses of\nscattering amplitudes describing the lightest pseudoscalar mesons interacting\nvia the strong force in the vector channel. Using lattice quantum\nchromodynamics, we postdict the defining parameters for two short-lived\nresonances, the $\\rho(770)$ and $K^*(892)$, which manifest as complex energy\npoles in $\\pi \\pi$ and $K \\pi$ scattering amplitudes, respectively. The\ncalculation proceeds by first computing the finite-volume energy spectrum of\nthe two-hadron systems, and then determining the amplitudes from the energies\nusing the L\\\"uscher formalism. The error budget includes a data-driven\nsystematic error, obtained by scanning possible fit ranges and fit models to\nextract the spectrum from Euclidean correlators, as well as the scattering\namplitudes from the latter. The final results, obtained by analytically\ncontinuing multiple parameterizations into the complex energy plane, are\n$M_\\rho = 796(5)(50)~\\mathrm{MeV}$, $\\Gamma_\\rho = 192(10)(31)~\\mathrm{MeV}$,\n$M_{K^*} = 893(2)(54)~\\mathrm{MeV}$ and $\\Gamma_{K^*} =\n51(2)(11)~\\mathrm{MeV}$, where the subscript indicates the resonance and $M$\nand $\\Gamma$ stand for the mass and width, respectively, and where the first\nbracket indicates the statistical and the second bracket the systematic\nuncertainty.",
        "chunk-id": 3,
        "chunk": "extract the spectrum from Euclidean correlators, as well as the scattering\namplitudes from the latter. The final results, obtained by analytically\ncontinuing multiple parameterizations into the complex energy plane, are\n$M_\\rho = 796(5)(50)~\\mathrm{MeV}$, $\\Gamma_\\rho = 192(10)(31)~\\mathrm{MeV}$,\n$M_{K^*} = 893(2)(54)~\\mathrm{MeV}$ and $\\Gamma_{K^*} =",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19194v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19194v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000080,
        "doi": null,
        "title": "Light and strange vector resonances from lattice QCD at physical quark masses",
        "abstract": "We present the first ab initio calculation at physical quark masses of\nscattering amplitudes describing the lightest pseudoscalar mesons interacting\nvia the strong force in the vector channel. Using lattice quantum\nchromodynamics, we postdict the defining parameters for two short-lived\nresonances, the $\\rho(770)$ and $K^*(892)$, which manifest as complex energy\npoles in $\\pi \\pi$ and $K \\pi$ scattering amplitudes, respectively. The\ncalculation proceeds by first computing the finite-volume energy spectrum of\nthe two-hadron systems, and then determining the amplitudes from the energies\nusing the L\\\"uscher formalism. The error budget includes a data-driven\nsystematic error, obtained by scanning possible fit ranges and fit models to\nextract the spectrum from Euclidean correlators, as well as the scattering\namplitudes from the latter. The final results, obtained by analytically\ncontinuing multiple parameterizations into the complex energy plane, are\n$M_\\rho = 796(5)(50)~\\mathrm{MeV}$, $\\Gamma_\\rho = 192(10)(31)~\\mathrm{MeV}$,\n$M_{K^*} = 893(2)(54)~\\mathrm{MeV}$ and $\\Gamma_{K^*} =\n51(2)(11)~\\mathrm{MeV}$, where the subscript indicates the resonance and $M$\nand $\\Gamma$ stand for the mass and width, respectively, and where the first\nbracket indicates the statistical and the second bracket the systematic\nuncertainty.",
        "chunk-id": 4,
        "chunk": "51(2)(11)~\\mathrm{MeV}$, where the subscript indicates the resonance and $M$\nand $\\Gamma$ stand for the mass and width, respectively, and where the first\nbracket indicates the statistical and the second bracket the systematic\nuncertainty.",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19194v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19194v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000081,
        "doi": null,
        "title": "Physical-mass calculation of $\u03c1(770)$ and $K^*(892)$ resonance parameters via $\u03c0\u03c0$ and $K \u03c0$ scattering amplitudes from lattice QCD",
        "abstract": "We present our study of the $\\rho(770)$ and $K^*(892)$ resonances from\nlattice quantum chromodynamics (QCD) employing domain-wall fermions at physical\nquark masses. We determine the finite-volume energy spectrum in various\nmomentum frames and obtain phase-shift parameterizations via the L\\\"uscher\nformalism, and as a final step the complex resonance poles of the $\\pi \\pi$ and\n$K \\pi$ elastic scattering amplitudes via an analytical continuation of the\nmodels. By sampling a large number of representative sets of underlying\nenergy-level fits, we also assign a systematic uncertainty to our final\nresults. This is a significant extension to data-driven analysis methods that\nhave been used in lattice QCD to date, due to the two-step nature of the\nformalism. Our final pole positions, $M+i\\Gamma/2$, with all statistical and\nsystematic errors exposed, are $M_{K^{*}} = 893(2)(8)(54)(2)~\\mathrm{MeV}$ and\n$\\Gamma_{K^{*}} = 51(2)(11)(3)(0)~\\mathrm{MeV}$ for the $K^*(892)$ resonance\nand $M_{\\rho} = 796(5)(15)(48)(2)~\\mathrm{MeV}$ and $\\Gamma_{\\rho} =\n192(10)(28)(12)(0)~\\mathrm{MeV}$ for the $\\rho(770)$ resonance. The four\ndifferently grouped sources of uncertainties are, in the order of occurrence:\nstatistical, data-driven systematic, an estimation of systematic effects beyond\nour computation (dominated by the fact that we employ a single lattice\nspacing), and the error from the scale-setting uncertainty on our ensemble.",
        "chunk-id": 1,
        "chunk": "We present our study of the $\\rho(770)$ and $K^*(892)$ resonances from\nlattice quantum chromodynamics (QCD) employing domain-wall fermions at physical\nquark masses. We determine the finite-volume energy spectrum in various\nmomentum frames and obtain phase-shift parameterizations via the L\\\"uscher\nformalism, and as a final step the complex resonance poles of the $\\pi \\pi$ and",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:12:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19193v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19193v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000081,
        "doi": null,
        "title": "Physical-mass calculation of $\u03c1(770)$ and $K^*(892)$ resonance parameters via $\u03c0\u03c0$ and $K \u03c0$ scattering amplitudes from lattice QCD",
        "abstract": "We present our study of the $\\rho(770)$ and $K^*(892)$ resonances from\nlattice quantum chromodynamics (QCD) employing domain-wall fermions at physical\nquark masses. We determine the finite-volume energy spectrum in various\nmomentum frames and obtain phase-shift parameterizations via the L\\\"uscher\nformalism, and as a final step the complex resonance poles of the $\\pi \\pi$ and\n$K \\pi$ elastic scattering amplitudes via an analytical continuation of the\nmodels. By sampling a large number of representative sets of underlying\nenergy-level fits, we also assign a systematic uncertainty to our final\nresults. This is a significant extension to data-driven analysis methods that\nhave been used in lattice QCD to date, due to the two-step nature of the\nformalism. Our final pole positions, $M+i\\Gamma/2$, with all statistical and\nsystematic errors exposed, are $M_{K^{*}} = 893(2)(8)(54)(2)~\\mathrm{MeV}$ and\n$\\Gamma_{K^{*}} = 51(2)(11)(3)(0)~\\mathrm{MeV}$ for the $K^*(892)$ resonance\nand $M_{\\rho} = 796(5)(15)(48)(2)~\\mathrm{MeV}$ and $\\Gamma_{\\rho} =\n192(10)(28)(12)(0)~\\mathrm{MeV}$ for the $\\rho(770)$ resonance. The four\ndifferently grouped sources of uncertainties are, in the order of occurrence:\nstatistical, data-driven systematic, an estimation of systematic effects beyond\nour computation (dominated by the fact that we employ a single lattice\nspacing), and the error from the scale-setting uncertainty on our ensemble.",
        "chunk-id": 2,
        "chunk": "$K \\pi$ elastic scattering amplitudes via an analytical continuation of the\nmodels. By sampling a large number of representative sets of underlying\nenergy-level fits, we also assign a systematic uncertainty to our final\nresults. This is a significant extension to data-driven analysis methods that\nhave been used in lattice QCD to date, due to the two-step nature of the",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:12:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19193v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19193v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000081,
        "doi": null,
        "title": "Physical-mass calculation of $\u03c1(770)$ and $K^*(892)$ resonance parameters via $\u03c0\u03c0$ and $K \u03c0$ scattering amplitudes from lattice QCD",
        "abstract": "We present our study of the $\\rho(770)$ and $K^*(892)$ resonances from\nlattice quantum chromodynamics (QCD) employing domain-wall fermions at physical\nquark masses. We determine the finite-volume energy spectrum in various\nmomentum frames and obtain phase-shift parameterizations via the L\\\"uscher\nformalism, and as a final step the complex resonance poles of the $\\pi \\pi$ and\n$K \\pi$ elastic scattering amplitudes via an analytical continuation of the\nmodels. By sampling a large number of representative sets of underlying\nenergy-level fits, we also assign a systematic uncertainty to our final\nresults. This is a significant extension to data-driven analysis methods that\nhave been used in lattice QCD to date, due to the two-step nature of the\nformalism. Our final pole positions, $M+i\\Gamma/2$, with all statistical and\nsystematic errors exposed, are $M_{K^{*}} = 893(2)(8)(54)(2)~\\mathrm{MeV}$ and\n$\\Gamma_{K^{*}} = 51(2)(11)(3)(0)~\\mathrm{MeV}$ for the $K^*(892)$ resonance\nand $M_{\\rho} = 796(5)(15)(48)(2)~\\mathrm{MeV}$ and $\\Gamma_{\\rho} =\n192(10)(28)(12)(0)~\\mathrm{MeV}$ for the $\\rho(770)$ resonance. The four\ndifferently grouped sources of uncertainties are, in the order of occurrence:\nstatistical, data-driven systematic, an estimation of systematic effects beyond\nour computation (dominated by the fact that we employ a single lattice\nspacing), and the error from the scale-setting uncertainty on our ensemble.",
        "chunk-id": 3,
        "chunk": "formalism. Our final pole positions, $M+i\\Gamma/2$, with all statistical and\nsystematic errors exposed, are $M_{K^{*}} = 893(2)(8)(54)(2)~\\mathrm{MeV}$ and\n$\\Gamma_{K^{*}} = 51(2)(11)(3)(0)~\\mathrm{MeV}$ for the $K^*(892)$ resonance\nand $M_{\\rho} = 796(5)(15)(48)(2)~\\mathrm{MeV}$ and $\\Gamma_{\\rho} =\n192(10)(28)(12)(0)~\\mathrm{MeV}$ for the $\\rho(770)$ resonance. The four",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:12:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19193v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19193v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000081,
        "doi": null,
        "title": "Physical-mass calculation of $\u03c1(770)$ and $K^*(892)$ resonance parameters via $\u03c0\u03c0$ and $K \u03c0$ scattering amplitudes from lattice QCD",
        "abstract": "We present our study of the $\\rho(770)$ and $K^*(892)$ resonances from\nlattice quantum chromodynamics (QCD) employing domain-wall fermions at physical\nquark masses. We determine the finite-volume energy spectrum in various\nmomentum frames and obtain phase-shift parameterizations via the L\\\"uscher\nformalism, and as a final step the complex resonance poles of the $\\pi \\pi$ and\n$K \\pi$ elastic scattering amplitudes via an analytical continuation of the\nmodels. By sampling a large number of representative sets of underlying\nenergy-level fits, we also assign a systematic uncertainty to our final\nresults. This is a significant extension to data-driven analysis methods that\nhave been used in lattice QCD to date, due to the two-step nature of the\nformalism. Our final pole positions, $M+i\\Gamma/2$, with all statistical and\nsystematic errors exposed, are $M_{K^{*}} = 893(2)(8)(54)(2)~\\mathrm{MeV}$ and\n$\\Gamma_{K^{*}} = 51(2)(11)(3)(0)~\\mathrm{MeV}$ for the $K^*(892)$ resonance\nand $M_{\\rho} = 796(5)(15)(48)(2)~\\mathrm{MeV}$ and $\\Gamma_{\\rho} =\n192(10)(28)(12)(0)~\\mathrm{MeV}$ for the $\\rho(770)$ resonance. The four\ndifferently grouped sources of uncertainties are, in the order of occurrence:\nstatistical, data-driven systematic, an estimation of systematic effects beyond\nour computation (dominated by the fact that we employ a single lattice\nspacing), and the error from the scale-setting uncertainty on our ensemble.",
        "chunk-id": 4,
        "chunk": "differently grouped sources of uncertainties are, in the order of occurrence:\nstatistical, data-driven systematic, an estimation of systematic effects beyond\nour computation (dominated by the fact that we employ a single lattice\nspacing), and the error from the scale-setting uncertainty on our ensemble.",
        "authors": [
            "Peter Boyle",
            "Felix Erben",
            "Vera G\u00fclpers",
            "Maxwell T. Hansen",
            "Fabian Joswig",
            "Nelson Pitanga Lachini",
            "Michael Marshall",
            "Antonin Portelli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:12:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19193v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19193v1",
        "categories": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ]
    },
    {
        "id": 30000082,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 1,
        "chunk": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000082,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 2,
        "chunk": "contrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000082,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 3,
        "chunk": "a principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000082,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 4,
        "chunk": "generations and their scores.",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000083,
        "doi": null,
        "title": "On asymptotic independence in higher dimensions",
        "abstract": "In the study of extremes, the presence of asymptotic independence signifies\nthat extreme events across multiple variables are probably less likely to occur\ntogether. Although well-understood in a bivariate context, the concept remains\nrelatively unexplored when addressing the nuances of joint occurrence of\nextremes in higher dimensions. In this paper, we propose a notion of mutual\nasymptotic independence to capture the behavior of joint extremes in dimensions\nlarger than two and contrast it with the classical notion of (pairwise)\nasymptotic independence. Furthermore, we define $k$-wise asymptotic\nindependence which lies in between pairwise and mutual asymptotic independence.\nThe concepts are compared using examples of Archimedean, Gaussian and\nMarshall-Olkin copulas among others. Notably, for the popular Gaussian copula,\nwe provide explicit conditions on the correlation matrix for mutual asymptotic\nindependence to hold; moreover, we are able to compute exact tail orders for\nvarious tail events.",
        "chunk-id": 1,
        "chunk": "In the study of extremes, the presence of asymptotic independence signifies\nthat extreme events across multiple variables are probably less likely to occur\ntogether. Although well-understood in a bivariate context, the concept remains\nrelatively unexplored when addressing the nuances of joint occurrence of\nextremes in higher dimensions. In this paper, we propose a notion of mutual",
        "authors": [
            "Bikramjit Das",
            "Vicky Fasen-Hartmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:05:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19186v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19186v1",
        "categories": [
            "Statistics Theory",
            "Statistics Theory",
            "Primary 62H05, 62H20, 62G32, Secondary 60E05"
        ]
    },
    {
        "id": 30000083,
        "doi": null,
        "title": "On asymptotic independence in higher dimensions",
        "abstract": "In the study of extremes, the presence of asymptotic independence signifies\nthat extreme events across multiple variables are probably less likely to occur\ntogether. Although well-understood in a bivariate context, the concept remains\nrelatively unexplored when addressing the nuances of joint occurrence of\nextremes in higher dimensions. In this paper, we propose a notion of mutual\nasymptotic independence to capture the behavior of joint extremes in dimensions\nlarger than two and contrast it with the classical notion of (pairwise)\nasymptotic independence. Furthermore, we define $k$-wise asymptotic\nindependence which lies in between pairwise and mutual asymptotic independence.\nThe concepts are compared using examples of Archimedean, Gaussian and\nMarshall-Olkin copulas among others. Notably, for the popular Gaussian copula,\nwe provide explicit conditions on the correlation matrix for mutual asymptotic\nindependence to hold; moreover, we are able to compute exact tail orders for\nvarious tail events.",
        "chunk-id": 2,
        "chunk": "asymptotic independence to capture the behavior of joint extremes in dimensions\nlarger than two and contrast it with the classical notion of (pairwise)\nasymptotic independence. Furthermore, we define $k$-wise asymptotic\nindependence which lies in between pairwise and mutual asymptotic independence.\nThe concepts are compared using examples of Archimedean, Gaussian and",
        "authors": [
            "Bikramjit Das",
            "Vicky Fasen-Hartmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:05:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19186v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19186v1",
        "categories": [
            "Statistics Theory",
            "Statistics Theory",
            "Primary 62H05, 62H20, 62G32, Secondary 60E05"
        ]
    },
    {
        "id": 30000083,
        "doi": null,
        "title": "On asymptotic independence in higher dimensions",
        "abstract": "In the study of extremes, the presence of asymptotic independence signifies\nthat extreme events across multiple variables are probably less likely to occur\ntogether. Although well-understood in a bivariate context, the concept remains\nrelatively unexplored when addressing the nuances of joint occurrence of\nextremes in higher dimensions. In this paper, we propose a notion of mutual\nasymptotic independence to capture the behavior of joint extremes in dimensions\nlarger than two and contrast it with the classical notion of (pairwise)\nasymptotic independence. Furthermore, we define $k$-wise asymptotic\nindependence which lies in between pairwise and mutual asymptotic independence.\nThe concepts are compared using examples of Archimedean, Gaussian and\nMarshall-Olkin copulas among others. Notably, for the popular Gaussian copula,\nwe provide explicit conditions on the correlation matrix for mutual asymptotic\nindependence to hold; moreover, we are able to compute exact tail orders for\nvarious tail events.",
        "chunk-id": 3,
        "chunk": "Marshall-Olkin copulas among others. Notably, for the popular Gaussian copula,\nwe provide explicit conditions on the correlation matrix for mutual asymptotic\nindependence to hold; moreover, we are able to compute exact tail orders for\nvarious tail events.",
        "authors": [
            "Bikramjit Das",
            "Vicky Fasen-Hartmann"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:05:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19186v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19186v1",
        "categories": [
            "Statistics Theory",
            "Statistics Theory",
            "Primary 62H05, 62H20, 62G32, Secondary 60E05"
        ]
    },
    {
        "id": 30000084,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 1,
        "chunk": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000084,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 2,
        "chunk": "inadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000084,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 3,
        "chunk": "X-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000084,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 4,
        "chunk": "available annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000084,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 5,
        "chunk": "budget in applied machine learning projects.",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000085,
        "doi": null,
        "title": "Stark Control of Plexcitonic States in Incoherent Quantum Systems",
        "abstract": "Electro-optic control of quantum dots embedded in the plasmonic nanocavities\nenables active tuning of photonic devices for emerging applications in Quantum\noptics such as quantum information processing, entanglement and ultrafast\noptical switching. Here, we demonstrate the coherent control of plexcitonic\nstates in (i) an off-resonant and (ii) a resonant coupled quantum systems\nthrough optical Stark effect (OSE). We analyze a hybrid plasmon-emitter system\nwhich exhibits tunable Fano resonance, Stark induced transparency (SIT) and\nvacuum Rabi splitting due to quadratic Stark shift in the degenerate states of\nquantum emitter (QE). In addition, a resonantly coupled system shows the\nsignature of double Fano resonance due to Stark-induced splitting in a\ntwo-level QE. Our study shows that Stark tuning of plexcitons not only\nmitigates decoherence in the quantum system but it also stimulates on/off\nswitching of spontaneous photon emission in the visible regime. Such tunable\nsystems can be used to operate photonic integrated circuits (PIC) for\napplications in quantum computing and information processing.",
        "chunk-id": 1,
        "chunk": "Electro-optic control of quantum dots embedded in the plasmonic nanocavities\nenables active tuning of photonic devices for emerging applications in Quantum\noptics such as quantum information processing, entanglement and ultrafast\noptical switching. Here, we demonstrate the coherent control of plexcitonic\nstates in (i) an off-resonant and (ii) a resonant coupled quantum systems",
        "authors": [
            "Hira Asif",
            "Ramazan Sahin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:49:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19173v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19173v1",
        "categories": [
            "Optics",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics",
            "Quantum Physics"
        ]
    },
    {
        "id": 30000085,
        "doi": null,
        "title": "Stark Control of Plexcitonic States in Incoherent Quantum Systems",
        "abstract": "Electro-optic control of quantum dots embedded in the plasmonic nanocavities\nenables active tuning of photonic devices for emerging applications in Quantum\noptics such as quantum information processing, entanglement and ultrafast\noptical switching. Here, we demonstrate the coherent control of plexcitonic\nstates in (i) an off-resonant and (ii) a resonant coupled quantum systems\nthrough optical Stark effect (OSE). We analyze a hybrid plasmon-emitter system\nwhich exhibits tunable Fano resonance, Stark induced transparency (SIT) and\nvacuum Rabi splitting due to quadratic Stark shift in the degenerate states of\nquantum emitter (QE). In addition, a resonantly coupled system shows the\nsignature of double Fano resonance due to Stark-induced splitting in a\ntwo-level QE. Our study shows that Stark tuning of plexcitons not only\nmitigates decoherence in the quantum system but it also stimulates on/off\nswitching of spontaneous photon emission in the visible regime. Such tunable\nsystems can be used to operate photonic integrated circuits (PIC) for\napplications in quantum computing and information processing.",
        "chunk-id": 2,
        "chunk": "through optical Stark effect (OSE). We analyze a hybrid plasmon-emitter system\nwhich exhibits tunable Fano resonance, Stark induced transparency (SIT) and\nvacuum Rabi splitting due to quadratic Stark shift in the degenerate states of\nquantum emitter (QE). In addition, a resonantly coupled system shows the\nsignature of double Fano resonance due to Stark-induced splitting in a",
        "authors": [
            "Hira Asif",
            "Ramazan Sahin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:49:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19173v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19173v1",
        "categories": [
            "Optics",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics",
            "Quantum Physics"
        ]
    },
    {
        "id": 30000085,
        "doi": null,
        "title": "Stark Control of Plexcitonic States in Incoherent Quantum Systems",
        "abstract": "Electro-optic control of quantum dots embedded in the plasmonic nanocavities\nenables active tuning of photonic devices for emerging applications in Quantum\noptics such as quantum information processing, entanglement and ultrafast\noptical switching. Here, we demonstrate the coherent control of plexcitonic\nstates in (i) an off-resonant and (ii) a resonant coupled quantum systems\nthrough optical Stark effect (OSE). We analyze a hybrid plasmon-emitter system\nwhich exhibits tunable Fano resonance, Stark induced transparency (SIT) and\nvacuum Rabi splitting due to quadratic Stark shift in the degenerate states of\nquantum emitter (QE). In addition, a resonantly coupled system shows the\nsignature of double Fano resonance due to Stark-induced splitting in a\ntwo-level QE. Our study shows that Stark tuning of plexcitons not only\nmitigates decoherence in the quantum system but it also stimulates on/off\nswitching of spontaneous photon emission in the visible regime. Such tunable\nsystems can be used to operate photonic integrated circuits (PIC) for\napplications in quantum computing and information processing.",
        "chunk-id": 3,
        "chunk": "two-level QE. Our study shows that Stark tuning of plexcitons not only\nmitigates decoherence in the quantum system but it also stimulates on/off\nswitching of spontaneous photon emission in the visible regime. Such tunable\nsystems can be used to operate photonic integrated circuits (PIC) for\napplications in quantum computing and information processing.",
        "authors": [
            "Hira Asif",
            "Ramazan Sahin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:49:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19173v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19173v1",
        "categories": [
            "Optics",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics",
            "Quantum Physics"
        ]
    },
    {
        "id": 30000086,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 1,
        "chunk": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000086,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 2,
        "chunk": "sentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000086,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 3,
        "chunk": "re-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000087,
        "doi": null,
        "title": "The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems",
        "abstract": "We examine how users perceive the limitations of an AI system when it\nencounters a task that it cannot perform perfectly and whether providing\nexplanations alongside its answers aids users in constructing an appropriate\nmental model of the system's capabilities and limitations. We employ a visual\nquestion answer and explanation task where we control the AI system's\nlimitations by manipulating the visual inputs: during inference, the system\neither processes full-color or grayscale images. Our goal is to determine\nwhether participants can perceive the limitations of the system. We hypothesize\nthat explanations will make limited AI capabilities more transparent to users.\nHowever, our results show that explanations do not have this effect. Instead of\nallowing users to more accurately assess the limitations of the AI system,\nexplanations generally increase users' perceptions of the system's competence -\nregardless of its actual performance.",
        "chunk-id": 1,
        "chunk": "We examine how users perceive the limitations of an AI system when it\nencounters a task that it cannot perform perfectly and whether providing\nexplanations alongside its answers aids users in constructing an appropriate\nmental model of the system's capabilities and limitations. We employ a visual\nquestion answer and explanation task where we control the AI system's",
        "authors": [
            "Judith Sieker",
            "Simeon Junker",
            "Ronja Utescher",
            "Nazia Attari",
            "Heiko Wersing",
            "Hendrik Buschmeier",
            "Sina Zarrie\u00df"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:44:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19170v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19170v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000087,
        "doi": null,
        "title": "The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems",
        "abstract": "We examine how users perceive the limitations of an AI system when it\nencounters a task that it cannot perform perfectly and whether providing\nexplanations alongside its answers aids users in constructing an appropriate\nmental model of the system's capabilities and limitations. We employ a visual\nquestion answer and explanation task where we control the AI system's\nlimitations by manipulating the visual inputs: during inference, the system\neither processes full-color or grayscale images. Our goal is to determine\nwhether participants can perceive the limitations of the system. We hypothesize\nthat explanations will make limited AI capabilities more transparent to users.\nHowever, our results show that explanations do not have this effect. Instead of\nallowing users to more accurately assess the limitations of the AI system,\nexplanations generally increase users' perceptions of the system's competence -\nregardless of its actual performance.",
        "chunk-id": 2,
        "chunk": "limitations by manipulating the visual inputs: during inference, the system\neither processes full-color or grayscale images. Our goal is to determine\nwhether participants can perceive the limitations of the system. We hypothesize\nthat explanations will make limited AI capabilities more transparent to users.",
        "authors": [
            "Judith Sieker",
            "Simeon Junker",
            "Ronja Utescher",
            "Nazia Attari",
            "Heiko Wersing",
            "Hendrik Buschmeier",
            "Sina Zarrie\u00df"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:44:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19170v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19170v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000087,
        "doi": null,
        "title": "The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems",
        "abstract": "We examine how users perceive the limitations of an AI system when it\nencounters a task that it cannot perform perfectly and whether providing\nexplanations alongside its answers aids users in constructing an appropriate\nmental model of the system's capabilities and limitations. We employ a visual\nquestion answer and explanation task where we control the AI system's\nlimitations by manipulating the visual inputs: during inference, the system\neither processes full-color or grayscale images. Our goal is to determine\nwhether participants can perceive the limitations of the system. We hypothesize\nthat explanations will make limited AI capabilities more transparent to users.\nHowever, our results show that explanations do not have this effect. Instead of\nallowing users to more accurately assess the limitations of the AI system,\nexplanations generally increase users' perceptions of the system's competence -\nregardless of its actual performance.",
        "chunk-id": 3,
        "chunk": "However, our results show that explanations do not have this effect. Instead of\nallowing users to more accurately assess the limitations of the AI system,\nexplanations generally increase users' perceptions of the system's competence -\nregardless of its actual performance.",
        "authors": [
            "Judith Sieker",
            "Simeon Junker",
            "Ronja Utescher",
            "Nazia Attari",
            "Heiko Wersing",
            "Hendrik Buschmeier",
            "Sina Zarrie\u00df"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:44:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19170v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19170v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 30000088,
        "doi": null,
        "title": "Exact Minimum Weight Spanners via Column Generation",
        "abstract": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a\nleast-weight subgraph $H\\subseteq G$ that preserves minimum distances between\nall node pairs up to a factor of $\\alpha$. There are many results on heuristics\nand approximation algorithms, including a recent investigation of their\npractical performance [20]. Exact approaches, in contrast, have long been\ndenounced as impractical: The first exact ILP (integer linear program) method\n[48] from 2004 is based on a model with exponentially many path variables,\nsolved via column generation. A second approach [2], modeling via arc-based\nmulticommodity flow, was presented in 2019. In both cases, only graphs with\n40-100 nodes were reported to be solvable.\n  In this paper, we briefly report on a theoretical comparison between these\ntwo models from a polyhedral point of view, and then concentrate on\nimprovements and engineering aspects. We evaluate their performance in a\nlarge-scale empirical study. We report that our tuned column generation\napproach, based on multicriteria shortest path computations, is able to solve\ninstances with over 16000 nodes within 13 minutes. Furthermore, now knowing\noptimal solutions for larger graphs, we are able to investigate the quality of\nthe strongest known heuristic on reasonably sized instances for the first time.",
        "chunk-id": 1,
        "chunk": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a\nleast-weight subgraph $H\\subseteq G$ that preserves minimum distances between\nall node pairs up to a factor of $\\alpha$. There are many results on heuristics\nand approximation algorithms, including a recent investigation of their\npractical performance [20]. Exact approaches, in contrast, have long been",
        "authors": [
            "Fritz B\u00f6kler",
            "Markus Chimani",
            "Henning Jasper",
            "Mirko H. Wagner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:32:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19164v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19164v1",
        "categories": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Combinatorics",
            "Graph theory (including graph drawing) in computer science, Graph algorithms (graph-theoretic aspects), Mixed integer programming",
            "Nonnumerical Algorithms and Problems, Combinatorics, Graph Theory"
        ]
    },
    {
        "id": 30000088,
        "doi": null,
        "title": "Exact Minimum Weight Spanners via Column Generation",
        "abstract": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a\nleast-weight subgraph $H\\subseteq G$ that preserves minimum distances between\nall node pairs up to a factor of $\\alpha$. There are many results on heuristics\nand approximation algorithms, including a recent investigation of their\npractical performance [20]. Exact approaches, in contrast, have long been\ndenounced as impractical: The first exact ILP (integer linear program) method\n[48] from 2004 is based on a model with exponentially many path variables,\nsolved via column generation. A second approach [2], modeling via arc-based\nmulticommodity flow, was presented in 2019. In both cases, only graphs with\n40-100 nodes were reported to be solvable.\n  In this paper, we briefly report on a theoretical comparison between these\ntwo models from a polyhedral point of view, and then concentrate on\nimprovements and engineering aspects. We evaluate their performance in a\nlarge-scale empirical study. We report that our tuned column generation\napproach, based on multicriteria shortest path computations, is able to solve\ninstances with over 16000 nodes within 13 minutes. Furthermore, now knowing\noptimal solutions for larger graphs, we are able to investigate the quality of\nthe strongest known heuristic on reasonably sized instances for the first time.",
        "chunk-id": 2,
        "chunk": "denounced as impractical: The first exact ILP (integer linear program) method\n[48] from 2004 is based on a model with exponentially many path variables,\nsolved via column generation. A second approach [2], modeling via arc-based\nmulticommodity flow, was presented in 2019. In both cases, only graphs with\n40-100 nodes were reported to be solvable.",
        "authors": [
            "Fritz B\u00f6kler",
            "Markus Chimani",
            "Henning Jasper",
            "Mirko H. Wagner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:32:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19164v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19164v1",
        "categories": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Combinatorics",
            "Graph theory (including graph drawing) in computer science, Graph algorithms (graph-theoretic aspects), Mixed integer programming",
            "Nonnumerical Algorithms and Problems, Combinatorics, Graph Theory"
        ]
    },
    {
        "id": 30000088,
        "doi": null,
        "title": "Exact Minimum Weight Spanners via Column Generation",
        "abstract": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a\nleast-weight subgraph $H\\subseteq G$ that preserves minimum distances between\nall node pairs up to a factor of $\\alpha$. There are many results on heuristics\nand approximation algorithms, including a recent investigation of their\npractical performance [20]. Exact approaches, in contrast, have long been\ndenounced as impractical: The first exact ILP (integer linear program) method\n[48] from 2004 is based on a model with exponentially many path variables,\nsolved via column generation. A second approach [2], modeling via arc-based\nmulticommodity flow, was presented in 2019. In both cases, only graphs with\n40-100 nodes were reported to be solvable.\n  In this paper, we briefly report on a theoretical comparison between these\ntwo models from a polyhedral point of view, and then concentrate on\nimprovements and engineering aspects. We evaluate their performance in a\nlarge-scale empirical study. We report that our tuned column generation\napproach, based on multicriteria shortest path computations, is able to solve\ninstances with over 16000 nodes within 13 minutes. Furthermore, now knowing\noptimal solutions for larger graphs, we are able to investigate the quality of\nthe strongest known heuristic on reasonably sized instances for the first time.",
        "chunk-id": 3,
        "chunk": "In this paper, we briefly report on a theoretical comparison between these\ntwo models from a polyhedral point of view, and then concentrate on\nimprovements and engineering aspects. We evaluate their performance in a\nlarge-scale empirical study. We report that our tuned column generation\napproach, based on multicriteria shortest path computations, is able to solve",
        "authors": [
            "Fritz B\u00f6kler",
            "Markus Chimani",
            "Henning Jasper",
            "Mirko H. Wagner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:32:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19164v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19164v1",
        "categories": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Combinatorics",
            "Graph theory (including graph drawing) in computer science, Graph algorithms (graph-theoretic aspects), Mixed integer programming",
            "Nonnumerical Algorithms and Problems, Combinatorics, Graph Theory"
        ]
    },
    {
        "id": 30000088,
        "doi": null,
        "title": "Exact Minimum Weight Spanners via Column Generation",
        "abstract": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a\nleast-weight subgraph $H\\subseteq G$ that preserves minimum distances between\nall node pairs up to a factor of $\\alpha$. There are many results on heuristics\nand approximation algorithms, including a recent investigation of their\npractical performance [20]. Exact approaches, in contrast, have long been\ndenounced as impractical: The first exact ILP (integer linear program) method\n[48] from 2004 is based on a model with exponentially many path variables,\nsolved via column generation. A second approach [2], modeling via arc-based\nmulticommodity flow, was presented in 2019. In both cases, only graphs with\n40-100 nodes were reported to be solvable.\n  In this paper, we briefly report on a theoretical comparison between these\ntwo models from a polyhedral point of view, and then concentrate on\nimprovements and engineering aspects. We evaluate their performance in a\nlarge-scale empirical study. We report that our tuned column generation\napproach, based on multicriteria shortest path computations, is able to solve\ninstances with over 16000 nodes within 13 minutes. Furthermore, now knowing\noptimal solutions for larger graphs, we are able to investigate the quality of\nthe strongest known heuristic on reasonably sized instances for the first time.",
        "chunk-id": 4,
        "chunk": "instances with over 16000 nodes within 13 minutes. Furthermore, now knowing\noptimal solutions for larger graphs, we are able to investigate the quality of\nthe strongest known heuristic on reasonably sized instances for the first time.",
        "authors": [
            "Fritz B\u00f6kler",
            "Markus Chimani",
            "Henning Jasper",
            "Mirko H. Wagner"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:32:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19164v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19164v1",
        "categories": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Combinatorics",
            "Graph theory (including graph drawing) in computer science, Graph algorithms (graph-theoretic aspects), Mixed integer programming",
            "Nonnumerical Algorithms and Problems, Combinatorics, Graph Theory"
        ]
    },
    {
        "id": 30000089,
        "doi": null,
        "title": "Single Image Estimation of Cell Migration Direction by Deep Circular Regression",
        "abstract": "In this paper we study the problem of estimating the migration direction of\ncells based on a single image. To the best of our knowledge, there is only one\nrelated work that uses a classification CNN for four classes (quadrants). This\napproach does not allow detailed directional resolution. We solve the single\nimage estimation problem using deep circular regression with special attention\nto cycle-sensitive methods. On two databases we achieve an average accuracy of\n$\\sim$17 degrees, which is a significant improvement over the previous work.",
        "chunk-id": 1,
        "chunk": "In this paper we study the problem of estimating the migration direction of\ncells based on a single image. To the best of our knowledge, there is only one\nrelated work that uses a classification CNN for four classes (quadrants). This\napproach does not allow detailed directional resolution. We solve the single",
        "authors": [
            "Lennart Bruns",
            "Lucas Lamparter",
            "Milos Galic",
            "Xiaoyi Jiang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:29:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19162v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19162v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000089,
        "doi": null,
        "title": "Single Image Estimation of Cell Migration Direction by Deep Circular Regression",
        "abstract": "In this paper we study the problem of estimating the migration direction of\ncells based on a single image. To the best of our knowledge, there is only one\nrelated work that uses a classification CNN for four classes (quadrants). This\napproach does not allow detailed directional resolution. We solve the single\nimage estimation problem using deep circular regression with special attention\nto cycle-sensitive methods. On two databases we achieve an average accuracy of\n$\\sim$17 degrees, which is a significant improvement over the previous work.",
        "chunk-id": 2,
        "chunk": "image estimation problem using deep circular regression with special attention\nto cycle-sensitive methods. On two databases we achieve an average accuracy of\n$\\sim$17 degrees, which is a significant improvement over the previous work.",
        "authors": [
            "Lennart Bruns",
            "Lucas Lamparter",
            "Milos Galic",
            "Xiaoyi Jiang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:29:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19162v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19162v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 30000090,
        "doi": null,
        "title": "Robust Classification of Dynamic Bichromatic point Sets in R2",
        "abstract": "Let $R \\cup B$ be a set of $n$ points in $\\mathbb{R}^2$, and let $k \\in\n1..n$. Our goal is to compute a line that \"best\" separates the \"red\" points $R$\nfrom the \"blue\" points $B$ with at most $k$ outliers. We present an efficient\nsemi-online dynamic data structure that can maintain whether such a separator\nexists. Furthermore, we present efficient exact and approximation algorithms\nthat compute a linear separator that is guaranteed to misclassify at most $k$,\npoints and minimizes the distance to the farthest outlier. Our exact algorithm\nruns in $O(nk + n \\log n)$ time, and our $(1+\\varepsilon)$-approximation\nalgorithm runs in $O(\\varepsilon^{-1/2}((n + k^2) \\log n))$ time. Based on our\n$(1+\\varepsilon)$-approximation algorithm we then also obtain a semi-online\ndata structure to maintain such a separator efficiently.",
        "chunk-id": 1,
        "chunk": "Let $R \\cup B$ be a set of $n$ points in $\\mathbb{R}^2$, and let $k \\in\n1..n$. Our goal is to compute a line that \"best\" separates the \"red\" points $R$\nfrom the \"blue\" points $B$ with at most $k$ outliers. We present an efficient\nsemi-online dynamic data structure that can maintain whether such a separator\nexists. Furthermore, we present efficient exact and approximation algorithms",
        "authors": [
            "Erwin Glazenburg",
            "Frank Staals",
            "Marc van Kreveld"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:29:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19161v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19161v1",
        "categories": [
            "Computational Geometry",
            "Analysis of algorithms,Approximation algorithms"
        ]
    },
    {
        "id": 30000090,
        "doi": null,
        "title": "Robust Classification of Dynamic Bichromatic point Sets in R2",
        "abstract": "Let $R \\cup B$ be a set of $n$ points in $\\mathbb{R}^2$, and let $k \\in\n1..n$. Our goal is to compute a line that \"best\" separates the \"red\" points $R$\nfrom the \"blue\" points $B$ with at most $k$ outliers. We present an efficient\nsemi-online dynamic data structure that can maintain whether such a separator\nexists. Furthermore, we present efficient exact and approximation algorithms\nthat compute a linear separator that is guaranteed to misclassify at most $k$,\npoints and minimizes the distance to the farthest outlier. Our exact algorithm\nruns in $O(nk + n \\log n)$ time, and our $(1+\\varepsilon)$-approximation\nalgorithm runs in $O(\\varepsilon^{-1/2}((n + k^2) \\log n))$ time. Based on our\n$(1+\\varepsilon)$-approximation algorithm we then also obtain a semi-online\ndata structure to maintain such a separator efficiently.",
        "chunk-id": 2,
        "chunk": "that compute a linear separator that is guaranteed to misclassify at most $k$,\npoints and minimizes the distance to the farthest outlier. Our exact algorithm\nruns in $O(nk + n \\log n)$ time, and our $(1+\\varepsilon)$-approximation\nalgorithm runs in $O(\\varepsilon^{-1/2}((n + k^2) \\log n))$ time. Based on our",
        "authors": [
            "Erwin Glazenburg",
            "Frank Staals",
            "Marc van Kreveld"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:29:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19161v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19161v1",
        "categories": [
            "Computational Geometry",
            "Analysis of algorithms,Approximation algorithms"
        ]
    },
    {
        "id": 30000090,
        "doi": null,
        "title": "Robust Classification of Dynamic Bichromatic point Sets in R2",
        "abstract": "Let $R \\cup B$ be a set of $n$ points in $\\mathbb{R}^2$, and let $k \\in\n1..n$. Our goal is to compute a line that \"best\" separates the \"red\" points $R$\nfrom the \"blue\" points $B$ with at most $k$ outliers. We present an efficient\nsemi-online dynamic data structure that can maintain whether such a separator\nexists. Furthermore, we present efficient exact and approximation algorithms\nthat compute a linear separator that is guaranteed to misclassify at most $k$,\npoints and minimizes the distance to the farthest outlier. Our exact algorithm\nruns in $O(nk + n \\log n)$ time, and our $(1+\\varepsilon)$-approximation\nalgorithm runs in $O(\\varepsilon^{-1/2}((n + k^2) \\log n))$ time. Based on our\n$(1+\\varepsilon)$-approximation algorithm we then also obtain a semi-online\ndata structure to maintain such a separator efficiently.",
        "chunk-id": 3,
        "chunk": "$(1+\\varepsilon)$-approximation algorithm we then also obtain a semi-online\ndata structure to maintain such a separator efficiently.",
        "authors": [
            "Erwin Glazenburg",
            "Frank Staals",
            "Marc van Kreveld"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:29:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19161v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19161v1",
        "categories": [
            "Computational Geometry",
            "Analysis of algorithms,Approximation algorithms"
        ]
    },
    {
        "id": 30000091,
        "doi": null,
        "title": "Gravitational waveforms from inspiral compact binaries in Hybrid metric-Palatini gravity",
        "abstract": "In this study, gravitational waveforms emitted by inspiralling compact binary\nsystems on quasicircular orbits in hybrid metric-Palatini gravity are computed\nin the lowest post-Newtonian approximation. By applying the stationary phase\napproximation, Fourier transforms of tensor polarization modes are obtained,\nand correction terms in the amplitude and phase of gravitational waves relative\nto General Relativity results are derived. Moreover, post-Einsteinian\nparameters are identified, and potential constraints on the background value of\nthe scalar field are obtained based on possible observations of the\ngravitational waves by the future ground based gravitational wave detectors.\nAdditionally, constraints on the background value of the scalar field are\nderived using updated observational data from the PSR J0737-3039 system. The\nlast rescrictions are comparable in order of magnitude to the best currently\nexisting constraints, which were derived from observational data within the\nsolar system.",
        "chunk-id": 1,
        "chunk": "In this study, gravitational waveforms emitted by inspiralling compact binary\nsystems on quasicircular orbits in hybrid metric-Palatini gravity are computed\nin the lowest post-Newtonian approximation. By applying the stationary phase\napproximation, Fourier transforms of tensor polarization modes are obtained,",
        "authors": [
            "P. I. Dyadina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:23:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19159v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19159v1",
        "categories": [
            "General Relativity and Quantum Cosmology"
        ]
    },
    {
        "id": 30000091,
        "doi": null,
        "title": "Gravitational waveforms from inspiral compact binaries in Hybrid metric-Palatini gravity",
        "abstract": "In this study, gravitational waveforms emitted by inspiralling compact binary\nsystems on quasicircular orbits in hybrid metric-Palatini gravity are computed\nin the lowest post-Newtonian approximation. By applying the stationary phase\napproximation, Fourier transforms of tensor polarization modes are obtained,\nand correction terms in the amplitude and phase of gravitational waves relative\nto General Relativity results are derived. Moreover, post-Einsteinian\nparameters are identified, and potential constraints on the background value of\nthe scalar field are obtained based on possible observations of the\ngravitational waves by the future ground based gravitational wave detectors.\nAdditionally, constraints on the background value of the scalar field are\nderived using updated observational data from the PSR J0737-3039 system. The\nlast rescrictions are comparable in order of magnitude to the best currently\nexisting constraints, which were derived from observational data within the\nsolar system.",
        "chunk-id": 2,
        "chunk": "and correction terms in the amplitude and phase of gravitational waves relative\nto General Relativity results are derived. Moreover, post-Einsteinian\nparameters are identified, and potential constraints on the background value of\nthe scalar field are obtained based on possible observations of the\ngravitational waves by the future ground based gravitational wave detectors.",
        "authors": [
            "P. I. Dyadina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:23:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19159v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19159v1",
        "categories": [
            "General Relativity and Quantum Cosmology"
        ]
    },
    {
        "id": 30000091,
        "doi": null,
        "title": "Gravitational waveforms from inspiral compact binaries in Hybrid metric-Palatini gravity",
        "abstract": "In this study, gravitational waveforms emitted by inspiralling compact binary\nsystems on quasicircular orbits in hybrid metric-Palatini gravity are computed\nin the lowest post-Newtonian approximation. By applying the stationary phase\napproximation, Fourier transforms of tensor polarization modes are obtained,\nand correction terms in the amplitude and phase of gravitational waves relative\nto General Relativity results are derived. Moreover, post-Einsteinian\nparameters are identified, and potential constraints on the background value of\nthe scalar field are obtained based on possible observations of the\ngravitational waves by the future ground based gravitational wave detectors.\nAdditionally, constraints on the background value of the scalar field are\nderived using updated observational data from the PSR J0737-3039 system. The\nlast rescrictions are comparable in order of magnitude to the best currently\nexisting constraints, which were derived from observational data within the\nsolar system.",
        "chunk-id": 3,
        "chunk": "Additionally, constraints on the background value of the scalar field are\nderived using updated observational data from the PSR J0737-3039 system. The\nlast rescrictions are comparable in order of magnitude to the best currently\nexisting constraints, which were derived from observational data within the\nsolar system.",
        "authors": [
            "P. I. Dyadina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:23:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19159v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19159v1",
        "categories": [
            "General Relativity and Quantum Cosmology"
        ]
    },
    {
        "id": 30000092,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 1,
        "chunk": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000092,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 2,
        "chunk": "triple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000092,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 3,
        "chunk": "causal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000092,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 4,
        "chunk": "experiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 30000093,
        "doi": null,
        "title": "Trivariate Bicycle Codes",
        "abstract": "Quantum error correction suppresses noise in quantum systems to allow for\nhigh-precision computations. In this work, we introduce Trivariate Bicycle\nQuantum Low-Density Parity-Check (TB-QLDPC) codes, via an extension of the\nframework developed by Bravyi et al. [Nature, 627, 778-782 (2024)]. Unlike the\nweight-6 codes proposed in their study, our approach also offers weight-4 and\nweight-5 codes, which promises to be more amenable to near-term experimental\nsetups. We show that our TB-QLDPC codes up to weight-6 have a bi-planar\nstructure. Further, most of our new codes can also be arranged in a\ntwo-dimensional toric layout, and have substantially better encoding rates than\ncomparable surface codes while offering comparable error suppression\ncapabilities. For example, we can encode 4 logical qubits with distance 5 into\n30 physical qubits with weight-5 check measurements, while a surface code with\ncomparable parameters requires 100 physical qubits. The high encoding rate and\ncompact layout make our codes highly suitable candidates for near-term hardware\nimplementations, paving the way for a realizable quantum error correction\nprotocol.",
        "chunk-id": 1,
        "chunk": "Quantum error correction suppresses noise in quantum systems to allow for\nhigh-precision computations. In this work, we introduce Trivariate Bicycle\nQuantum Low-Density Parity-Check (TB-QLDPC) codes, via an extension of the\nframework developed by Bravyi et al. [Nature, 627, 778-782 (2024)]. Unlike the\nweight-6 codes proposed in their study, our approach also offers weight-4 and",
        "authors": [
            "Lukas Voss",
            "Sim Jian Xian",
            "Tobias Haug",
            "Kishor Bharti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:10:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19151v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19151v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000093,
        "doi": null,
        "title": "Trivariate Bicycle Codes",
        "abstract": "Quantum error correction suppresses noise in quantum systems to allow for\nhigh-precision computations. In this work, we introduce Trivariate Bicycle\nQuantum Low-Density Parity-Check (TB-QLDPC) codes, via an extension of the\nframework developed by Bravyi et al. [Nature, 627, 778-782 (2024)]. Unlike the\nweight-6 codes proposed in their study, our approach also offers weight-4 and\nweight-5 codes, which promises to be more amenable to near-term experimental\nsetups. We show that our TB-QLDPC codes up to weight-6 have a bi-planar\nstructure. Further, most of our new codes can also be arranged in a\ntwo-dimensional toric layout, and have substantially better encoding rates than\ncomparable surface codes while offering comparable error suppression\ncapabilities. For example, we can encode 4 logical qubits with distance 5 into\n30 physical qubits with weight-5 check measurements, while a surface code with\ncomparable parameters requires 100 physical qubits. The high encoding rate and\ncompact layout make our codes highly suitable candidates for near-term hardware\nimplementations, paving the way for a realizable quantum error correction\nprotocol.",
        "chunk-id": 2,
        "chunk": "weight-5 codes, which promises to be more amenable to near-term experimental\nsetups. We show that our TB-QLDPC codes up to weight-6 have a bi-planar\nstructure. Further, most of our new codes can also be arranged in a\ntwo-dimensional toric layout, and have substantially better encoding rates than\ncomparable surface codes while offering comparable error suppression",
        "authors": [
            "Lukas Voss",
            "Sim Jian Xian",
            "Tobias Haug",
            "Kishor Bharti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:10:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19151v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19151v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000093,
        "doi": null,
        "title": "Trivariate Bicycle Codes",
        "abstract": "Quantum error correction suppresses noise in quantum systems to allow for\nhigh-precision computations. In this work, we introduce Trivariate Bicycle\nQuantum Low-Density Parity-Check (TB-QLDPC) codes, via an extension of the\nframework developed by Bravyi et al. [Nature, 627, 778-782 (2024)]. Unlike the\nweight-6 codes proposed in their study, our approach also offers weight-4 and\nweight-5 codes, which promises to be more amenable to near-term experimental\nsetups. We show that our TB-QLDPC codes up to weight-6 have a bi-planar\nstructure. Further, most of our new codes can also be arranged in a\ntwo-dimensional toric layout, and have substantially better encoding rates than\ncomparable surface codes while offering comparable error suppression\ncapabilities. For example, we can encode 4 logical qubits with distance 5 into\n30 physical qubits with weight-5 check measurements, while a surface code with\ncomparable parameters requires 100 physical qubits. The high encoding rate and\ncompact layout make our codes highly suitable candidates for near-term hardware\nimplementations, paving the way for a realizable quantum error correction\nprotocol.",
        "chunk-id": 3,
        "chunk": "capabilities. For example, we can encode 4 logical qubits with distance 5 into\n30 physical qubits with weight-5 check measurements, while a surface code with\ncomparable parameters requires 100 physical qubits. The high encoding rate and\ncompact layout make our codes highly suitable candidates for near-term hardware",
        "authors": [
            "Lukas Voss",
            "Sim Jian Xian",
            "Tobias Haug",
            "Kishor Bharti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:10:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19151v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19151v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000093,
        "doi": null,
        "title": "Trivariate Bicycle Codes",
        "abstract": "Quantum error correction suppresses noise in quantum systems to allow for\nhigh-precision computations. In this work, we introduce Trivariate Bicycle\nQuantum Low-Density Parity-Check (TB-QLDPC) codes, via an extension of the\nframework developed by Bravyi et al. [Nature, 627, 778-782 (2024)]. Unlike the\nweight-6 codes proposed in their study, our approach also offers weight-4 and\nweight-5 codes, which promises to be more amenable to near-term experimental\nsetups. We show that our TB-QLDPC codes up to weight-6 have a bi-planar\nstructure. Further, most of our new codes can also be arranged in a\ntwo-dimensional toric layout, and have substantially better encoding rates than\ncomparable surface codes while offering comparable error suppression\ncapabilities. For example, we can encode 4 logical qubits with distance 5 into\n30 physical qubits with weight-5 check measurements, while a surface code with\ncomparable parameters requires 100 physical qubits. The high encoding rate and\ncompact layout make our codes highly suitable candidates for near-term hardware\nimplementations, paving the way for a realizable quantum error correction\nprotocol.",
        "chunk-id": 4,
        "chunk": "implementations, paving the way for a realizable quantum error correction\nprotocol.",
        "authors": [
            "Lukas Voss",
            "Sim Jian Xian",
            "Tobias Haug",
            "Kishor Bharti"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:10:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19151v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19151v1",
        "categories": [
            "Quantum Physics"
        ]
    },
    {
        "id": 30000094,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 1,
        "chunk": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 30000094,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 2,
        "chunk": "by the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 30000094,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 3,
        "chunk": "the need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 30000094,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 4,
        "chunk": "to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 30000095,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 1,
        "chunk": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000095,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 2,
        "chunk": "and the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000095,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 3,
        "chunk": "sector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000095,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 4,
        "chunk": "out-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 30000096,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 1,
        "chunk": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 30000096,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 2,
        "chunk": "cost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 30000096,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 3,
        "chunk": "learning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 30000097,
        "doi": null,
        "title": "QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams",
        "abstract": "Estimating cardinality, i.e., the number of distinct elements, of a data\nstream is a fundamental problem in areas like databases, computer networks, and\ninformation retrieval. This study delves into a broader scenario where each\nelement carries a positive weight. Unlike traditional cardinality estimation,\nlimited research exists on weighted cardinality, with current methods requiring\nsubstantial memory and computational resources, challenging for devices with\nlimited capabilities and real-time applications like anomaly detection. To\naddress these issues, we propose QSketch, a memory-efficient sketch method for\nestimating weighted cardinality in streams. QSketch uses a quantization\ntechnique to condense continuous variables into a compact set of integer\nvariables, with each variable requiring only 8 bits, making it 8 times smaller\nthan previous methods. Furthermore, we leverage dynamic properties during\nQSketch generation to significantly enhance estimation accuracy and achieve a\nlower time complexity of $O(1)$ for updating estimations upon encountering a\nnew element. Experimental results on synthetic and real-world datasets show\nthat QSketch is approximately 30\\% more accurate and two orders of magnitude\nfaster than the state-of-the-art, using only $1/8$ of the memory.",
        "chunk-id": 1,
        "chunk": "Estimating cardinality, i.e., the number of distinct elements, of a data\nstream is a fundamental problem in areas like databases, computer networks, and\ninformation retrieval. This study delves into a broader scenario where each\nelement carries a positive weight. Unlike traditional cardinality estimation,",
        "authors": [
            "Yiyan Qi",
            "Rundong Li",
            "Pinghui Wang",
            "Yufang Sun",
            "Rui Xing"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:55:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19143v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19143v1",
        "categories": [
            "Databases",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 30000097,
        "doi": null,
        "title": "QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams",
        "abstract": "Estimating cardinality, i.e., the number of distinct elements, of a data\nstream is a fundamental problem in areas like databases, computer networks, and\ninformation retrieval. This study delves into a broader scenario where each\nelement carries a positive weight. Unlike traditional cardinality estimation,\nlimited research exists on weighted cardinality, with current methods requiring\nsubstantial memory and computational resources, challenging for devices with\nlimited capabilities and real-time applications like anomaly detection. To\naddress these issues, we propose QSketch, a memory-efficient sketch method for\nestimating weighted cardinality in streams. QSketch uses a quantization\ntechnique to condense continuous variables into a compact set of integer\nvariables, with each variable requiring only 8 bits, making it 8 times smaller\nthan previous methods. Furthermore, we leverage dynamic properties during\nQSketch generation to significantly enhance estimation accuracy and achieve a\nlower time complexity of $O(1)$ for updating estimations upon encountering a\nnew element. Experimental results on synthetic and real-world datasets show\nthat QSketch is approximately 30\\% more accurate and two orders of magnitude\nfaster than the state-of-the-art, using only $1/8$ of the memory.",
        "chunk-id": 2,
        "chunk": "limited research exists on weighted cardinality, with current methods requiring\nsubstantial memory and computational resources, challenging for devices with\nlimited capabilities and real-time applications like anomaly detection. To\naddress these issues, we propose QSketch, a memory-efficient sketch method for\nestimating weighted cardinality in streams. QSketch uses a quantization",
        "authors": [
            "Yiyan Qi",
            "Rundong Li",
            "Pinghui Wang",
            "Yufang Sun",
            "Rui Xing"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:55:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19143v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19143v1",
        "categories": [
            "Databases",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 30000097,
        "doi": null,
        "title": "QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams",
        "abstract": "Estimating cardinality, i.e., the number of distinct elements, of a data\nstream is a fundamental problem in areas like databases, computer networks, and\ninformation retrieval. This study delves into a broader scenario where each\nelement carries a positive weight. Unlike traditional cardinality estimation,\nlimited research exists on weighted cardinality, with current methods requiring\nsubstantial memory and computational resources, challenging for devices with\nlimited capabilities and real-time applications like anomaly detection. To\naddress these issues, we propose QSketch, a memory-efficient sketch method for\nestimating weighted cardinality in streams. QSketch uses a quantization\ntechnique to condense continuous variables into a compact set of integer\nvariables, with each variable requiring only 8 bits, making it 8 times smaller\nthan previous methods. Furthermore, we leverage dynamic properties during\nQSketch generation to significantly enhance estimation accuracy and achieve a\nlower time complexity of $O(1)$ for updating estimations upon encountering a\nnew element. Experimental results on synthetic and real-world datasets show\nthat QSketch is approximately 30\\% more accurate and two orders of magnitude\nfaster than the state-of-the-art, using only $1/8$ of the memory.",
        "chunk-id": 3,
        "chunk": "technique to condense continuous variables into a compact set of integer\nvariables, with each variable requiring only 8 bits, making it 8 times smaller\nthan previous methods. Furthermore, we leverage dynamic properties during\nQSketch generation to significantly enhance estimation accuracy and achieve a\nlower time complexity of $O(1)$ for updating estimations upon encountering a",
        "authors": [
            "Yiyan Qi",
            "Rundong Li",
            "Pinghui Wang",
            "Yufang Sun",
            "Rui Xing"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:55:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19143v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19143v1",
        "categories": [
            "Databases",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 30000097,
        "doi": null,
        "title": "QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams",
        "abstract": "Estimating cardinality, i.e., the number of distinct elements, of a data\nstream is a fundamental problem in areas like databases, computer networks, and\ninformation retrieval. This study delves into a broader scenario where each\nelement carries a positive weight. Unlike traditional cardinality estimation,\nlimited research exists on weighted cardinality, with current methods requiring\nsubstantial memory and computational resources, challenging for devices with\nlimited capabilities and real-time applications like anomaly detection. To\naddress these issues, we propose QSketch, a memory-efficient sketch method for\nestimating weighted cardinality in streams. QSketch uses a quantization\ntechnique to condense continuous variables into a compact set of integer\nvariables, with each variable requiring only 8 bits, making it 8 times smaller\nthan previous methods. Furthermore, we leverage dynamic properties during\nQSketch generation to significantly enhance estimation accuracy and achieve a\nlower time complexity of $O(1)$ for updating estimations upon encountering a\nnew element. Experimental results on synthetic and real-world datasets show\nthat QSketch is approximately 30\\% more accurate and two orders of magnitude\nfaster than the state-of-the-art, using only $1/8$ of the memory.",
        "chunk-id": 4,
        "chunk": "new element. Experimental results on synthetic and real-world datasets show\nthat QSketch is approximately 30\\% more accurate and two orders of magnitude\nfaster than the state-of-the-art, using only $1/8$ of the memory.",
        "authors": [
            "Yiyan Qi",
            "Rundong Li",
            "Pinghui Wang",
            "Yufang Sun",
            "Rui Xing"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:55:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19143v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19143v1",
        "categories": [
            "Databases",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 30000098,
        "doi": null,
        "title": "Exact confidence intervals for functions of parameters in the k-sample multinomial problem",
        "abstract": "When the target of inference is a real-valued function of probability\nparameters in the k-sample multinomial problem, variance estimation may be\nchallenging. In small samples, methods like the nonparametric bootstrap or\ndelta method may perform poorly. We propose a novel general method in this\nsetting for computing exact p-values and confidence intervals which means that\ntype I error rates are correctly bounded and confidence intervals have at least\nnominal coverage at all sample sizes. Our method is applicable to any\nreal-valued function of multinomial probabilities, accommodating an arbitrary\nnumber of samples with varying category counts. We describe the method and\nprovide an implementation of it in R, with some computational optimization to\nensure broad applicability. Simulations demonstrate our method's ability to\nmaintain correct coverage rates in settings where the nonparametric bootstrap\nfails.",
        "chunk-id": 1,
        "chunk": "When the target of inference is a real-valued function of probability\nparameters in the k-sample multinomial problem, variance estimation may be\nchallenging. In small samples, methods like the nonparametric bootstrap or\ndelta method may perform poorly. We propose a novel general method in this\nsetting for computing exact p-values and confidence intervals which means that",
        "authors": [
            "Michael C Sachs",
            "Erin E Gabriel",
            "Michael P Fay"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:48:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19141v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19141v1",
        "categories": [
            "Computation"
        ]
    },
    {
        "id": 30000098,
        "doi": null,
        "title": "Exact confidence intervals for functions of parameters in the k-sample multinomial problem",
        "abstract": "When the target of inference is a real-valued function of probability\nparameters in the k-sample multinomial problem, variance estimation may be\nchallenging. In small samples, methods like the nonparametric bootstrap or\ndelta method may perform poorly. We propose a novel general method in this\nsetting for computing exact p-values and confidence intervals which means that\ntype I error rates are correctly bounded and confidence intervals have at least\nnominal coverage at all sample sizes. Our method is applicable to any\nreal-valued function of multinomial probabilities, accommodating an arbitrary\nnumber of samples with varying category counts. We describe the method and\nprovide an implementation of it in R, with some computational optimization to\nensure broad applicability. Simulations demonstrate our method's ability to\nmaintain correct coverage rates in settings where the nonparametric bootstrap\nfails.",
        "chunk-id": 2,
        "chunk": "type I error rates are correctly bounded and confidence intervals have at least\nnominal coverage at all sample sizes. Our method is applicable to any\nreal-valued function of multinomial probabilities, accommodating an arbitrary\nnumber of samples with varying category counts. We describe the method and\nprovide an implementation of it in R, with some computational optimization to",
        "authors": [
            "Michael C Sachs",
            "Erin E Gabriel",
            "Michael P Fay"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:48:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19141v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19141v1",
        "categories": [
            "Computation"
        ]
    },
    {
        "id": 30000098,
        "doi": null,
        "title": "Exact confidence intervals for functions of parameters in the k-sample multinomial problem",
        "abstract": "When the target of inference is a real-valued function of probability\nparameters in the k-sample multinomial problem, variance estimation may be\nchallenging. In small samples, methods like the nonparametric bootstrap or\ndelta method may perform poorly. We propose a novel general method in this\nsetting for computing exact p-values and confidence intervals which means that\ntype I error rates are correctly bounded and confidence intervals have at least\nnominal coverage at all sample sizes. Our method is applicable to any\nreal-valued function of multinomial probabilities, accommodating an arbitrary\nnumber of samples with varying category counts. We describe the method and\nprovide an implementation of it in R, with some computational optimization to\nensure broad applicability. Simulations demonstrate our method's ability to\nmaintain correct coverage rates in settings where the nonparametric bootstrap\nfails.",
        "chunk-id": 3,
        "chunk": "ensure broad applicability. Simulations demonstrate our method's ability to\nmaintain correct coverage rates in settings where the nonparametric bootstrap\nfails.",
        "authors": [
            "Michael C Sachs",
            "Erin E Gabriel",
            "Michael P Fay"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:48:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19141v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19141v1",
        "categories": [
            "Computation"
        ]
    },
    {
        "id": 30000099,
        "doi": null,
        "title": "Topological Dynamics and Correspondences in Composite Exceptional Rings",
        "abstract": "The exploration of novel phases and the elucidation of correspondences\nbetween topological invariants and their intriguing properties are pivotal in\nthe realm of topological physics. Here, we investigate a complex exceptional\nstructure, termed the composite exceptional ring (CER), composed of a\nthird-order exceptional ring and multiple Weyl exceptional rings. We establish\na direct correspondence between Chern numbers and the distinctive behaviors\nexhibited by these exceptional structures. Notably, we demonstrate that band\nbraiding during quasistatic encircling processes correlates with bands\npossessing nontrivial Chern numbers, leading to triple (double) periodic\nspectra for cases with topologically nontrivial (trivial) middle bands.\nMoreover, the Chern numbers predict mode transfer behaviors during dynamical\nencircling process. We propose experimental schemes to realize CER in cold\natoms, emphasizing the critical role of Chern numbers as both a measurable\nquantity and a descriptor of the exceptional physics inherent to dissipative\nsystems. The discovery of CER opens significant avenues for expanding the scope\nof topological classifications in non-Hermitian systems, with promising\napplications in quantum computing and metrology.",
        "chunk-id": 1,
        "chunk": "The exploration of novel phases and the elucidation of correspondences\nbetween topological invariants and their intriguing properties are pivotal in\nthe realm of topological physics. Here, we investigate a complex exceptional\nstructure, termed the composite exceptional ring (CER), composed of a\nthird-order exceptional ring and multiple Weyl exceptional rings. We establish",
        "authors": [
            "Zhoutao Lei",
            "Yuangang Deng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:41:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19137v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19137v1",
        "categories": [
            "Quantum Gases"
        ]
    },
    {
        "id": 30000099,
        "doi": null,
        "title": "Topological Dynamics and Correspondences in Composite Exceptional Rings",
        "abstract": "The exploration of novel phases and the elucidation of correspondences\nbetween topological invariants and their intriguing properties are pivotal in\nthe realm of topological physics. Here, we investigate a complex exceptional\nstructure, termed the composite exceptional ring (CER), composed of a\nthird-order exceptional ring and multiple Weyl exceptional rings. We establish\na direct correspondence between Chern numbers and the distinctive behaviors\nexhibited by these exceptional structures. Notably, we demonstrate that band\nbraiding during quasistatic encircling processes correlates with bands\npossessing nontrivial Chern numbers, leading to triple (double) periodic\nspectra for cases with topologically nontrivial (trivial) middle bands.\nMoreover, the Chern numbers predict mode transfer behaviors during dynamical\nencircling process. We propose experimental schemes to realize CER in cold\natoms, emphasizing the critical role of Chern numbers as both a measurable\nquantity and a descriptor of the exceptional physics inherent to dissipative\nsystems. The discovery of CER opens significant avenues for expanding the scope\nof topological classifications in non-Hermitian systems, with promising\napplications in quantum computing and metrology.",
        "chunk-id": 2,
        "chunk": "a direct correspondence between Chern numbers and the distinctive behaviors\nexhibited by these exceptional structures. Notably, we demonstrate that band\nbraiding during quasistatic encircling processes correlates with bands\npossessing nontrivial Chern numbers, leading to triple (double) periodic\nspectra for cases with topologically nontrivial (trivial) middle bands.",
        "authors": [
            "Zhoutao Lei",
            "Yuangang Deng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:41:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19137v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19137v1",
        "categories": [
            "Quantum Gases"
        ]
    },
    {
        "id": 30000099,
        "doi": null,
        "title": "Topological Dynamics and Correspondences in Composite Exceptional Rings",
        "abstract": "The exploration of novel phases and the elucidation of correspondences\nbetween topological invariants and their intriguing properties are pivotal in\nthe realm of topological physics. Here, we investigate a complex exceptional\nstructure, termed the composite exceptional ring (CER), composed of a\nthird-order exceptional ring and multiple Weyl exceptional rings. We establish\na direct correspondence between Chern numbers and the distinctive behaviors\nexhibited by these exceptional structures. Notably, we demonstrate that band\nbraiding during quasistatic encircling processes correlates with bands\npossessing nontrivial Chern numbers, leading to triple (double) periodic\nspectra for cases with topologically nontrivial (trivial) middle bands.\nMoreover, the Chern numbers predict mode transfer behaviors during dynamical\nencircling process. We propose experimental schemes to realize CER in cold\natoms, emphasizing the critical role of Chern numbers as both a measurable\nquantity and a descriptor of the exceptional physics inherent to dissipative\nsystems. The discovery of CER opens significant avenues for expanding the scope\nof topological classifications in non-Hermitian systems, with promising\napplications in quantum computing and metrology.",
        "chunk-id": 3,
        "chunk": "Moreover, the Chern numbers predict mode transfer behaviors during dynamical\nencircling process. We propose experimental schemes to realize CER in cold\natoms, emphasizing the critical role of Chern numbers as both a measurable\nquantity and a descriptor of the exceptional physics inherent to dissipative\nsystems. The discovery of CER opens significant avenues for expanding the scope",
        "authors": [
            "Zhoutao Lei",
            "Yuangang Deng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:41:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19137v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19137v1",
        "categories": [
            "Quantum Gases"
        ]
    },
    {
        "id": 30000099,
        "doi": null,
        "title": "Topological Dynamics and Correspondences in Composite Exceptional Rings",
        "abstract": "The exploration of novel phases and the elucidation of correspondences\nbetween topological invariants and their intriguing properties are pivotal in\nthe realm of topological physics. Here, we investigate a complex exceptional\nstructure, termed the composite exceptional ring (CER), composed of a\nthird-order exceptional ring and multiple Weyl exceptional rings. We establish\na direct correspondence between Chern numbers and the distinctive behaviors\nexhibited by these exceptional structures. Notably, we demonstrate that band\nbraiding during quasistatic encircling processes correlates with bands\npossessing nontrivial Chern numbers, leading to triple (double) periodic\nspectra for cases with topologically nontrivial (trivial) middle bands.\nMoreover, the Chern numbers predict mode transfer behaviors during dynamical\nencircling process. We propose experimental schemes to realize CER in cold\natoms, emphasizing the critical role of Chern numbers as both a measurable\nquantity and a descriptor of the exceptional physics inherent to dissipative\nsystems. The discovery of CER opens significant avenues for expanding the scope\nof topological classifications in non-Hermitian systems, with promising\napplications in quantum computing and metrology.",
        "chunk-id": 4,
        "chunk": "of topological classifications in non-Hermitian systems, with promising\napplications in quantum computing and metrology.",
        "authors": [
            "Zhoutao Lei",
            "Yuangang Deng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:41:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19137v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19137v1",
        "categories": [
            "Quantum Gases"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 1,
        "chunk": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 2,
        "chunk": "information loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 3,
        "chunk": "proposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 4,
        "chunk": "price levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 1,
        "chunk": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 2,
        "chunk": "address this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 3,
        "chunk": "alignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 1,
        "chunk": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 2,
        "chunk": "relationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 3,
        "chunk": "Our benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 4,
        "chunk": "generated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 1,
        "chunk": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 2,
        "chunk": "works have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 3,
        "chunk": "often fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 4,
        "chunk": "proximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 5,
        "chunk": "learning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 6,
        "chunk": "to standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 1,
        "chunk": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 2,
        "chunk": "subsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 3,
        "chunk": "without sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 1,
        "chunk": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 2,
        "chunk": "experiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 3,
        "chunk": "features. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 1,
        "chunk": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 2,
        "chunk": "differential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 3,
        "chunk": "that can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 1,
        "chunk": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 2,
        "chunk": "tabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 3,
        "chunk": "feature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 4,
        "chunk": "range of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 5,
        "chunk": "datasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 1,
        "chunk": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 2,
        "chunk": "Component Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 3,
        "chunk": "Since the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 1,
        "chunk": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 2,
        "chunk": "manipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 3,
        "chunk": "which a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 4,
        "chunk": "model possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 5,
        "chunk": "that emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 1,
        "chunk": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 2,
        "chunk": "solution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 3,
        "chunk": "the absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 4,
        "chunk": "challenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 5,
        "chunk": "a Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 1,
        "chunk": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 2,
        "chunk": "crucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 3,
        "chunk": "MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 4,
        "chunk": "human evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 1,
        "chunk": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 2,
        "chunk": "a storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 3,
        "chunk": "problems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 4,
        "chunk": "entailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 5,
        "chunk": "a desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 1,
        "chunk": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 2,
        "chunk": "learned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 3,
        "chunk": "process, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 4,
        "chunk": "instance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 1,
        "chunk": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 2,
        "chunk": "text-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 3,
        "chunk": "rhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 1,
        "chunk": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 2,
        "chunk": "simulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 3,
        "chunk": "the art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 1,
        "chunk": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 2,
        "chunk": "simulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 3,
        "chunk": "models. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 1,
        "chunk": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 2,
        "chunk": "hard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 3,
        "chunk": "(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 4,
        "chunk": "Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 5,
        "chunk": "of tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 1,
        "chunk": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 2,
        "chunk": "climate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 3,
        "chunk": "coordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 4,
        "chunk": "ecosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 1,
        "chunk": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 2,
        "chunk": "reducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 3,
        "chunk": "compression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 4,
        "chunk": "compression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 1,
        "chunk": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 2,
        "chunk": "of the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 3,
        "chunk": "integrating batch correction directly into the clustering procedure.",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 1,
        "chunk": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 2,
        "chunk": "under the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 3,
        "chunk": "components in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 4,
        "chunk": "flexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 1,
        "chunk": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 2,
        "chunk": "demonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 3,
        "chunk": "approach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 1,
        "chunk": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 2,
        "chunk": "Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 3,
        "chunk": "Turbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 4,
        "chunk": "highlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 1,
        "chunk": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 2,
        "chunk": "application areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 3,
        "chunk": "algorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 1,
        "chunk": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 2,
        "chunk": "PubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 3,
        "chunk": "creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 4,
        "chunk": "data quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 1,
        "chunk": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 2,
        "chunk": "Models (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 3,
        "chunk": "training and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 4,
        "chunk": "setting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 1,
        "chunk": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 2,
        "chunk": "limitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 3,
        "chunk": "Additionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 4,
        "chunk": "superiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 1,
        "chunk": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 2,
        "chunk": "frameworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 3,
        "chunk": "data quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 4,
        "chunk": "Reusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 1,
        "chunk": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 2,
        "chunk": "structural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 3,
        "chunk": "SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 4,
        "chunk": "spatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 5,
        "chunk": "On 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 1,
        "chunk": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 2,
        "chunk": "significantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 3,
        "chunk": "methods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 4,
        "chunk": "the variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 5,
        "chunk": "groups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 6,
        "chunk": "during design and maintenance phases.",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 1,
        "chunk": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 2,
        "chunk": "approaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 3,
        "chunk": "compared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 1,
        "chunk": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 2,
        "chunk": "multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 3,
        "chunk": "optimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 4,
        "chunk": "scenarios. The code will be made available at https://aka.ms/autorag.",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 1,
        "chunk": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 2,
        "chunk": "observe that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 3,
        "chunk": "Transformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 4,
        "chunk": "comprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 5,
        "chunk": "different scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000034,
        "doi": null,
        "title": "Staggered Quantizers for Perfect Perceptual Quality: A Connection between Quantizers with Common Randomness and Without",
        "abstract": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,\nwe provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "chunk-id": 1,
        "chunk": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,",
        "authors": [
            "Ruida Zhou",
            "Chao Tian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:15:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19248v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19248v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000034,
        "doi": null,
        "title": "Staggered Quantizers for Perfect Perceptual Quality: A Connection between Quantizers with Common Randomness and Without",
        "abstract": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,\nwe provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "chunk-id": 2,
        "chunk": "we provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "authors": [
            "Ruida Zhou",
            "Chao Tian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:15:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19248v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19248v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 1,
        "chunk": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 2,
        "chunk": "methods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 3,
        "chunk": "Image Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 4,
        "chunk": "inter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 5,
        "chunk": "state-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 1,
        "chunk": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 2,
        "chunk": "enhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 3,
        "chunk": "information to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 4,
        "chunk": "inject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 5,
        "chunk": "achieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 1,
        "chunk": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 2,
        "chunk": "analyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 3,
        "chunk": "primary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 1,
        "chunk": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 2,
        "chunk": "and there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 3,
        "chunk": "justifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 4,
        "chunk": "well as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 1,
        "chunk": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 2,
        "chunk": "human-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 3,
        "chunk": "proprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 1,
        "chunk": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 2,
        "chunk": "systems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 3,
        "chunk": "using only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 4,
        "chunk": "We then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000041,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 1,
        "chunk": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000041,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 2,
        "chunk": "\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 2,
        "chunk": "to lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 3,
        "chunk": "with student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 4,
        "chunk": "finally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 5,
        "chunk": "thoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 6,
        "chunk": "experiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 2,
        "chunk": "propose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 3,
        "chunk": "educational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 4,
        "chunk": "multi-agent systems in virtual classroom teaching.",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 1,
        "chunk": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 2,
        "chunk": "focus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 3,
        "chunk": "are commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 4,
        "chunk": "However, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 5,
        "chunk": "act as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 1,
        "chunk": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 2,
        "chunk": "effectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 3,
        "chunk": "exhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 1,
        "chunk": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 2,
        "chunk": "machine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 3,
        "chunk": "databases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 4,
        "chunk": "detection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 1,
        "chunk": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 2,
        "chunk": "suggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 3,
        "chunk": "guarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 4,
        "chunk": "synthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 1,
        "chunk": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 2,
        "chunk": "the CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 3,
        "chunk": "(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 4,
        "chunk": "low as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 1,
        "chunk": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 2,
        "chunk": "contrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 3,
        "chunk": "a principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 4,
        "chunk": "generations and their scores.",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 1,
        "chunk": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 2,
        "chunk": "the preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 3,
        "chunk": "mathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 4,
        "chunk": "generalize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 1,
        "chunk": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 2,
        "chunk": "inadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 3,
        "chunk": "X-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 4,
        "chunk": "available annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 5,
        "chunk": "budget in applied machine learning projects.",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 1,
        "chunk": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 2,
        "chunk": "possibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 3,
        "chunk": "(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 1,
        "chunk": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 2,
        "chunk": "measurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 3,
        "chunk": "QED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 1,
        "chunk": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 2,
        "chunk": "triple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 3,
        "chunk": "causal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 4,
        "chunk": "experiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 1,
        "chunk": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 2,
        "chunk": "network (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 3,
        "chunk": "Monitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 1,
        "chunk": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 2,
        "chunk": "by the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 3,
        "chunk": "the need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 4,
        "chunk": "to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 1,
        "chunk": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 2,
        "chunk": "and the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 3,
        "chunk": "sector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 4,
        "chunk": "out-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 1,
        "chunk": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 2,
        "chunk": "cost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 3,
        "chunk": "learning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 1,
        "chunk": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 2,
        "chunk": "on Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 3,
        "chunk": "enhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 4,
        "chunk": "and 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 5,
        "chunk": "future. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 1,
        "chunk": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 2,
        "chunk": "clinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 3,
        "chunk": "supervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 4,
        "chunk": "mitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 1,
        "chunk": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 2,
        "chunk": "progressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 3,
        "chunk": "language models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 4,
        "chunk": "validate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000062,
        "doi": null,
        "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
        "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "chunk-id": 1,
        "chunk": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information",
        "authors": [
            "Hsuvas Borkakoty",
            "Luis Espinosa-Anke"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:53:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19116v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19116v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000062,
        "doi": null,
        "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
        "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "chunk-id": 2,
        "chunk": "available, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "authors": [
            "Hsuvas Borkakoty",
            "Luis Espinosa-Anke"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:53:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19116v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19116v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 1,
        "chunk": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 2,
        "chunk": "suggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 3,
        "chunk": "domain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 1,
        "chunk": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 2,
        "chunk": "dynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 3,
        "chunk": "programming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 4,
        "chunk": "and without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 1,
        "chunk": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 2,
        "chunk": "functions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 3,
        "chunk": "independent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 1,
        "chunk": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 2,
        "chunk": "in the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 3,
        "chunk": "Statement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 1,
        "chunk": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 2,
        "chunk": "theoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 3,
        "chunk": "demonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 1,
        "chunk": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 2,
        "chunk": "running average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 3,
        "chunk": "Adaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 4,
        "chunk": "running model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 1,
        "chunk": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 2,
        "chunk": "comparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 3,
        "chunk": "in-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 1,
        "chunk": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 2,
        "chunk": "covariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 3,
        "chunk": "models not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 4,
        "chunk": "ggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 1,
        "chunk": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 2,
        "chunk": "data, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 3,
        "chunk": "target images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 4,
        "chunk": "extensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 1,
        "chunk": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 2,
        "chunk": "Generation (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 3,
        "chunk": "equipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 4,
        "chunk": "numerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 5,
        "chunk": "revealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 1,
        "chunk": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 2,
        "chunk": "Poisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 3,
        "chunk": "future unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 4,
        "chunk": "proton-proton collisions.",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 1,
        "chunk": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 2,
        "chunk": "complex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 3,
        "chunk": "manner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 1,
        "chunk": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 2,
        "chunk": "generalization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 3,
        "chunk": "dataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000076,
        "doi": null,
        "title": "Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers",
        "abstract": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier\nhighlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "chunk-id": 1,
        "chunk": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier",
        "authors": [
            "Ainhize Barrainkua",
            "Paula Gordaliza",
            "Jose A. Lozano",
            "Novi Quadrianto"
        ],
        "journal_ref": "Presented at the XI Symposium of Theory and Applications of Data\n  Mining from the XX Conference of the Spanish Association for Artificial\n  Intelligence CAEPIA 2024",
        "published": "2024-06-27T10:34:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19066v1",
        "categories": [
            "Machine Learning",
            "Computers and Society",
            "Artificial intelligence, Reasoning under uncertainty",
            "General; Artificial Intelligence "
        ]
    },
    {
        "id": 10000076,
        "doi": null,
        "title": "Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers",
        "abstract": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier\nhighlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "chunk-id": 2,
        "chunk": "highlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "authors": [
            "Ainhize Barrainkua",
            "Paula Gordaliza",
            "Jose A. Lozano",
            "Novi Quadrianto"
        ],
        "journal_ref": "Presented at the XI Symposium of Theory and Applications of Data\n  Mining from the XX Conference of the Spanish Association for Artificial\n  Intelligence CAEPIA 2024",
        "published": "2024-06-27T10:34:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19066v1",
        "categories": [
            "Machine Learning",
            "Computers and Society",
            "Artificial intelligence, Reasoning under uncertainty",
            "General; Artificial Intelligence "
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 1,
        "chunk": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 2,
        "chunk": "knowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 3,
        "chunk": "over 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 4,
        "chunk": "in-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 1,
        "chunk": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 2,
        "chunk": "This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 3,
        "chunk": "Gaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 4,
        "chunk": "leads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 5,
        "chunk": "evolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 6,
        "chunk": "which facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 1,
        "chunk": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 2,
        "chunk": "segmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 3,
        "chunk": "owing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 4,
        "chunk": "reveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 5,
        "chunk": "improving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 1,
        "chunk": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 2,
        "chunk": "of end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 3,
        "chunk": "with semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 1,
        "chunk": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 2,
        "chunk": "access to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 3,
        "chunk": "approximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 4,
        "chunk": "with continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 1,
        "chunk": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 2,
        "chunk": "deployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 3,
        "chunk": "iterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 4,
        "chunk": "performance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 5,
        "chunk": "client model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 1,
        "chunk": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 2,
        "chunk": "presence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 3,
        "chunk": "a large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 4,
        "chunk": "both synthetic and real datasets with noisy data and nuisance features.",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 1,
        "chunk": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 2,
        "chunk": "required to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 3,
        "chunk": "CMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 4,
        "chunk": "knowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 5,
        "chunk": "usage, advanced method development, and fair performance evaluation.",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000085,
        "doi": null,
        "title": "On Convex Optimization with Semi-Sensitive Features",
        "abstract": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically\nin terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "chunk-id": 1,
        "chunk": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically",
        "authors": [
            "Badih Ghazi",
            "Pritish Kamath",
            "Ravi Kumar",
            "Pasin Manurangsi",
            "Raghu Meka",
            "Chiyuan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:45:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19040v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19040v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 10000085,
        "doi": null,
        "title": "On Convex Optimization with Semi-Sensitive Features",
        "abstract": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically\nin terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "chunk-id": 2,
        "chunk": "in terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "authors": [
            "Badih Ghazi",
            "Pritish Kamath",
            "Ravi Kumar",
            "Pasin Manurangsi",
            "Raghu Meka",
            "Chiyuan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:45:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19040v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19040v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 1,
        "chunk": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 2,
        "chunk": "initiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 3,
        "chunk": "graph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 4,
        "chunk": "Knowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 1,
        "chunk": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 2,
        "chunk": "often overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 3,
        "chunk": "generation, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 4,
        "chunk": "property and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 5,
        "chunk": "substantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 1,
        "chunk": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 2,
        "chunk": "developed a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 3,
        "chunk": "labelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 4,
        "chunk": "RankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 5,
        "chunk": "single-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 1,
        "chunk": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 2,
        "chunk": "with eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 3,
        "chunk": "that often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 4,
        "chunk": "the large data set upon completion of the review of this article.",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000090,
        "doi": null,
        "title": "Coded Cooperative Networks for Semi-Decentralized Federated Learning",
        "abstract": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless\ndiversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "chunk-id": 1,
        "chunk": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless",
        "authors": [
            "Shudi Weng",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19002v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000090,
        "doi": null,
        "title": "Coded Cooperative Networks for Semi-Decentralized Federated Learning",
        "abstract": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless\ndiversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "chunk-id": 2,
        "chunk": "diversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "authors": [
            "Shudi Weng",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19002v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 1,
        "chunk": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 2,
        "chunk": "techniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 3,
        "chunk": "low task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 4,
        "chunk": "method that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 1,
        "chunk": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 2,
        "chunk": "constrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 3,
        "chunk": "such a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 4,
        "chunk": "supplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 5,
        "chunk": "label learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 1,
        "chunk": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 2,
        "chunk": "typically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 3,
        "chunk": "(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 4,
        "chunk": "pseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 1,
        "chunk": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 2,
        "chunk": "the Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 3,
        "chunk": "not toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 1,
        "chunk": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 2,
        "chunk": "we study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 3,
        "chunk": "control over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 4,
        "chunk": "mine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 5,
        "chunk": "multi-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 1,
        "chunk": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 2,
        "chunk": "systems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 3,
        "chunk": "resource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 4,
        "chunk": "existing thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 5,
        "chunk": "Raptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 1,
        "chunk": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 2,
        "chunk": "propose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 3,
        "chunk": "accurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 4,
        "chunk": "adaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 1,
        "chunk": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 2,
        "chunk": "in unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 3,
        "chunk": "medical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 4,
        "chunk": "training. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 1,
        "chunk": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 2,
        "chunk": "preliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 3,
        "chunk": "contemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 4,
        "chunk": "modality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 5,
        "chunk": "graphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000000,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 1,
        "chunk": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000000,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 2,
        "chunk": "cross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000000,
        "doi": null,
        "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
        "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "chunk-id": 3,
        "chunk": "among public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios.",
        "authors": [
            "Xiliang Zhu",
            "Shayna Gardiner",
            "Tere Rold\u00e1n",
            "David Rossouw"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:38:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19358v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19358v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000001,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 1,
        "chunk": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000001,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 2,
        "chunk": "sentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000001,
        "doi": null,
        "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
        "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However,\nthere is much less focus on studying NER datasets, compared to developing new\nNER models. In this paper, we employed three simple techniques to detect\nannotation errors in the OntoNotes 5.0 corpus for English NER, which is the\nlargest available NER corpus for English. Our techniques corrected ~10% of the\nsentences in train/dev/test data. In terms of entity mentions, we corrected the\nspan and/or type of ~8% of mentions in the dataset, while\nadding/deleting/splitting/merging a few more. These are large numbers of\nchanges, considering the size of OntoNotes. We used three NER libraries to\ntrain, evaluate and compare the models trained with the original and the\nre-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "chunk-id": 3,
        "chunk": "re-annotated datasets, which showed an average improvement of 1.23% in overall\nF-scores, with large (>10%) improvements for some of the entity types. While\nour annotation error detection methods are not exhaustive and there is some\nmanual annotation effort involved, they are largely language agnostic and can\nbe employed with other NER datasets, and other sequence labelling tasks.",
        "authors": [
            "Gabriel Bernier-Colborne",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:48:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19172v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19172v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000002,
        "doi": null,
        "title": "VideoMambaPro: A Leap Forward for Mamba in Video Understanding",
        "abstract": "Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in\nvideo analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The\ncombination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.",
        "chunk-id": 1,
        "chunk": "Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in",
        "authors": [
            "Hui Lu",
            "Albert Ali Salah",
            "Ronald Poppe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:45:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19006v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19006v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000002,
        "doi": null,
        "title": "VideoMambaPro: A Leap Forward for Mamba in Video Understanding",
        "abstract": "Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in\nvideo analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The\ncombination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.",
        "chunk-id": 2,
        "chunk": "video analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba",
        "authors": [
            "Hui Lu",
            "Albert Ali Salah",
            "Ronald Poppe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:45:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19006v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19006v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000002,
        "doi": null,
        "title": "VideoMambaPro: A Leap Forward for Mamba in Video Understanding",
        "abstract": "Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in\nvideo analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The\ncombination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.",
        "chunk-id": 3,
        "chunk": "backbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The",
        "authors": [
            "Hui Lu",
            "Albert Ali Salah",
            "Ronald Poppe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:45:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19006v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19006v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000002,
        "doi": null,
        "title": "VideoMambaPro: A Leap Forward for Mamba in Video Understanding",
        "abstract": "Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in\nvideo analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The\ncombination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.",
        "chunk-id": 4,
        "chunk": "combination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.",
        "authors": [
            "Hui Lu",
            "Albert Ali Salah",
            "Ronald Poppe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:45:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19006v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19006v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000003,
        "doi": null,
        "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
        "abstract": "Large language models (LLMs) can now generate and recognize text in a wide\nrange of styles and genres, including highly specialized, creative genres like\npoetry. But what do LLMs really know about poetry? What can they know about\npoetry? We develop a task to evaluate how well LLMs recognize a specific aspect\nof poetry, poetic form, for more than 20 forms and formal elements in the\nEnglish language. Poetic form captures many different poetic features,\nincluding rhyme scheme, meter, and word or line repetition. We use this task to\nreflect on LLMs' current poetic capabilities, as well as the challenges and\npitfalls of creating NLP benchmarks for poetry and for other creative tasks. In\nparticular, we use this task to audit and reflect on the poems included in\npopular pretraining datasets. Our findings have implications for NLP\nresearchers interested in model evaluation, digital humanities and cultural\nanalytics scholars, and cultural heritage professionals.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) can now generate and recognize text in a wide\nrange of styles and genres, including highly specialized, creative genres like\npoetry. But what do LLMs really know about poetry? What can they know about\npoetry? We develop a task to evaluate how well LLMs recognize a specific aspect\nof poetry, poetic form, for more than 20 forms and formal elements in the",
        "authors": [
            "Melanie Walsh",
            "Anna Preus",
            "Maria Antoniak"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:36:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18906v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18906v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000003,
        "doi": null,
        "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
        "abstract": "Large language models (LLMs) can now generate and recognize text in a wide\nrange of styles and genres, including highly specialized, creative genres like\npoetry. But what do LLMs really know about poetry? What can they know about\npoetry? We develop a task to evaluate how well LLMs recognize a specific aspect\nof poetry, poetic form, for more than 20 forms and formal elements in the\nEnglish language. Poetic form captures many different poetic features,\nincluding rhyme scheme, meter, and word or line repetition. We use this task to\nreflect on LLMs' current poetic capabilities, as well as the challenges and\npitfalls of creating NLP benchmarks for poetry and for other creative tasks. In\nparticular, we use this task to audit and reflect on the poems included in\npopular pretraining datasets. Our findings have implications for NLP\nresearchers interested in model evaluation, digital humanities and cultural\nanalytics scholars, and cultural heritage professionals.",
        "chunk-id": 2,
        "chunk": "English language. Poetic form captures many different poetic features,\nincluding rhyme scheme, meter, and word or line repetition. We use this task to\nreflect on LLMs' current poetic capabilities, as well as the challenges and\npitfalls of creating NLP benchmarks for poetry and for other creative tasks. In\nparticular, we use this task to audit and reflect on the poems included in",
        "authors": [
            "Melanie Walsh",
            "Anna Preus",
            "Maria Antoniak"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:36:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18906v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18906v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000003,
        "doi": null,
        "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
        "abstract": "Large language models (LLMs) can now generate and recognize text in a wide\nrange of styles and genres, including highly specialized, creative genres like\npoetry. But what do LLMs really know about poetry? What can they know about\npoetry? We develop a task to evaluate how well LLMs recognize a specific aspect\nof poetry, poetic form, for more than 20 forms and formal elements in the\nEnglish language. Poetic form captures many different poetic features,\nincluding rhyme scheme, meter, and word or line repetition. We use this task to\nreflect on LLMs' current poetic capabilities, as well as the challenges and\npitfalls of creating NLP benchmarks for poetry and for other creative tasks. In\nparticular, we use this task to audit and reflect on the poems included in\npopular pretraining datasets. Our findings have implications for NLP\nresearchers interested in model evaluation, digital humanities and cultural\nanalytics scholars, and cultural heritage professionals.",
        "chunk-id": 3,
        "chunk": "popular pretraining datasets. Our findings have implications for NLP\nresearchers interested in model evaluation, digital humanities and cultural\nanalytics scholars, and cultural heritage professionals.",
        "authors": [
            "Melanie Walsh",
            "Anna Preus",
            "Maria Antoniak"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:36:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18906v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18906v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000004,
        "doi": null,
        "title": "Can we teach language models to gloss endangered languages?",
        "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation\nprojects, where each morpheme is labeled with a descriptive annotation.\nAutomating the creation of interlinear glossed text can be desirable to reduce\nannotator effort and maintain consistency across annotated corpora. Prior\nresearch has explored a number of statistical and neural methods for\nautomatically producing IGT.\n  As large language models (LLMs) have showed promising results across\nmultilingual tasks, even for rare, endangered languages, it is natural to\nwonder whether they can be utilized for the task of generating IGT. We explore\nwhether LLMs can be effective at the task of interlinear glossing with\nin-context learning, without any traditional training. We propose new\napproaches for selecting examples to provide in-context, observing that\ntargeted selection can significantly improve performance. We find that\nLLM-based methods beat standard transformer baselines, despite requiring no\ntraining at all. These approaches still underperform state-of-the-art\nsupervised systems for the task, but are highly practical for researchers\noutside of the NLP community, requiring minimal effort to use.",
        "chunk-id": 1,
        "chunk": "Interlinear glossed text (IGT) is a popular format in language documentation\nprojects, where each morpheme is labeled with a descriptive annotation.\nAutomating the creation of interlinear glossed text can be desirable to reduce\nannotator effort and maintain consistency across annotated corpora. Prior\nresearch has explored a number of statistical and neural methods for",
        "authors": [
            "Michael Ginn",
            "Mans Hulden",
            "Alexis Palmer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:17:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18895v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18895v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000004,
        "doi": null,
        "title": "Can we teach language models to gloss endangered languages?",
        "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation\nprojects, where each morpheme is labeled with a descriptive annotation.\nAutomating the creation of interlinear glossed text can be desirable to reduce\nannotator effort and maintain consistency across annotated corpora. Prior\nresearch has explored a number of statistical and neural methods for\nautomatically producing IGT.\n  As large language models (LLMs) have showed promising results across\nmultilingual tasks, even for rare, endangered languages, it is natural to\nwonder whether they can be utilized for the task of generating IGT. We explore\nwhether LLMs can be effective at the task of interlinear glossing with\nin-context learning, without any traditional training. We propose new\napproaches for selecting examples to provide in-context, observing that\ntargeted selection can significantly improve performance. We find that\nLLM-based methods beat standard transformer baselines, despite requiring no\ntraining at all. These approaches still underperform state-of-the-art\nsupervised systems for the task, but are highly practical for researchers\noutside of the NLP community, requiring minimal effort to use.",
        "chunk-id": 2,
        "chunk": "automatically producing IGT.\n  As large language models (LLMs) have showed promising results across\nmultilingual tasks, even for rare, endangered languages, it is natural to\nwonder whether they can be utilized for the task of generating IGT. We explore\nwhether LLMs can be effective at the task of interlinear glossing with",
        "authors": [
            "Michael Ginn",
            "Mans Hulden",
            "Alexis Palmer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:17:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18895v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18895v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000004,
        "doi": null,
        "title": "Can we teach language models to gloss endangered languages?",
        "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation\nprojects, where each morpheme is labeled with a descriptive annotation.\nAutomating the creation of interlinear glossed text can be desirable to reduce\nannotator effort and maintain consistency across annotated corpora. Prior\nresearch has explored a number of statistical and neural methods for\nautomatically producing IGT.\n  As large language models (LLMs) have showed promising results across\nmultilingual tasks, even for rare, endangered languages, it is natural to\nwonder whether they can be utilized for the task of generating IGT. We explore\nwhether LLMs can be effective at the task of interlinear glossing with\nin-context learning, without any traditional training. We propose new\napproaches for selecting examples to provide in-context, observing that\ntargeted selection can significantly improve performance. We find that\nLLM-based methods beat standard transformer baselines, despite requiring no\ntraining at all. These approaches still underperform state-of-the-art\nsupervised systems for the task, but are highly practical for researchers\noutside of the NLP community, requiring minimal effort to use.",
        "chunk-id": 3,
        "chunk": "in-context learning, without any traditional training. We propose new\napproaches for selecting examples to provide in-context, observing that\ntargeted selection can significantly improve performance. We find that\nLLM-based methods beat standard transformer baselines, despite requiring no\ntraining at all. These approaches still underperform state-of-the-art",
        "authors": [
            "Michael Ginn",
            "Mans Hulden",
            "Alexis Palmer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:17:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18895v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18895v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000004,
        "doi": null,
        "title": "Can we teach language models to gloss endangered languages?",
        "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation\nprojects, where each morpheme is labeled with a descriptive annotation.\nAutomating the creation of interlinear glossed text can be desirable to reduce\nannotator effort and maintain consistency across annotated corpora. Prior\nresearch has explored a number of statistical and neural methods for\nautomatically producing IGT.\n  As large language models (LLMs) have showed promising results across\nmultilingual tasks, even for rare, endangered languages, it is natural to\nwonder whether they can be utilized for the task of generating IGT. We explore\nwhether LLMs can be effective at the task of interlinear glossing with\nin-context learning, without any traditional training. We propose new\napproaches for selecting examples to provide in-context, observing that\ntargeted selection can significantly improve performance. We find that\nLLM-based methods beat standard transformer baselines, despite requiring no\ntraining at all. These approaches still underperform state-of-the-art\nsupervised systems for the task, but are highly practical for researchers\noutside of the NLP community, requiring minimal effort to use.",
        "chunk-id": 4,
        "chunk": "supervised systems for the task, but are highly practical for researchers\noutside of the NLP community, requiring minimal effort to use.",
        "authors": [
            "Michael Ginn",
            "Mans Hulden",
            "Alexis Palmer"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T05:17:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18895v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18895v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000005,
        "doi": null,
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "chunk-id": 1,
        "chunk": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no",
        "authors": [
            "Vipul Rathore",
            "Aniruddha Deb",
            "Ankish Chandresh",
            "Parag Singla",
            "Mausam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T04:21:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18880v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18880v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000005,
        "doi": null,
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "chunk-id": 2,
        "chunk": "labelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.",
        "authors": [
            "Vipul Rathore",
            "Aniruddha Deb",
            "Ankish Chandresh",
            "Parag Singla",
            "Mausam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T04:21:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18880v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18880v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000005,
        "doi": null,
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "chunk-id": 3,
        "chunk": "setting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source",
        "authors": [
            "Vipul Rathore",
            "Aniruddha Deb",
            "Ankish Chandresh",
            "Parag Singla",
            "Mausam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T04:21:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18880v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18880v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000005,
        "doi": null,
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "chunk-id": 4,
        "chunk": "MRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction",
        "authors": [
            "Vipul Rathore",
            "Aniruddha Deb",
            "Ankish Chandresh",
            "Parag Singla",
            "Mausam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T04:21:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18880v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18880v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000005,
        "doi": null,
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "chunk-id": 5,
        "chunk": "confidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "authors": [
            "Vipul Rathore",
            "Aniruddha Deb",
            "Ankish Chandresh",
            "Parag Singla",
            "Mausam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T04:21:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18880v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18880v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000006,
        "doi": null,
        "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
        "abstract": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical\nfeatures and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose\nELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal\nrelations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a\nnovel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "chunk-id": 1,
        "chunk": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical",
        "authors": [
            "Jizheng Chen",
            "Kounianhua Du",
            "Jianghao Lin",
            "Bo Chen",
            "Ruiming Tang",
            "Weinan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T01:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18825v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18825v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000006,
        "doi": null,
        "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
        "abstract": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical\nfeatures and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose\nELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal\nrelations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a\nnovel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "chunk-id": 2,
        "chunk": "features and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose",
        "authors": [
            "Jizheng Chen",
            "Kounianhua Du",
            "Jianghao Lin",
            "Bo Chen",
            "Ruiming Tang",
            "Weinan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T01:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18825v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18825v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000006,
        "doi": null,
        "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
        "abstract": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical\nfeatures and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose\nELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal\nrelations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a\nnovel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "chunk-id": 3,
        "chunk": "ELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal",
        "authors": [
            "Jizheng Chen",
            "Kounianhua Du",
            "Jianghao Lin",
            "Bo Chen",
            "Ruiming Tang",
            "Weinan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T01:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18825v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18825v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000006,
        "doi": null,
        "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
        "abstract": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical\nfeatures and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose\nELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal\nrelations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a\nnovel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "chunk-id": 4,
        "chunk": "relations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a",
        "authors": [
            "Jizheng Chen",
            "Kounianhua Du",
            "Jianghao Lin",
            "Bo Chen",
            "Ruiming Tang",
            "Weinan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T01:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18825v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18825v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000006,
        "doi": null,
        "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
        "abstract": "Large language models have been flourishing in the natural language\nprocessing (NLP) domain, and their potential for recommendation has been paid\nmuch attention to. Despite the intelligence shown by the\nrecommendation-oriented finetuned models, LLMs struggle to fully understand the\nuser behavior patterns due to their innate weakness in interpreting numerical\nfeatures and the overhead for long context, where the temporal relations among\nuser behaviors, subtle quantitative signals among different ratings, and\nvarious side features of items are not well explored. Existing works only\nfine-tune a sole LLM on given text data without introducing that important\ninformation to it, leaving these problems unsolved. In this paper, we propose\nELCoRec to Enhance Language understanding with CoPropagation of numerical and\ncategorical features for Recommendation. Concretely, we propose to inject the\npreference understanding capability into LLM via a GAT expert model where the\nuser preference is better encoded by parallelly propagating the temporal\nrelations, and rating signals as well as various side information of historical\nitems. The parallel propagation mechanism could stabilize heterogeneous\nfeatures and offer an informative user preference encoding, which is then\ninjected into the language models via soft prompting at the cost of a single\ntoken embedding. To further obtain the user's recent interests, we proposed a\nnovel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "chunk-id": 5,
        "chunk": "novel Recent interaction Augmented Prompt (RAP) template. Experiment results\nover three datasets against strong baselines validate the effectiveness of\nELCoRec. The code is available at\nhttps://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.",
        "authors": [
            "Jizheng Chen",
            "Kounianhua Du",
            "Jianghao Lin",
            "Bo Chen",
            "Ruiming Tang",
            "Weinan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T01:37:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18825v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18825v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 20000007,
        "doi": null,
        "title": "Implicit Discourse Relation Classification For Nigerian Pidgin",
        "abstract": "Despite attempts to make Large Language Models multi-lingual, many of the\nworld's languages are still severely under-resourced. This widens the\nperformance gap between NLP and AI applications aimed at well-financed, and\nthose aimed at less-resourced languages. In this paper, we focus on Nigerian\nPidgin (NP), which is spoken by nearly 100 million people, but has\ncomparatively very few NLP resources and corpora. We address the task of\nImplicit Discourse Relation Classification (IDRC) and systematically compare an\napproach translating NP data to English and then using a well-resourced IDRC\ntool and back-projecting the labels versus creating a synthetic discourse\ncorpus for NP, in which we translate PDTB and project PDTB labels, and then\ntrain an NP IDR classifier. The latter approach of learning a \"native\" NP\nclassifier outperforms our baseline by 13.27\\% and 33.98\\% in f$_{1}$ score for\n4-way and 11-way classification, respectively.",
        "chunk-id": 1,
        "chunk": "Despite attempts to make Large Language Models multi-lingual, many of the\nworld's languages are still severely under-resourced. This widens the\nperformance gap between NLP and AI applications aimed at well-financed, and\nthose aimed at less-resourced languages. In this paper, we focus on Nigerian\nPidgin (NP), which is spoken by nearly 100 million people, but has",
        "authors": [
            "Muhammed Saeed",
            "Peter Bourgonje",
            "Vera Demberg"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T22:10:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18776v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18776v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000007,
        "doi": null,
        "title": "Implicit Discourse Relation Classification For Nigerian Pidgin",
        "abstract": "Despite attempts to make Large Language Models multi-lingual, many of the\nworld's languages are still severely under-resourced. This widens the\nperformance gap between NLP and AI applications aimed at well-financed, and\nthose aimed at less-resourced languages. In this paper, we focus on Nigerian\nPidgin (NP), which is spoken by nearly 100 million people, but has\ncomparatively very few NLP resources and corpora. We address the task of\nImplicit Discourse Relation Classification (IDRC) and systematically compare an\napproach translating NP data to English and then using a well-resourced IDRC\ntool and back-projecting the labels versus creating a synthetic discourse\ncorpus for NP, in which we translate PDTB and project PDTB labels, and then\ntrain an NP IDR classifier. The latter approach of learning a \"native\" NP\nclassifier outperforms our baseline by 13.27\\% and 33.98\\% in f$_{1}$ score for\n4-way and 11-way classification, respectively.",
        "chunk-id": 2,
        "chunk": "comparatively very few NLP resources and corpora. We address the task of\nImplicit Discourse Relation Classification (IDRC) and systematically compare an\napproach translating NP data to English and then using a well-resourced IDRC\ntool and back-projecting the labels versus creating a synthetic discourse\ncorpus for NP, in which we translate PDTB and project PDTB labels, and then",
        "authors": [
            "Muhammed Saeed",
            "Peter Bourgonje",
            "Vera Demberg"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T22:10:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18776v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18776v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000007,
        "doi": null,
        "title": "Implicit Discourse Relation Classification For Nigerian Pidgin",
        "abstract": "Despite attempts to make Large Language Models multi-lingual, many of the\nworld's languages are still severely under-resourced. This widens the\nperformance gap between NLP and AI applications aimed at well-financed, and\nthose aimed at less-resourced languages. In this paper, we focus on Nigerian\nPidgin (NP), which is spoken by nearly 100 million people, but has\ncomparatively very few NLP resources and corpora. We address the task of\nImplicit Discourse Relation Classification (IDRC) and systematically compare an\napproach translating NP data to English and then using a well-resourced IDRC\ntool and back-projecting the labels versus creating a synthetic discourse\ncorpus for NP, in which we translate PDTB and project PDTB labels, and then\ntrain an NP IDR classifier. The latter approach of learning a \"native\" NP\nclassifier outperforms our baseline by 13.27\\% and 33.98\\% in f$_{1}$ score for\n4-way and 11-way classification, respectively.",
        "chunk-id": 3,
        "chunk": "train an NP IDR classifier. The latter approach of learning a \"native\" NP\nclassifier outperforms our baseline by 13.27\\% and 33.98\\% in f$_{1}$ score for\n4-way and 11-way classification, respectively.",
        "authors": [
            "Muhammed Saeed",
            "Peter Bourgonje",
            "Vera Demberg"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T22:10:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18776v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18776v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000008,
        "doi": null,
        "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
        "abstract": "Large language models (LLMs) have revolutionized the field of NLP. Notably,\ntheir in-context learning capabilities also enable their use as evaluation\nmetrics for natural language generation, making them particularly advantageous\nin low-resource scenarios and time-restricted applications. In this work, we\nintroduce PrExMe, a large-scale prompt exploration for metrics, where we\nevaluate more than 720 prompt templates for open-source LLM-based metrics on\nmachine translation (MT) and summarization datasets, totalling over 6.6M\nevaluations. This extensive comparison (1) serves as a benchmark of the\nperformance of recent open-source LLMs as metrics and (2) explores the\nstability and variability of different prompting strategies. We discover that,\non the one hand, there are scenarios for which prompts are stable. For\ninstance, some LLMs show idiosyncratic preferences and favor to grade generated\ntexts with textual labels while others prefer to return numeric scores. On the\nother hand, the stability of prompts and model rankings can be susceptible to\nseemingly innocuous changes. For example, changing the requested output format\nfrom \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our\nevaluation. Our study contributes to understanding the impact of different\nprompting approaches on LLM-based metrics for MT and summarization evaluation,\nhighlighting the most stable prompting patterns and potential limitations.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have revolutionized the field of NLP. Notably,\ntheir in-context learning capabilities also enable their use as evaluation\nmetrics for natural language generation, making them particularly advantageous\nin low-resource scenarios and time-restricted applications. In this work, we\nintroduce PrExMe, a large-scale prompt exploration for metrics, where we",
        "authors": [
            "Christoph Leiter",
            "Steffen Eger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T17:56:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18528v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000008,
        "doi": null,
        "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
        "abstract": "Large language models (LLMs) have revolutionized the field of NLP. Notably,\ntheir in-context learning capabilities also enable their use as evaluation\nmetrics for natural language generation, making them particularly advantageous\nin low-resource scenarios and time-restricted applications. In this work, we\nintroduce PrExMe, a large-scale prompt exploration for metrics, where we\nevaluate more than 720 prompt templates for open-source LLM-based metrics on\nmachine translation (MT) and summarization datasets, totalling over 6.6M\nevaluations. This extensive comparison (1) serves as a benchmark of the\nperformance of recent open-source LLMs as metrics and (2) explores the\nstability and variability of different prompting strategies. We discover that,\non the one hand, there are scenarios for which prompts are stable. For\ninstance, some LLMs show idiosyncratic preferences and favor to grade generated\ntexts with textual labels while others prefer to return numeric scores. On the\nother hand, the stability of prompts and model rankings can be susceptible to\nseemingly innocuous changes. For example, changing the requested output format\nfrom \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our\nevaluation. Our study contributes to understanding the impact of different\nprompting approaches on LLM-based metrics for MT and summarization evaluation,\nhighlighting the most stable prompting patterns and potential limitations.",
        "chunk-id": 2,
        "chunk": "evaluate more than 720 prompt templates for open-source LLM-based metrics on\nmachine translation (MT) and summarization datasets, totalling over 6.6M\nevaluations. This extensive comparison (1) serves as a benchmark of the\nperformance of recent open-source LLMs as metrics and (2) explores the\nstability and variability of different prompting strategies. We discover that,",
        "authors": [
            "Christoph Leiter",
            "Steffen Eger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T17:56:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18528v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000008,
        "doi": null,
        "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
        "abstract": "Large language models (LLMs) have revolutionized the field of NLP. Notably,\ntheir in-context learning capabilities also enable their use as evaluation\nmetrics for natural language generation, making them particularly advantageous\nin low-resource scenarios and time-restricted applications. In this work, we\nintroduce PrExMe, a large-scale prompt exploration for metrics, where we\nevaluate more than 720 prompt templates for open-source LLM-based metrics on\nmachine translation (MT) and summarization datasets, totalling over 6.6M\nevaluations. This extensive comparison (1) serves as a benchmark of the\nperformance of recent open-source LLMs as metrics and (2) explores the\nstability and variability of different prompting strategies. We discover that,\non the one hand, there are scenarios for which prompts are stable. For\ninstance, some LLMs show idiosyncratic preferences and favor to grade generated\ntexts with textual labels while others prefer to return numeric scores. On the\nother hand, the stability of prompts and model rankings can be susceptible to\nseemingly innocuous changes. For example, changing the requested output format\nfrom \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our\nevaluation. Our study contributes to understanding the impact of different\nprompting approaches on LLM-based metrics for MT and summarization evaluation,\nhighlighting the most stable prompting patterns and potential limitations.",
        "chunk-id": 3,
        "chunk": "on the one hand, there are scenarios for which prompts are stable. For\ninstance, some LLMs show idiosyncratic preferences and favor to grade generated\ntexts with textual labels while others prefer to return numeric scores. On the\nother hand, the stability of prompts and model rankings can be susceptible to",
        "authors": [
            "Christoph Leiter",
            "Steffen Eger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T17:56:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18528v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000008,
        "doi": null,
        "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
        "abstract": "Large language models (LLMs) have revolutionized the field of NLP. Notably,\ntheir in-context learning capabilities also enable their use as evaluation\nmetrics for natural language generation, making them particularly advantageous\nin low-resource scenarios and time-restricted applications. In this work, we\nintroduce PrExMe, a large-scale prompt exploration for metrics, where we\nevaluate more than 720 prompt templates for open-source LLM-based metrics on\nmachine translation (MT) and summarization datasets, totalling over 6.6M\nevaluations. This extensive comparison (1) serves as a benchmark of the\nperformance of recent open-source LLMs as metrics and (2) explores the\nstability and variability of different prompting strategies. We discover that,\non the one hand, there are scenarios for which prompts are stable. For\ninstance, some LLMs show idiosyncratic preferences and favor to grade generated\ntexts with textual labels while others prefer to return numeric scores. On the\nother hand, the stability of prompts and model rankings can be susceptible to\nseemingly innocuous changes. For example, changing the requested output format\nfrom \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our\nevaluation. Our study contributes to understanding the impact of different\nprompting approaches on LLM-based metrics for MT and summarization evaluation,\nhighlighting the most stable prompting patterns and potential limitations.",
        "chunk-id": 4,
        "chunk": "seemingly innocuous changes. For example, changing the requested output format\nfrom \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our\nevaluation. Our study contributes to understanding the impact of different\nprompting approaches on LLM-based metrics for MT and summarization evaluation,\nhighlighting the most stable prompting patterns and potential limitations.",
        "authors": [
            "Christoph Leiter",
            "Steffen Eger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T17:56:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18528v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000009,
        "doi": null,
        "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
        "abstract": "There is an increasing trend towards evaluating NLP models with LLM-generated\njudgments instead of human judgments. In the absence of a comparison against\nhuman data, this raises concerns about the validity of these evaluations; in\ncase they are conducted with proprietary models, this also raises concerns over\nreproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets with\nhuman annotations, and comprehensively evaluate 11 current LLMs, covering both\nopen-weight and proprietary models, for their ability to replicate the\nannotations. Our evaluations show that each LLM exhibits a large variance\nacross datasets in its correlation to human judgments. We conclude that LLMs\nare not yet ready to systematically replace human judges in NLP.",
        "chunk-id": 1,
        "chunk": "There is an increasing trend towards evaluating NLP models with LLM-generated\njudgments instead of human judgments. In the absence of a comparison against\nhuman data, this raises concerns about the validity of these evaluations; in\ncase they are conducted with proprietary models, this also raises concerns over",
        "authors": [
            "Anna Bavaresco",
            "Raffaella Bernardi",
            "Leonardo Bertolazzi",
            "Desmond Elliott",
            "Raquel Fern\u00e1ndez",
            "Albert Gatt",
            "Esam Ghaleb",
            "Mario Giulianelli",
            "Michael Hanna",
            "Alexander Koller",
            "Andr\u00e9 F. T. Martins",
            "Philipp Mondorf",
            "Vera Neplenbroek",
            "Sandro Pezzelle",
            "Barbara Plank",
            "David Schlangen",
            "Alessandro Suglia",
            "Aditya K Surikuchi",
            "Ece Takmaz",
            "Alberto Testoni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T14:56:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18403v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18403v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000009,
        "doi": null,
        "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
        "abstract": "There is an increasing trend towards evaluating NLP models with LLM-generated\njudgments instead of human judgments. In the absence of a comparison against\nhuman data, this raises concerns about the validity of these evaluations; in\ncase they are conducted with proprietary models, this also raises concerns over\nreproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets with\nhuman annotations, and comprehensively evaluate 11 current LLMs, covering both\nopen-weight and proprietary models, for their ability to replicate the\nannotations. Our evaluations show that each LLM exhibits a large variance\nacross datasets in its correlation to human judgments. We conclude that LLMs\nare not yet ready to systematically replace human judges in NLP.",
        "chunk-id": 2,
        "chunk": "reproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets with\nhuman annotations, and comprehensively evaluate 11 current LLMs, covering both\nopen-weight and proprietary models, for their ability to replicate the\nannotations. Our evaluations show that each LLM exhibits a large variance\nacross datasets in its correlation to human judgments. We conclude that LLMs",
        "authors": [
            "Anna Bavaresco",
            "Raffaella Bernardi",
            "Leonardo Bertolazzi",
            "Desmond Elliott",
            "Raquel Fern\u00e1ndez",
            "Albert Gatt",
            "Esam Ghaleb",
            "Mario Giulianelli",
            "Michael Hanna",
            "Alexander Koller",
            "Andr\u00e9 F. T. Martins",
            "Philipp Mondorf",
            "Vera Neplenbroek",
            "Sandro Pezzelle",
            "Barbara Plank",
            "David Schlangen",
            "Alessandro Suglia",
            "Aditya K Surikuchi",
            "Ece Takmaz",
            "Alberto Testoni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T14:56:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18403v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18403v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000009,
        "doi": null,
        "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
        "abstract": "There is an increasing trend towards evaluating NLP models with LLM-generated\njudgments instead of human judgments. In the absence of a comparison against\nhuman data, this raises concerns about the validity of these evaluations; in\ncase they are conducted with proprietary models, this also raises concerns over\nreproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets with\nhuman annotations, and comprehensively evaluate 11 current LLMs, covering both\nopen-weight and proprietary models, for their ability to replicate the\nannotations. Our evaluations show that each LLM exhibits a large variance\nacross datasets in its correlation to human judgments. We conclude that LLMs\nare not yet ready to systematically replace human judges in NLP.",
        "chunk-id": 3,
        "chunk": "are not yet ready to systematically replace human judges in NLP.",
        "authors": [
            "Anna Bavaresco",
            "Raffaella Bernardi",
            "Leonardo Bertolazzi",
            "Desmond Elliott",
            "Raquel Fern\u00e1ndez",
            "Albert Gatt",
            "Esam Ghaleb",
            "Mario Giulianelli",
            "Michael Hanna",
            "Alexander Koller",
            "Andr\u00e9 F. T. Martins",
            "Philipp Mondorf",
            "Vera Neplenbroek",
            "Sandro Pezzelle",
            "Barbara Plank",
            "David Schlangen",
            "Alessandro Suglia",
            "Aditya K Surikuchi",
            "Ece Takmaz",
            "Alberto Testoni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T14:56:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18403v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18403v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000010,
        "doi": null,
        "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
        "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
        "chunk-id": 1,
        "chunk": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating",
        "authors": [
            "Simon M\u00fcnker",
            "Kai Kugler",
            "Achim Rettinger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T10:44:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18239v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000010,
        "doi": null,
        "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
        "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
        "chunk-id": 2,
        "chunk": "such annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation",
        "authors": [
            "Simon M\u00fcnker",
            "Kai Kugler",
            "Achim Rettinger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T10:44:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18239v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000010,
        "doi": null,
        "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
        "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
        "chunk-id": 3,
        "chunk": "and preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in",
        "authors": [
            "Simon M\u00fcnker",
            "Kai Kugler",
            "Achim Rettinger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T10:44:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18239v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000010,
        "doi": null,
        "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
        "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
        "chunk-id": 4,
        "chunk": "the NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
        "authors": [
            "Simon M\u00fcnker",
            "Kai Kugler",
            "Achim Rettinger"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T10:44:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18239v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18239v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 1,
        "chunk": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 2,
        "chunk": "are continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 3,
        "chunk": "abilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 4,
        "chunk": "provides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 5,
        "chunk": "interact with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000011,
        "doi": null,
        "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
        "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
        "chunk-id": 6,
        "chunk": "88.56%, 79.04%, and 82.69% respectively.",
        "authors": [
            "Ziqiu Wang",
            "Jun Liu",
            "Shengkai Zhang",
            "Yang Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T07:21:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18122v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18122v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000012,
        "doi": null,
        "title": "LLM-Driven Multimodal Opinion Expression Identification",
        "abstract": "Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to\nmirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method\nSTOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.",
        "chunk-id": 1,
        "chunk": "Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to",
        "authors": [
            "Bonian Jia",
            "Huiyao Chen",
            "Yueheng Sun",
            "Meishan Zhang",
            "Min Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T05:52:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18088v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18088v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 20000012,
        "doi": null,
        "title": "LLM-Driven Multimodal Opinion Expression Identification",
        "abstract": "Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to\nmirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method\nSTOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.",
        "chunk-id": 2,
        "chunk": "mirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method",
        "authors": [
            "Bonian Jia",
            "Huiyao Chen",
            "Yueheng Sun",
            "Meishan Zhang",
            "Min Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T05:52:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18088v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18088v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 20000012,
        "doi": null,
        "title": "LLM-Driven Multimodal Opinion Expression Identification",
        "abstract": "Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to\nmirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method\nSTOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.",
        "chunk-id": 3,
        "chunk": "STOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.",
        "authors": [
            "Bonian Jia",
            "Huiyao Chen",
            "Yueheng Sun",
            "Meishan Zhang",
            "Min Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T05:52:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18088v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18088v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 20000013,
        "doi": null,
        "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
        "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision",
        "authors": [
            "Linqing Chen",
            "Weilei Wang",
            "Zilong Bai",
            "Peng Xu",
            "Yan Fang",
            "Jie Fang",
            "Wentao Wu",
            "Lizhi Zhou",
            "Ruiji Zhang",
            "Yubin Xia",
            "Chaobo Xu",
            "Ran Hu",
            "Licong Xu",
            "Qijun Cai",
            "Haoran Hua",
            "Jing Sun",
            "Jin Liu",
            "Tian Qiu",
            "Haowen Liu",
            "Meng Hu",
            "Xiuwen Li",
            "Fei Gao",
            "Yufu Wang",
            "Lin Tie",
            "Chaochao Wang",
            "Jianping Lu",
            "Cheng Sun",
            "Yixin Wang",
            "Shengjie Yang",
            "Yuancheng Li",
            "Lu Jin",
            "Lisha Zhang",
            "Fu Bian",
            "Changyang Tu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T03:43:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18045v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18045v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000013,
        "doi": null,
        "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
        "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.",
        "chunk-id": 2,
        "chunk": "areas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on",
        "authors": [
            "Linqing Chen",
            "Weilei Wang",
            "Zilong Bai",
            "Peng Xu",
            "Yan Fang",
            "Jie Fang",
            "Wentao Wu",
            "Lizhi Zhou",
            "Ruiji Zhang",
            "Yubin Xia",
            "Chaobo Xu",
            "Ran Hu",
            "Licong Xu",
            "Qijun Cai",
            "Haoran Hua",
            "Jing Sun",
            "Jin Liu",
            "Tian Qiu",
            "Haowen Liu",
            "Meng Hu",
            "Xiuwen Li",
            "Fei Gao",
            "Yufu Wang",
            "Lin Tie",
            "Chaochao Wang",
            "Jianping Lu",
            "Cheng Sun",
            "Yixin Wang",
            "Shengjie Yang",
            "Yuancheng Li",
            "Lu Jin",
            "Lisha Zhang",
            "Fu Bian",
            "Changyang Tu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T03:43:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18045v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18045v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000013,
        "doi": null,
        "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
        "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.",
        "chunk-id": 3,
        "chunk": "key benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for",
        "authors": [
            "Linqing Chen",
            "Weilei Wang",
            "Zilong Bai",
            "Peng Xu",
            "Yan Fang",
            "Jie Fang",
            "Wentao Wu",
            "Lizhi Zhou",
            "Ruiji Zhang",
            "Yubin Xia",
            "Chaobo Xu",
            "Ran Hu",
            "Licong Xu",
            "Qijun Cai",
            "Haoran Hua",
            "Jing Sun",
            "Jin Liu",
            "Tian Qiu",
            "Haowen Liu",
            "Meng Hu",
            "Xiuwen Li",
            "Fei Gao",
            "Yufu Wang",
            "Lin Tie",
            "Chaochao Wang",
            "Jianping Lu",
            "Cheng Sun",
            "Yixin Wang",
            "Shengjie Yang",
            "Yuancheng Li",
            "Lu Jin",
            "Lisha Zhang",
            "Fu Bian",
            "Changyang Tu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T03:43:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18045v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18045v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000013,
        "doi": null,
        "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
        "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.",
        "chunk-id": 4,
        "chunk": "enhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.",
        "authors": [
            "Linqing Chen",
            "Weilei Wang",
            "Zilong Bai",
            "Peng Xu",
            "Yan Fang",
            "Jie Fang",
            "Wentao Wu",
            "Lizhi Zhou",
            "Ruiji Zhang",
            "Yubin Xia",
            "Chaobo Xu",
            "Ran Hu",
            "Licong Xu",
            "Qijun Cai",
            "Haoran Hua",
            "Jing Sun",
            "Jin Liu",
            "Tian Qiu",
            "Haowen Liu",
            "Meng Hu",
            "Xiuwen Li",
            "Fei Gao",
            "Yufu Wang",
            "Lin Tie",
            "Chaochao Wang",
            "Jianping Lu",
            "Cheng Sun",
            "Yixin Wang",
            "Shengjie Yang",
            "Yuancheng Li",
            "Lu Jin",
            "Lisha Zhang",
            "Fu Bian",
            "Changyang Tu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-26T03:43:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18045v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18045v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000014,
        "doi": null,
        "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning",
        "abstract": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.\n  This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream\napplications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training\nparadigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.",
        "authors": [
            "Shiva Kumar Pentyala",
            "Zhichao Wang",
            "Bin Bi",
            "Kiran Ramnath",
            "Xiang-Bo Mao",
            "Regunathan Radhakrishnan",
            "Sitaram Asur",
            "Na",
            "Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T20:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17923v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17923v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000014,
        "doi": null,
        "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning",
        "abstract": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.\n  This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream\napplications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training\nparadigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm.",
        "chunk-id": 2,
        "chunk": "This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream",
        "authors": [
            "Shiva Kumar Pentyala",
            "Zhichao Wang",
            "Bin Bi",
            "Kiran Ramnath",
            "Xiang-Bo Mao",
            "Regunathan Radhakrishnan",
            "Sitaram Asur",
            "Na",
            "Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T20:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17923v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17923v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000014,
        "doi": null,
        "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning",
        "abstract": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.\n  This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream\napplications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training\nparadigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm.",
        "chunk-id": 3,
        "chunk": "applications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training",
        "authors": [
            "Shiva Kumar Pentyala",
            "Zhichao Wang",
            "Bin Bi",
            "Kiran Ramnath",
            "Xiang-Bo Mao",
            "Regunathan Radhakrishnan",
            "Sitaram Asur",
            "Na",
            "Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T20:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17923v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17923v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000014,
        "doi": null,
        "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning",
        "abstract": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.\n  This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream\napplications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training\nparadigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm.",
        "chunk-id": 4,
        "chunk": "paradigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm.",
        "authors": [
            "Shiva Kumar Pentyala",
            "Zhichao Wang",
            "Bin Bi",
            "Kiran Ramnath",
            "Xiang-Bo Mao",
            "Regunathan Radhakrishnan",
            "Sitaram Asur",
            "Na",
            "Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T20:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17923v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17923v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000015,
        "doi": null,
        "title": "Cloaked Classifiers: Pseudonymization Strategies on Sensitive Classification Tasks",
        "abstract": "Protecting privacy is essential when sharing data, particularly in the case\nof an online radicalization dataset that may contain personal information. In\nthis paper, we explore the balance between preserving data usefulness and\nensuring robust privacy safeguards, since regulations like the European GDPR\nshape how personal information must be handled. We share our method for\nmanually pseudonymizing a multilingual radicalization dataset, ensuring\nperformance comparable to the original data. Furthermore, we highlight the\nimportance of establishing comprehensive guidelines for processing sensitive\nNLP data by sharing our complete pseudonymization process, our guidelines, the\nchallenges we encountered as well as the resulting dataset.",
        "chunk-id": 1,
        "chunk": "Protecting privacy is essential when sharing data, particularly in the case\nof an online radicalization dataset that may contain personal information. In\nthis paper, we explore the balance between preserving data usefulness and\nensuring robust privacy safeguards, since regulations like the European GDPR\nshape how personal information must be handled. We share our method for",
        "authors": [
            "Arij Riabi",
            "Menel Mahamdi",
            "Virginie Mouilleron",
            "Djam\u00e9 Seddah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T18:30:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17875v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17875v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000015,
        "doi": null,
        "title": "Cloaked Classifiers: Pseudonymization Strategies on Sensitive Classification Tasks",
        "abstract": "Protecting privacy is essential when sharing data, particularly in the case\nof an online radicalization dataset that may contain personal information. In\nthis paper, we explore the balance between preserving data usefulness and\nensuring robust privacy safeguards, since regulations like the European GDPR\nshape how personal information must be handled. We share our method for\nmanually pseudonymizing a multilingual radicalization dataset, ensuring\nperformance comparable to the original data. Furthermore, we highlight the\nimportance of establishing comprehensive guidelines for processing sensitive\nNLP data by sharing our complete pseudonymization process, our guidelines, the\nchallenges we encountered as well as the resulting dataset.",
        "chunk-id": 2,
        "chunk": "manually pseudonymizing a multilingual radicalization dataset, ensuring\nperformance comparable to the original data. Furthermore, we highlight the\nimportance of establishing comprehensive guidelines for processing sensitive\nNLP data by sharing our complete pseudonymization process, our guidelines, the\nchallenges we encountered as well as the resulting dataset.",
        "authors": [
            "Arij Riabi",
            "Menel Mahamdi",
            "Virginie Mouilleron",
            "Djam\u00e9 Seddah"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T18:30:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17875v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17875v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000016,
        "doi": null,
        "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
        "abstract": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference\ntasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial\nNLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only\nreached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
        "chunk-id": 1,
        "chunk": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference",
        "authors": [
            "Tin Van Huynh",
            "Kiet Van Nguyen",
            "Ngan Luu-Thuy Nguyen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T16:58:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17716v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17716v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000016,
        "doi": null,
        "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
        "abstract": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference\ntasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial\nNLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only\nreached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
        "chunk-id": 2,
        "chunk": "tasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial",
        "authors": [
            "Tin Van Huynh",
            "Kiet Van Nguyen",
            "Ngan Luu-Thuy Nguyen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T16:58:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17716v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17716v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000016,
        "doi": null,
        "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
        "abstract": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference\ntasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial\nNLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only\nreached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
        "chunk-id": 3,
        "chunk": "NLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only",
        "authors": [
            "Tin Van Huynh",
            "Kiet Van Nguyen",
            "Ngan Luu-Thuy Nguyen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T16:58:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17716v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17716v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000016,
        "doi": null,
        "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
        "abstract": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference\ntasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial\nNLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only\nreached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
        "chunk-id": 4,
        "chunk": "reached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
        "authors": [
            "Tin Van Huynh",
            "Kiet Van Nguyen",
            "Ngan Luu-Thuy Nguyen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T16:58:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17716v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17716v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000017,
        "doi": null,
        "title": "Variationist: Exploring Multifaceted Variation and Bias in Written Language Data",
        "abstract": "Exploring and understanding language data is a fundamental stage in all areas\ndealing with human language. It allows NLP practitioners to uncover quality\nconcerns and harmful biases in data before training, and helps linguists and\nsocial scientists to gain insight into language use and human behavior. Yet,\nthere is currently a lack of a unified, customizable tool to seamlessly inspect\nand visualize language variation and bias across multiple variables, language\nunits, and diverse metrics that go beyond descriptive statistics. In this\npaper, we introduce Variationist, a highly-modular, extensible, and\ntask-agnostic tool that fills this gap. Variationist handles at once a\npotentially unlimited combination of variable types and semantics across\ndiversity and association metrics with regards to the language unit of choice,\nand orchestrates the creation of up to five-dimensional interactive charts for\nover 30 variable type-semantics combinations. Through our case studies on\ncomputational dialectology, human label variation, and text generation, we show\nhow Variationist enables researchers from different disciplines to effortlessly\nanswer specific research questions or unveil undesired associations in language\ndata. A Python library, code, documentation, and tutorials are made publicly\navailable to the research community.",
        "chunk-id": 1,
        "chunk": "Exploring and understanding language data is a fundamental stage in all areas\ndealing with human language. It allows NLP practitioners to uncover quality\nconcerns and harmful biases in data before training, and helps linguists and\nsocial scientists to gain insight into language use and human behavior. Yet,",
        "authors": [
            "Alan Ramponi",
            "Camilla Casula",
            "Stefano Menini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T15:41:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17647v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17647v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000017,
        "doi": null,
        "title": "Variationist: Exploring Multifaceted Variation and Bias in Written Language Data",
        "abstract": "Exploring and understanding language data is a fundamental stage in all areas\ndealing with human language. It allows NLP practitioners to uncover quality\nconcerns and harmful biases in data before training, and helps linguists and\nsocial scientists to gain insight into language use and human behavior. Yet,\nthere is currently a lack of a unified, customizable tool to seamlessly inspect\nand visualize language variation and bias across multiple variables, language\nunits, and diverse metrics that go beyond descriptive statistics. In this\npaper, we introduce Variationist, a highly-modular, extensible, and\ntask-agnostic tool that fills this gap. Variationist handles at once a\npotentially unlimited combination of variable types and semantics across\ndiversity and association metrics with regards to the language unit of choice,\nand orchestrates the creation of up to five-dimensional interactive charts for\nover 30 variable type-semantics combinations. Through our case studies on\ncomputational dialectology, human label variation, and text generation, we show\nhow Variationist enables researchers from different disciplines to effortlessly\nanswer specific research questions or unveil undesired associations in language\ndata. A Python library, code, documentation, and tutorials are made publicly\navailable to the research community.",
        "chunk-id": 2,
        "chunk": "there is currently a lack of a unified, customizable tool to seamlessly inspect\nand visualize language variation and bias across multiple variables, language\nunits, and diverse metrics that go beyond descriptive statistics. In this\npaper, we introduce Variationist, a highly-modular, extensible, and\ntask-agnostic tool that fills this gap. Variationist handles at once a",
        "authors": [
            "Alan Ramponi",
            "Camilla Casula",
            "Stefano Menini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T15:41:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17647v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17647v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000017,
        "doi": null,
        "title": "Variationist: Exploring Multifaceted Variation and Bias in Written Language Data",
        "abstract": "Exploring and understanding language data is a fundamental stage in all areas\ndealing with human language. It allows NLP practitioners to uncover quality\nconcerns and harmful biases in data before training, and helps linguists and\nsocial scientists to gain insight into language use and human behavior. Yet,\nthere is currently a lack of a unified, customizable tool to seamlessly inspect\nand visualize language variation and bias across multiple variables, language\nunits, and diverse metrics that go beyond descriptive statistics. In this\npaper, we introduce Variationist, a highly-modular, extensible, and\ntask-agnostic tool that fills this gap. Variationist handles at once a\npotentially unlimited combination of variable types and semantics across\ndiversity and association metrics with regards to the language unit of choice,\nand orchestrates the creation of up to five-dimensional interactive charts for\nover 30 variable type-semantics combinations. Through our case studies on\ncomputational dialectology, human label variation, and text generation, we show\nhow Variationist enables researchers from different disciplines to effortlessly\nanswer specific research questions or unveil undesired associations in language\ndata. A Python library, code, documentation, and tutorials are made publicly\navailable to the research community.",
        "chunk-id": 3,
        "chunk": "potentially unlimited combination of variable types and semantics across\ndiversity and association metrics with regards to the language unit of choice,\nand orchestrates the creation of up to five-dimensional interactive charts for\nover 30 variable type-semantics combinations. Through our case studies on\ncomputational dialectology, human label variation, and text generation, we show",
        "authors": [
            "Alan Ramponi",
            "Camilla Casula",
            "Stefano Menini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T15:41:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17647v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17647v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000017,
        "doi": null,
        "title": "Variationist: Exploring Multifaceted Variation and Bias in Written Language Data",
        "abstract": "Exploring and understanding language data is a fundamental stage in all areas\ndealing with human language. It allows NLP practitioners to uncover quality\nconcerns and harmful biases in data before training, and helps linguists and\nsocial scientists to gain insight into language use and human behavior. Yet,\nthere is currently a lack of a unified, customizable tool to seamlessly inspect\nand visualize language variation and bias across multiple variables, language\nunits, and diverse metrics that go beyond descriptive statistics. In this\npaper, we introduce Variationist, a highly-modular, extensible, and\ntask-agnostic tool that fills this gap. Variationist handles at once a\npotentially unlimited combination of variable types and semantics across\ndiversity and association metrics with regards to the language unit of choice,\nand orchestrates the creation of up to five-dimensional interactive charts for\nover 30 variable type-semantics combinations. Through our case studies on\ncomputational dialectology, human label variation, and text generation, we show\nhow Variationist enables researchers from different disciplines to effortlessly\nanswer specific research questions or unveil undesired associations in language\ndata. A Python library, code, documentation, and tutorials are made publicly\navailable to the research community.",
        "chunk-id": 4,
        "chunk": "how Variationist enables researchers from different disciplines to effortlessly\nanswer specific research questions or unveil undesired associations in language\ndata. A Python library, code, documentation, and tutorials are made publicly\navailable to the research community.",
        "authors": [
            "Alan Ramponi",
            "Camilla Casula",
            "Stefano Menini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T15:41:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17647v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17647v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000018,
        "doi": null,
        "title": "LumberChunker: Long-Form Narrative Document Segmentation",
        "abstract": "Modern NLP tasks increasingly rely on dense retrieval methods to access\nup-to-date and relevant contextual information. We are motivated by the premise\nthat retrieval benefits from segments that can vary in size such that a\ncontent's semantic independence is better captured. We propose LumberChunker, a\nmethod leveraging an LLM to dynamically segment documents, which iteratively\nprompts the LLM to identify the point within a group of sequential passages\nwhere the content begins to shift. To evaluate our method, we introduce\nGutenQA, a benchmark with 3000 \"needle in a haystack\" type of question-answer\npairs derived from 100 public domain narrative books available on Project\nGutenberg. Our experiments show that LumberChunker not only outperforms the\nmost competitive baseline by 7.37% in retrieval performance (DCG@20) but also\nthat, when integrated into a RAG pipeline, LumberChunker proves to be more\neffective than other chunking methods and competitive baselines, such as the\nGemini 1.5M Pro. Our Code and Data are available at\nhttps://github.com/joaodsmarques/LumberChunker",
        "chunk-id": 1,
        "chunk": "Modern NLP tasks increasingly rely on dense retrieval methods to access\nup-to-date and relevant contextual information. We are motivated by the premise\nthat retrieval benefits from segments that can vary in size such that a\ncontent's semantic independence is better captured. We propose LumberChunker, a\nmethod leveraging an LLM to dynamically segment documents, which iteratively",
        "authors": [
            "Andr\u00e9 V. Duarte",
            "Jo\u00e3o Marques",
            "Miguel Gra\u00e7a",
            "Miguel Freire",
            "Lei Li",
            "Arlindo L. Oliveira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17526v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17526v1",
        "categories": [
            "Computation and Language",
            "Information Retrieval",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000018,
        "doi": null,
        "title": "LumberChunker: Long-Form Narrative Document Segmentation",
        "abstract": "Modern NLP tasks increasingly rely on dense retrieval methods to access\nup-to-date and relevant contextual information. We are motivated by the premise\nthat retrieval benefits from segments that can vary in size such that a\ncontent's semantic independence is better captured. We propose LumberChunker, a\nmethod leveraging an LLM to dynamically segment documents, which iteratively\nprompts the LLM to identify the point within a group of sequential passages\nwhere the content begins to shift. To evaluate our method, we introduce\nGutenQA, a benchmark with 3000 \"needle in a haystack\" type of question-answer\npairs derived from 100 public domain narrative books available on Project\nGutenberg. Our experiments show that LumberChunker not only outperforms the\nmost competitive baseline by 7.37% in retrieval performance (DCG@20) but also\nthat, when integrated into a RAG pipeline, LumberChunker proves to be more\neffective than other chunking methods and competitive baselines, such as the\nGemini 1.5M Pro. Our Code and Data are available at\nhttps://github.com/joaodsmarques/LumberChunker",
        "chunk-id": 2,
        "chunk": "prompts the LLM to identify the point within a group of sequential passages\nwhere the content begins to shift. To evaluate our method, we introduce\nGutenQA, a benchmark with 3000 \"needle in a haystack\" type of question-answer\npairs derived from 100 public domain narrative books available on Project\nGutenberg. Our experiments show that LumberChunker not only outperforms the",
        "authors": [
            "Andr\u00e9 V. Duarte",
            "Jo\u00e3o Marques",
            "Miguel Gra\u00e7a",
            "Miguel Freire",
            "Lei Li",
            "Arlindo L. Oliveira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17526v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17526v1",
        "categories": [
            "Computation and Language",
            "Information Retrieval",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000018,
        "doi": null,
        "title": "LumberChunker: Long-Form Narrative Document Segmentation",
        "abstract": "Modern NLP tasks increasingly rely on dense retrieval methods to access\nup-to-date and relevant contextual information. We are motivated by the premise\nthat retrieval benefits from segments that can vary in size such that a\ncontent's semantic independence is better captured. We propose LumberChunker, a\nmethod leveraging an LLM to dynamically segment documents, which iteratively\nprompts the LLM to identify the point within a group of sequential passages\nwhere the content begins to shift. To evaluate our method, we introduce\nGutenQA, a benchmark with 3000 \"needle in a haystack\" type of question-answer\npairs derived from 100 public domain narrative books available on Project\nGutenberg. Our experiments show that LumberChunker not only outperforms the\nmost competitive baseline by 7.37% in retrieval performance (DCG@20) but also\nthat, when integrated into a RAG pipeline, LumberChunker proves to be more\neffective than other chunking methods and competitive baselines, such as the\nGemini 1.5M Pro. Our Code and Data are available at\nhttps://github.com/joaodsmarques/LumberChunker",
        "chunk-id": 3,
        "chunk": "most competitive baseline by 7.37% in retrieval performance (DCG@20) but also\nthat, when integrated into a RAG pipeline, LumberChunker proves to be more\neffective than other chunking methods and competitive baselines, such as the\nGemini 1.5M Pro. Our Code and Data are available at\nhttps://github.com/joaodsmarques/LumberChunker",
        "authors": [
            "Andr\u00e9 V. Duarte",
            "Jo\u00e3o Marques",
            "Miguel Gra\u00e7a",
            "Miguel Freire",
            "Lei Li",
            "Arlindo L. Oliveira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17526v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17526v1",
        "categories": [
            "Computation and Language",
            "Information Retrieval",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000019,
        "doi": null,
        "title": "Leveraging LLMs for Dialogue Quality Measurement",
        "abstract": "In task-oriented conversational AI evaluation, unsupervised methods poorly\ncorrelate with human judgments, and supervised approaches lack generalization.\nRecent advances in large language models (LLMs) show robust zeroshot and\nfew-shot capabilities across NLP tasks. This paper explores using LLMs for\nautomated dialogue quality evaluation, experimenting with various\nconfigurations on public and proprietary datasets. Manipulating factors such as\nmodel size, in-context examples, and selection techniques, we examine\n\"chain-of-thought\" (CoT) reasoning and label extraction procedures. Our results\nshow that (1) larger models yield more accurate dialogue labels; (2)\nalgorithmic selection of in-context examples outperforms random selection; (3)\nCoT reasoning where an LLM is asked to provide justifications before outputting\nfinal labels improves performance; and (4) fine-tuned LLMs outperform\nout-of-the-box ones. Our results indicate that LLMs that are suitably\nfine-tuned and have sufficient reasoning capabilities can be leveraged for\nautomated dialogue evaluation.",
        "chunk-id": 1,
        "chunk": "In task-oriented conversational AI evaluation, unsupervised methods poorly\ncorrelate with human judgments, and supervised approaches lack generalization.\nRecent advances in large language models (LLMs) show robust zeroshot and\nfew-shot capabilities across NLP tasks. This paper explores using LLMs for\nautomated dialogue quality evaluation, experimenting with various",
        "authors": [
            "Jinghan Jia",
            "Abi Komma",
            "Timothy Leffel",
            "Xujun Peng",
            "Ajay Nagesh",
            "Tamer Soliman",
            "Aram Galstyan",
            "Anoop Kumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T06:19:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17304v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000019,
        "doi": null,
        "title": "Leveraging LLMs for Dialogue Quality Measurement",
        "abstract": "In task-oriented conversational AI evaluation, unsupervised methods poorly\ncorrelate with human judgments, and supervised approaches lack generalization.\nRecent advances in large language models (LLMs) show robust zeroshot and\nfew-shot capabilities across NLP tasks. This paper explores using LLMs for\nautomated dialogue quality evaluation, experimenting with various\nconfigurations on public and proprietary datasets. Manipulating factors such as\nmodel size, in-context examples, and selection techniques, we examine\n\"chain-of-thought\" (CoT) reasoning and label extraction procedures. Our results\nshow that (1) larger models yield more accurate dialogue labels; (2)\nalgorithmic selection of in-context examples outperforms random selection; (3)\nCoT reasoning where an LLM is asked to provide justifications before outputting\nfinal labels improves performance; and (4) fine-tuned LLMs outperform\nout-of-the-box ones. Our results indicate that LLMs that are suitably\nfine-tuned and have sufficient reasoning capabilities can be leveraged for\nautomated dialogue evaluation.",
        "chunk-id": 2,
        "chunk": "configurations on public and proprietary datasets. Manipulating factors such as\nmodel size, in-context examples, and selection techniques, we examine\n\"chain-of-thought\" (CoT) reasoning and label extraction procedures. Our results\nshow that (1) larger models yield more accurate dialogue labels; (2)\nalgorithmic selection of in-context examples outperforms random selection; (3)",
        "authors": [
            "Jinghan Jia",
            "Abi Komma",
            "Timothy Leffel",
            "Xujun Peng",
            "Ajay Nagesh",
            "Tamer Soliman",
            "Aram Galstyan",
            "Anoop Kumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T06:19:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17304v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000019,
        "doi": null,
        "title": "Leveraging LLMs for Dialogue Quality Measurement",
        "abstract": "In task-oriented conversational AI evaluation, unsupervised methods poorly\ncorrelate with human judgments, and supervised approaches lack generalization.\nRecent advances in large language models (LLMs) show robust zeroshot and\nfew-shot capabilities across NLP tasks. This paper explores using LLMs for\nautomated dialogue quality evaluation, experimenting with various\nconfigurations on public and proprietary datasets. Manipulating factors such as\nmodel size, in-context examples, and selection techniques, we examine\n\"chain-of-thought\" (CoT) reasoning and label extraction procedures. Our results\nshow that (1) larger models yield more accurate dialogue labels; (2)\nalgorithmic selection of in-context examples outperforms random selection; (3)\nCoT reasoning where an LLM is asked to provide justifications before outputting\nfinal labels improves performance; and (4) fine-tuned LLMs outperform\nout-of-the-box ones. Our results indicate that LLMs that are suitably\nfine-tuned and have sufficient reasoning capabilities can be leveraged for\nautomated dialogue evaluation.",
        "chunk-id": 3,
        "chunk": "CoT reasoning where an LLM is asked to provide justifications before outputting\nfinal labels improves performance; and (4) fine-tuned LLMs outperform\nout-of-the-box ones. Our results indicate that LLMs that are suitably\nfine-tuned and have sufficient reasoning capabilities can be leveraged for\nautomated dialogue evaluation.",
        "authors": [
            "Jinghan Jia",
            "Abi Komma",
            "Timothy Leffel",
            "Xujun Peng",
            "Ajay Nagesh",
            "Tamer Soliman",
            "Aram Galstyan",
            "Anoop Kumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T06:19:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17304v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17304v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000020,
        "doi": null,
        "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
        "abstract": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce\nDynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing\ndata. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four\ndomains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to\ndynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "chunk-id": 1,
        "chunk": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce",
        "authors": [
            "Zhehao Zhang",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T04:27:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000020,
        "doi": null,
        "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
        "abstract": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce\nDynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing\ndata. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four\ndomains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to\ndynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "chunk-id": 2,
        "chunk": "Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing",
        "authors": [
            "Zhehao Zhang",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T04:27:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000020,
        "doi": null,
        "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
        "abstract": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce\nDynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing\ndata. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four\ndomains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to\ndynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "chunk-id": 3,
        "chunk": "data. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four",
        "authors": [
            "Zhehao Zhang",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T04:27:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000020,
        "doi": null,
        "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
        "abstract": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce\nDynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing\ndata. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four\ndomains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to\ndynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "chunk-id": 4,
        "chunk": "domains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to",
        "authors": [
            "Zhehao Zhang",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T04:27:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000020,
        "doi": null,
        "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
        "abstract": "The current paradigm of evaluating Large Language Models (LLMs) through\nstatic benchmarks comes with significant limitations, such as vulnerability to\ndata contamination and a lack of adaptability to the evolving capabilities of\nLLMs. Therefore, evaluation methods that can adapt and generate evaluation data\nwith controlled complexity are urgently needed. In this work, we introduce\nDynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to\ndynamically extend current benchmarks with controlled complexity and diversity.\nSpecifically, we first extract the reasoning graphs of data points in current\nbenchmarks and then perturb the reasoning graphs to generate novel testing\ndata. Such newly generated test samples can have different levels of complexity\nwhile maintaining linguistic diversity similar to the original benchmarks. We\nfurther use a code-augmented LLM to ensure the label correctness of newly\ngenerated data. We apply our DARG framework to diverse reasoning tasks in four\ndomains with 15 state-of-the-art LLMs. Experimental results show that almost\nall LLMs experience a performance decrease with increased complexity and\ncertain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit\nmore biases when being evaluated via the data generated by DARG with higher\ncomplexity levels. These observations provide useful insights into how to\ndynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "chunk-id": 5,
        "chunk": "dynamically and adaptively evaluate LLMs. The code is available at\nhttps://github.com/SALT-NLP/DARG.",
        "authors": [
            "Zhehao Zhang",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-25T04:27:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.17271v1",
        "arxiv_link": "http://arxiv.org/abs/2406.17271v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000021,
        "doi": null,
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "chunk-id": 1,
        "chunk": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual",
        "authors": [
            "Mounika Marreddy",
            "Subba Reddy Oota",
            "Venkata Charan Chinni",
            "Manish Gupta",
            "Lucie Flek"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T17:41:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16833v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16833v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000021,
        "doi": null,
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "chunk-id": 2,
        "chunk": "annotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language",
        "authors": [
            "Mounika Marreddy",
            "Subba Reddy Oota",
            "Venkata Charan Chinni",
            "Manish Gupta",
            "Lucie Flek"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T17:41:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16833v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16833v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000021,
        "doi": null,
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "chunk-id": 3,
        "chunk": "models (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which",
        "authors": [
            "Mounika Marreddy",
            "Subba Reddy Oota",
            "Venkata Charan Chinni",
            "Manish Gupta",
            "Lucie Flek"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T17:41:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16833v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16833v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000021,
        "doi": null,
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "chunk-id": 4,
        "chunk": "deals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class",
        "authors": [
            "Mounika Marreddy",
            "Subba Reddy Oota",
            "Venkata Charan Chinni",
            "Manish Gupta",
            "Lucie Flek"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T17:41:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16833v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16833v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000021,
        "doi": null,
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "chunk-id": 5,
        "chunk": "dogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "authors": [
            "Mounika Marreddy",
            "Subba Reddy Oota",
            "Venkata Charan Chinni",
            "Manish Gupta",
            "Lucie Flek"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T17:41:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16833v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16833v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000022,
        "doi": null,
        "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
        "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual",
        "chunk-id": 1,
        "chunk": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called",
        "authors": [
            "Rishabh Maheshwary",
            "Vikas Yadav",
            "Hoang Nguyen",
            "Khyati Mahajan",
            "Sathwik Tejaswi Madhusudhan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:45:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16783v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16783v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000022,
        "doi": null,
        "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
        "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual",
        "chunk-id": 2,
        "chunk": "M2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual",
        "authors": [
            "Rishabh Maheshwary",
            "Vikas Yadav",
            "Hoang Nguyen",
            "Khyati Mahajan",
            "Sathwik Tejaswi Madhusudhan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:45:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16783v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16783v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000022,
        "doi": null,
        "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
        "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual",
        "chunk-id": 3,
        "chunk": "consistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for",
        "authors": [
            "Rishabh Maheshwary",
            "Vikas Yadav",
            "Hoang Nguyen",
            "Khyati Mahajan",
            "Sathwik Tejaswi Madhusudhan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:45:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16783v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16783v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000022,
        "doi": null,
        "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
        "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual",
        "chunk-id": 4,
        "chunk": "its creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual",
        "authors": [
            "Rishabh Maheshwary",
            "Vikas Yadav",
            "Hoang Nguyen",
            "Khyati Mahajan",
            "Sathwik Tejaswi Madhusudhan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:45:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16783v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16783v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000023,
        "doi": null,
        "title": "Finding Transformer Circuits with Edge Pruning",
        "abstract": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we\nframe automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to\ncircuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its\nefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap\nsubstantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "chunk-id": 1,
        "chunk": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we",
        "authors": [
            "Adithya Bhaskar",
            "Alexander Wettig",
            "Dan Friedman",
            "Danqi Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:40:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16778v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16778v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000023,
        "doi": null,
        "title": "Finding Transformer Circuits with Edge Pruning",
        "abstract": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we\nframe automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to\ncircuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its\nefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap\nsubstantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "chunk-id": 2,
        "chunk": "frame automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to",
        "authors": [
            "Adithya Bhaskar",
            "Alexander Wettig",
            "Dan Friedman",
            "Danqi Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:40:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16778v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16778v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000023,
        "doi": null,
        "title": "Finding Transformer Circuits with Edge Pruning",
        "abstract": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we\nframe automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to\ncircuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its\nefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap\nsubstantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "chunk-id": 3,
        "chunk": "circuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its",
        "authors": [
            "Adithya Bhaskar",
            "Alexander Wettig",
            "Dan Friedman",
            "Danqi Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:40:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16778v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16778v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000023,
        "doi": null,
        "title": "Finding Transformer Circuits with Edge Pruning",
        "abstract": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we\nframe automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to\ncircuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its\nefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap\nsubstantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "chunk-id": 4,
        "chunk": "efficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap",
        "authors": [
            "Adithya Bhaskar",
            "Alexander Wettig",
            "Dan Friedman",
            "Danqi Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:40:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16778v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16778v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000023,
        "doi": null,
        "title": "Finding Transformer Circuits with Edge Pruning",
        "abstract": "The path to interpreting a language model often proceeds via analysis of\ncircuits -- sparse computational subgraphs of the model that capture specific\naspects of its behavior. Recent work has automated the task of discovering\ncircuits. Yet, these methods have practical limitations, as they rely either on\ninefficient search algorithms or inaccurate approximations. In this paper, we\nframe automated circuit discovery as an optimization problem and propose *Edge\nPruning* as an effective and scalable solution. Edge Pruning leverages\ngradient-based pruning techniques, but instead of removing neurons or\ncomponents, it prunes the \\emph{edges} between components. Our method finds\ncircuits in GPT-2 that use less than half the number of edges compared to\ncircuits found by previous methods while being equally faithful to the full\nmodel predictions on standard circuit-finding tasks. Edge Pruning is efficient\neven with as many as 100K examples, outperforming previous methods in speed and\nproducing substantially better circuits. It also perfectly recovers the\nground-truth circuits in two models compiled with Tracr. Thanks to its\nefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale\nthat prior methods operate on. We use this setting for a case study comparing\nthe mechanisms behind instruction prompting and in-context learning. We find\ntwo circuits with more than 99.96% sparsity that match the performance of the\nfull model and reveal that the mechanisms in the two settings overlap\nsubstantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "chunk-id": 5,
        "chunk": "substantially. Our case study shows that Edge Pruning is a practical and\nscalable tool for interpretability and sheds light on behaviors that only\nemerge in large models.",
        "authors": [
            "Adithya Bhaskar",
            "Alexander Wettig",
            "Dan Friedman",
            "Danqi Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:40:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16778v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16778v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000024,
        "doi": null,
        "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
        "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
        "chunk-id": 1,
        "chunk": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic",
        "authors": [
            "Zhen Huang",
            "Zengzhi Wang",
            "Shijie Xia",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:31:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16772v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16772v2",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000024,
        "doi": null,
        "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
        "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
        "chunk-id": 2,
        "chunk": "medal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and",
        "authors": [
            "Zhen Huang",
            "Zengzhi Wang",
            "Shijie Xia",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:31:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16772v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16772v2",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000024,
        "doi": null,
        "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
        "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
        "chunk-id": 3,
        "chunk": "Claude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to",
        "authors": [
            "Zhen Huang",
            "Zengzhi Wang",
            "Shijie Xia",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:31:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16772v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16772v2",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000024,
        "doi": null,
        "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
        "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
        "chunk-id": 4,
        "chunk": "continuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
        "authors": [
            "Zhen Huang",
            "Zengzhi Wang",
            "Shijie Xia",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T16:31:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16772v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16772v2",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000025,
        "doi": null,
        "title": "CLIMATELI: Evaluating Entity Linking on Climate Change Data",
        "abstract": "Climate Change (CC) is a pressing topic of global importance, attracting\nincreasing attention across research fields, from social sciences to Natural\nLanguage Processing (NLP). CC is also discussed in various settings and\ncommunication platforms, from academic publications to social media forums.\nUnderstanding who and what is mentioned in such data is a first critical step\nto gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),\nthe first manually annotated CC dataset that links 3,087 entity spans to\nWikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing\nentity linking (EL) systems on the CC topic across various genres and propose\nautomated filtering methods for CC entities. We find that the performance of EL\nmodels notably lags behind humans at both token and entity levels. Testing\nwithin the scope of retaining or excluding non-nominal and/or non-CC entities\nparticularly impacts the models' performances.",
        "chunk-id": 1,
        "chunk": "Climate Change (CC) is a pressing topic of global importance, attracting\nincreasing attention across research fields, from social sciences to Natural\nLanguage Processing (NLP). CC is also discussed in various settings and\ncommunication platforms, from academic publications to social media forums.\nUnderstanding who and what is mentioned in such data is a first critical step",
        "authors": [
            "Shijia Zhou",
            "Siyao Peng",
            "Barbara Plank"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T15:36:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16732v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16732v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000025,
        "doi": null,
        "title": "CLIMATELI: Evaluating Entity Linking on Climate Change Data",
        "abstract": "Climate Change (CC) is a pressing topic of global importance, attracting\nincreasing attention across research fields, from social sciences to Natural\nLanguage Processing (NLP). CC is also discussed in various settings and\ncommunication platforms, from academic publications to social media forums.\nUnderstanding who and what is mentioned in such data is a first critical step\nto gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),\nthe first manually annotated CC dataset that links 3,087 entity spans to\nWikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing\nentity linking (EL) systems on the CC topic across various genres and propose\nautomated filtering methods for CC entities. We find that the performance of EL\nmodels notably lags behind humans at both token and entity levels. Testing\nwithin the scope of retaining or excluding non-nominal and/or non-CC entities\nparticularly impacts the models' performances.",
        "chunk-id": 2,
        "chunk": "to gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),\nthe first manually annotated CC dataset that links 3,087 entity spans to\nWikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing\nentity linking (EL) systems on the CC topic across various genres and propose\nautomated filtering methods for CC entities. We find that the performance of EL",
        "authors": [
            "Shijia Zhou",
            "Siyao Peng",
            "Barbara Plank"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T15:36:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16732v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16732v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000025,
        "doi": null,
        "title": "CLIMATELI: Evaluating Entity Linking on Climate Change Data",
        "abstract": "Climate Change (CC) is a pressing topic of global importance, attracting\nincreasing attention across research fields, from social sciences to Natural\nLanguage Processing (NLP). CC is also discussed in various settings and\ncommunication platforms, from academic publications to social media forums.\nUnderstanding who and what is mentioned in such data is a first critical step\nto gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),\nthe first manually annotated CC dataset that links 3,087 entity spans to\nWikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing\nentity linking (EL) systems on the CC topic across various genres and propose\nautomated filtering methods for CC entities. We find that the performance of EL\nmodels notably lags behind humans at both token and entity levels. Testing\nwithin the scope of retaining or excluding non-nominal and/or non-CC entities\nparticularly impacts the models' performances.",
        "chunk-id": 3,
        "chunk": "models notably lags behind humans at both token and entity levels. Testing\nwithin the scope of retaining or excluding non-nominal and/or non-CC entities\nparticularly impacts the models' performances.",
        "authors": [
            "Shijia Zhou",
            "Siyao Peng",
            "Barbara Plank"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T15:36:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16732v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16732v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000026,
        "doi": null,
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "chunk-id": 1,
        "chunk": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves",
        "authors": [
            "Markus Frohmann",
            "Igor Sterner",
            "Ivan Vuli\u0107",
            "Benjamin Minixhofer",
            "Markus Schedl"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T14:36:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16678v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16678v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000026,
        "doi": null,
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "chunk-id": 2,
        "chunk": "all of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,",
        "authors": [
            "Markus Frohmann",
            "Igor Sterner",
            "Ivan Vuli\u0107",
            "Benjamin Minixhofer",
            "Markus Schedl"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T14:36:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16678v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16678v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000026,
        "doi": null,
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "chunk-id": 3,
        "chunk": "establishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,",
        "authors": [
            "Markus Frohmann",
            "Igor Sterner",
            "Ivan Vuli\u0107",
            "Benjamin Minixhofer",
            "Markus Schedl"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T14:36:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16678v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16678v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000026,
        "doi": null,
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "chunk-id": 4,
        "chunk": "we introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains",
        "authors": [
            "Markus Frohmann",
            "Igor Sterner",
            "Ivan Vuli\u0107",
            "Benjamin Minixhofer",
            "Markus Schedl"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T14:36:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16678v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16678v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000026,
        "doi": null,
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "chunk-id": 5,
        "chunk": "and languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
        "authors": [
            "Markus Frohmann",
            "Igor Sterner",
            "Ivan Vuli\u0107",
            "Benjamin Minixhofer",
            "Markus Schedl"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T14:36:11+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16678v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16678v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000027,
        "doi": null,
        "title": "The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation",
        "abstract": "Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of a smaller model in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model\ninitialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our finding shows that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation\nprocess itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.",
        "chunk-id": 1,
        "chunk": "Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of a smaller model in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model",
        "authors": [
            "Haryo Akbarianto Wibowo",
            "Thamar Solorio",
            "Alham Fikri Aji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T10:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16524v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16524v1",
        "categories": [
            "Computation and Language",
            "Natural language processing"
        ]
    },
    {
        "id": 20000027,
        "doi": null,
        "title": "The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation",
        "abstract": "Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of a smaller model in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model\ninitialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our finding shows that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation\nprocess itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.",
        "chunk-id": 2,
        "chunk": "initialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our finding shows that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation",
        "authors": [
            "Haryo Akbarianto Wibowo",
            "Thamar Solorio",
            "Alham Fikri Aji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T10:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16524v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16524v1",
        "categories": [
            "Computation and Language",
            "Natural language processing"
        ]
    },
    {
        "id": 20000027,
        "doi": null,
        "title": "The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation",
        "abstract": "Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of a smaller model in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model\ninitialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our finding shows that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation\nprocess itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.",
        "chunk-id": 3,
        "chunk": "process itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.",
        "authors": [
            "Haryo Akbarianto Wibowo",
            "Thamar Solorio",
            "Alham Fikri Aji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T10:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16524v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16524v1",
        "categories": [
            "Computation and Language",
            "Natural language processing"
        ]
    },
    {
        "id": 20000028,
        "doi": null,
        "title": "Deepfake tweets automatic detection",
        "abstract": "This study addresses the critical challenge of detecting DeepFake tweets by\nleveraging advanced natural language processing (NLP) techniques to distinguish\nbetween genuine and AI-generated texts. Given the increasing prevalence of\nmisinformation, our research utilizes the TweepFake dataset to train and\nevaluate various machine learning models. The objective is to identify\neffective strategies for recognizing DeepFake content, thereby enhancing the\nintegrity of digital communications. By developing reliable methods for\ndetecting AI-generated misinformation, this work contributes to a more\ntrustworthy online information environment.",
        "chunk-id": 1,
        "chunk": "This study addresses the critical challenge of detecting DeepFake tweets by\nleveraging advanced natural language processing (NLP) techniques to distinguish\nbetween genuine and AI-generated texts. Given the increasing prevalence of\nmisinformation, our research utilizes the TweepFake dataset to train and\nevaluate various machine learning models. The objective is to identify",
        "authors": [
            "Adam Frej",
            "Adrian Kaminski",
            "Piotr Marciniak",
            "Szymon Szmajdzinski",
            "Soveatin Kuntur",
            "Anna Wroblewska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T09:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16489v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16489v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000028,
        "doi": null,
        "title": "Deepfake tweets automatic detection",
        "abstract": "This study addresses the critical challenge of detecting DeepFake tweets by\nleveraging advanced natural language processing (NLP) techniques to distinguish\nbetween genuine and AI-generated texts. Given the increasing prevalence of\nmisinformation, our research utilizes the TweepFake dataset to train and\nevaluate various machine learning models. The objective is to identify\neffective strategies for recognizing DeepFake content, thereby enhancing the\nintegrity of digital communications. By developing reliable methods for\ndetecting AI-generated misinformation, this work contributes to a more\ntrustworthy online information environment.",
        "chunk-id": 2,
        "chunk": "effective strategies for recognizing DeepFake content, thereby enhancing the\nintegrity of digital communications. By developing reliable methods for\ndetecting AI-generated misinformation, this work contributes to a more\ntrustworthy online information environment.",
        "authors": [
            "Adam Frej",
            "Adrian Kaminski",
            "Piotr Marciniak",
            "Szymon Szmajdzinski",
            "Soveatin Kuntur",
            "Anna Wroblewska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T09:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16489v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16489v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000029,
        "doi": null,
        "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
        "abstract": "Intermediate reasoning or acting steps have successfully improved large\nlanguage models (LLMs) for handling various downstream natural language\nprocessing (NLP) tasks. When applying LLMs for code generation, recent works\nmainly focus on directing the models to articulate intermediate\nnatural-language reasoning steps, as in chain-of-thought (CoT) prompting, and\nthen output code with the natural language or other structured intermediate\nsteps. However, such output is not suitable for code translation or generation\ntasks since the standard CoT has different logical structures and forms of\nexpression with the code. In this work, we introduce the universal code\n(UniCode) as the intermediate representation. It is a description of algorithm\nsteps using a mix of conventions of programming languages, such as assignment\noperator, conditional operator, and loop. Hence, we collect an instruction\ndataset UniCoder-Instruct to train our model UniCoder on multi-task learning\nobjectives. UniCoder-Instruct comprises natural-language questions, code\nsolutions, and the corresponding universal code. The alignment between the\nintermediate universal code representation and the final code solution\nsignificantly improves the quality of the generated code. The experimental\nresults demonstrate that UniCoder with the universal code significantly\noutperforms the previous prompting methods by a large margin, showcasing the\neffectiveness of the structural clues in pseudo-code.",
        "chunk-id": 1,
        "chunk": "Intermediate reasoning or acting steps have successfully improved large\nlanguage models (LLMs) for handling various downstream natural language\nprocessing (NLP) tasks. When applying LLMs for code generation, recent works\nmainly focus on directing the models to articulate intermediate\nnatural-language reasoning steps, as in chain-of-thought (CoT) prompting, and",
        "authors": [
            "Tao Sun",
            "Linzheng Chai",
            "Jian Yang",
            "Yuwei Yin",
            "Hongcheng Guo",
            "Jiaheng Liu",
            "Bing Wang",
            "Liqun Yang",
            "Zhoujun Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T08:32:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16441v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16441v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000029,
        "doi": null,
        "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
        "abstract": "Intermediate reasoning or acting steps have successfully improved large\nlanguage models (LLMs) for handling various downstream natural language\nprocessing (NLP) tasks. When applying LLMs for code generation, recent works\nmainly focus on directing the models to articulate intermediate\nnatural-language reasoning steps, as in chain-of-thought (CoT) prompting, and\nthen output code with the natural language or other structured intermediate\nsteps. However, such output is not suitable for code translation or generation\ntasks since the standard CoT has different logical structures and forms of\nexpression with the code. In this work, we introduce the universal code\n(UniCode) as the intermediate representation. It is a description of algorithm\nsteps using a mix of conventions of programming languages, such as assignment\noperator, conditional operator, and loop. Hence, we collect an instruction\ndataset UniCoder-Instruct to train our model UniCoder on multi-task learning\nobjectives. UniCoder-Instruct comprises natural-language questions, code\nsolutions, and the corresponding universal code. The alignment between the\nintermediate universal code representation and the final code solution\nsignificantly improves the quality of the generated code. The experimental\nresults demonstrate that UniCoder with the universal code significantly\noutperforms the previous prompting methods by a large margin, showcasing the\neffectiveness of the structural clues in pseudo-code.",
        "chunk-id": 2,
        "chunk": "then output code with the natural language or other structured intermediate\nsteps. However, such output is not suitable for code translation or generation\ntasks since the standard CoT has different logical structures and forms of\nexpression with the code. In this work, we introduce the universal code\n(UniCode) as the intermediate representation. It is a description of algorithm",
        "authors": [
            "Tao Sun",
            "Linzheng Chai",
            "Jian Yang",
            "Yuwei Yin",
            "Hongcheng Guo",
            "Jiaheng Liu",
            "Bing Wang",
            "Liqun Yang",
            "Zhoujun Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T08:32:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16441v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16441v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000029,
        "doi": null,
        "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
        "abstract": "Intermediate reasoning or acting steps have successfully improved large\nlanguage models (LLMs) for handling various downstream natural language\nprocessing (NLP) tasks. When applying LLMs for code generation, recent works\nmainly focus on directing the models to articulate intermediate\nnatural-language reasoning steps, as in chain-of-thought (CoT) prompting, and\nthen output code with the natural language or other structured intermediate\nsteps. However, such output is not suitable for code translation or generation\ntasks since the standard CoT has different logical structures and forms of\nexpression with the code. In this work, we introduce the universal code\n(UniCode) as the intermediate representation. It is a description of algorithm\nsteps using a mix of conventions of programming languages, such as assignment\noperator, conditional operator, and loop. Hence, we collect an instruction\ndataset UniCoder-Instruct to train our model UniCoder on multi-task learning\nobjectives. UniCoder-Instruct comprises natural-language questions, code\nsolutions, and the corresponding universal code. The alignment between the\nintermediate universal code representation and the final code solution\nsignificantly improves the quality of the generated code. The experimental\nresults demonstrate that UniCoder with the universal code significantly\noutperforms the previous prompting methods by a large margin, showcasing the\neffectiveness of the structural clues in pseudo-code.",
        "chunk-id": 3,
        "chunk": "steps using a mix of conventions of programming languages, such as assignment\noperator, conditional operator, and loop. Hence, we collect an instruction\ndataset UniCoder-Instruct to train our model UniCoder on multi-task learning\nobjectives. UniCoder-Instruct comprises natural-language questions, code\nsolutions, and the corresponding universal code. The alignment between the",
        "authors": [
            "Tao Sun",
            "Linzheng Chai",
            "Jian Yang",
            "Yuwei Yin",
            "Hongcheng Guo",
            "Jiaheng Liu",
            "Bing Wang",
            "Liqun Yang",
            "Zhoujun Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T08:32:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16441v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16441v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000029,
        "doi": null,
        "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
        "abstract": "Intermediate reasoning or acting steps have successfully improved large\nlanguage models (LLMs) for handling various downstream natural language\nprocessing (NLP) tasks. When applying LLMs for code generation, recent works\nmainly focus on directing the models to articulate intermediate\nnatural-language reasoning steps, as in chain-of-thought (CoT) prompting, and\nthen output code with the natural language or other structured intermediate\nsteps. However, such output is not suitable for code translation or generation\ntasks since the standard CoT has different logical structures and forms of\nexpression with the code. In this work, we introduce the universal code\n(UniCode) as the intermediate representation. It is a description of algorithm\nsteps using a mix of conventions of programming languages, such as assignment\noperator, conditional operator, and loop. Hence, we collect an instruction\ndataset UniCoder-Instruct to train our model UniCoder on multi-task learning\nobjectives. UniCoder-Instruct comprises natural-language questions, code\nsolutions, and the corresponding universal code. The alignment between the\nintermediate universal code representation and the final code solution\nsignificantly improves the quality of the generated code. The experimental\nresults demonstrate that UniCoder with the universal code significantly\noutperforms the previous prompting methods by a large margin, showcasing the\neffectiveness of the structural clues in pseudo-code.",
        "chunk-id": 4,
        "chunk": "intermediate universal code representation and the final code solution\nsignificantly improves the quality of the generated code. The experimental\nresults demonstrate that UniCoder with the universal code significantly\noutperforms the previous prompting methods by a large margin, showcasing the\neffectiveness of the structural clues in pseudo-code.",
        "authors": [
            "Tao Sun",
            "Linzheng Chai",
            "Jian Yang",
            "Yuwei Yin",
            "Hongcheng Guo",
            "Jiaheng Liu",
            "Bing Wang",
            "Liqun Yang",
            "Zhoujun Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T08:32:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16441v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16441v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000030,
        "doi": null,
        "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
        "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
        "chunk-id": 1,
        "chunk": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,",
        "authors": [
            "Yuu Jinnai"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T04:50:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16316v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 20000030,
        "doi": null,
        "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
        "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
        "chunk-id": 2,
        "chunk": "it is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the",
        "authors": [
            "Yuu Jinnai"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T04:50:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16316v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 20000030,
        "doi": null,
        "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
        "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
        "chunk-id": 3,
        "chunk": "effect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not",
        "authors": [
            "Yuu Jinnai"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T04:50:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16316v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 20000030,
        "doi": null,
        "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
        "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
        "chunk-id": 4,
        "chunk": "demonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
        "authors": [
            "Yuu Jinnai"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T04:50:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16316v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16316v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 20000031,
        "doi": null,
        "title": "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing",
        "abstract": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing\nchallenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its\nrecognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using\nReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?\nTo our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "chunk-id": 1,
        "chunk": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing",
        "authors": [
            "Jiangshu Du",
            "Yibo Wang",
            "Wenting Zhao",
            "Zhongfen Deng",
            "Shuaiqi Liu",
            "Renze Lou",
            "Henry Peng Zou",
            "Pranav Narayanan Venkit",
            "Nan Zhang",
            "Mukund Srinath",
            "Haoran Ranran Zhang",
            "Vipul Gupta",
            "Yinghui Li",
            "Tao Li",
            "Fei Wang",
            "Qin Liu",
            "Tianlin Liu",
            "Pengzhi Gao",
            "Congying Xia",
            "Chen Xing",
            "Jiayang Cheng",
            "Zhaowei Wang",
            "Ying Su",
            "Raj Sanjay Shah",
            "Ruohao Guo",
            "Jing Gu",
            "Haoran Li",
            "Kangda Wei",
            "Zihao Wang",
            "Lu Cheng",
            "Surangika Ranathunga",
            "Meng Fang",
            "Jie Fu",
            "Fei Liu",
            "Ruihong Huang",
            "Eduardo Blanco",
            "Yixin Cao",
            "Rui Zhang",
            "Philip S. Yu",
            "Wenpeng Yin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T01:30:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16253v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16253v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000031,
        "doi": null,
        "title": "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing",
        "abstract": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing\nchallenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its\nrecognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using\nReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?\nTo our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "chunk-id": 2,
        "chunk": "challenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its",
        "authors": [
            "Jiangshu Du",
            "Yibo Wang",
            "Wenting Zhao",
            "Zhongfen Deng",
            "Shuaiqi Liu",
            "Renze Lou",
            "Henry Peng Zou",
            "Pranav Narayanan Venkit",
            "Nan Zhang",
            "Mukund Srinath",
            "Haoran Ranran Zhang",
            "Vipul Gupta",
            "Yinghui Li",
            "Tao Li",
            "Fei Wang",
            "Qin Liu",
            "Tianlin Liu",
            "Pengzhi Gao",
            "Congying Xia",
            "Chen Xing",
            "Jiayang Cheng",
            "Zhaowei Wang",
            "Ying Su",
            "Raj Sanjay Shah",
            "Ruohao Guo",
            "Jing Gu",
            "Haoran Li",
            "Kangda Wei",
            "Zihao Wang",
            "Lu Cheng",
            "Surangika Ranathunga",
            "Meng Fang",
            "Jie Fu",
            "Fei Liu",
            "Ruihong Huang",
            "Eduardo Blanco",
            "Yixin Cao",
            "Rui Zhang",
            "Philip S. Yu",
            "Wenpeng Yin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T01:30:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16253v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16253v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000031,
        "doi": null,
        "title": "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing",
        "abstract": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing\nchallenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its\nrecognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using\nReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?\nTo our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "chunk-id": 3,
        "chunk": "recognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using",
        "authors": [
            "Jiangshu Du",
            "Yibo Wang",
            "Wenting Zhao",
            "Zhongfen Deng",
            "Shuaiqi Liu",
            "Renze Lou",
            "Henry Peng Zou",
            "Pranav Narayanan Venkit",
            "Nan Zhang",
            "Mukund Srinath",
            "Haoran Ranran Zhang",
            "Vipul Gupta",
            "Yinghui Li",
            "Tao Li",
            "Fei Wang",
            "Qin Liu",
            "Tianlin Liu",
            "Pengzhi Gao",
            "Congying Xia",
            "Chen Xing",
            "Jiayang Cheng",
            "Zhaowei Wang",
            "Ying Su",
            "Raj Sanjay Shah",
            "Ruohao Guo",
            "Jing Gu",
            "Haoran Li",
            "Kangda Wei",
            "Zihao Wang",
            "Lu Cheng",
            "Surangika Ranathunga",
            "Meng Fang",
            "Jie Fu",
            "Fei Liu",
            "Ruihong Huang",
            "Eduardo Blanco",
            "Yixin Cao",
            "Rui Zhang",
            "Philip S. Yu",
            "Wenpeng Yin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T01:30:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16253v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16253v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000031,
        "doi": null,
        "title": "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing",
        "abstract": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing\nchallenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its\nrecognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using\nReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?\nTo our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "chunk-id": 4,
        "chunk": "ReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?",
        "authors": [
            "Jiangshu Du",
            "Yibo Wang",
            "Wenting Zhao",
            "Zhongfen Deng",
            "Shuaiqi Liu",
            "Renze Lou",
            "Henry Peng Zou",
            "Pranav Narayanan Venkit",
            "Nan Zhang",
            "Mukund Srinath",
            "Haoran Ranran Zhang",
            "Vipul Gupta",
            "Yinghui Li",
            "Tao Li",
            "Fei Wang",
            "Qin Liu",
            "Tianlin Liu",
            "Pengzhi Gao",
            "Congying Xia",
            "Chen Xing",
            "Jiayang Cheng",
            "Zhaowei Wang",
            "Ying Su",
            "Raj Sanjay Shah",
            "Ruohao Guo",
            "Jing Gu",
            "Haoran Li",
            "Kangda Wei",
            "Zihao Wang",
            "Lu Cheng",
            "Surangika Ranathunga",
            "Meng Fang",
            "Jie Fu",
            "Fei Liu",
            "Ruihong Huang",
            "Eduardo Blanco",
            "Yixin Cao",
            "Rui Zhang",
            "Philip S. Yu",
            "Wenpeng Yin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T01:30:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16253v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16253v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000031,
        "doi": null,
        "title": "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing",
        "abstract": "This work is motivated by two key trends. On one hand, large language models\n(LLMs) have shown remarkable versatility in various generative tasks such as\nwriting, drawing, and question answering, significantly reducing the time\nrequired for many routine tasks. On the other hand, researchers, whose work is\nnot only time-consuming but also highly expertise-demanding, face increasing\nchallenges as they have to spend more time reading, writing, and reviewing\npapers. This raises the question: how can LLMs potentially assist researchers\nin alleviating their heavy workload?\n  This study focuses on the topic of LLMs assist NLP Researchers, particularly\nexamining the effectiveness of LLM in assisting paper (meta-)reviewing and its\nrecognizability. To address this, we constructed the ReviewCritique dataset,\nwhich includes two types of information: (i) NLP papers (initial submissions\nrather than camera-ready) with both human-written and LLM-generated reviews,\nand (ii) each review comes with \"deficiency\" labels and corresponding\nexplanations for individual segments, annotated by experts. Using\nReviewCritique, this study explores two threads of research questions: (i)\n\"LLMs as Reviewers\", how do reviews generated by LLMs compare with those\nwritten by humans in terms of quality and distinguishability? (ii) \"LLMs as\nMetareviewers\", how effectively can LLMs identify potential issues, such as\nDeficient or unprofessional review segments, within individual paper reviews?\nTo our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "chunk-id": 5,
        "chunk": "To our knowledge, this is the first work to provide such a comprehensive\nanalysis.",
        "authors": [
            "Jiangshu Du",
            "Yibo Wang",
            "Wenting Zhao",
            "Zhongfen Deng",
            "Shuaiqi Liu",
            "Renze Lou",
            "Henry Peng Zou",
            "Pranav Narayanan Venkit",
            "Nan Zhang",
            "Mukund Srinath",
            "Haoran Ranran Zhang",
            "Vipul Gupta",
            "Yinghui Li",
            "Tao Li",
            "Fei Wang",
            "Qin Liu",
            "Tianlin Liu",
            "Pengzhi Gao",
            "Congying Xia",
            "Chen Xing",
            "Jiayang Cheng",
            "Zhaowei Wang",
            "Ying Su",
            "Raj Sanjay Shah",
            "Ruohao Guo",
            "Jing Gu",
            "Haoran Li",
            "Kangda Wei",
            "Zihao Wang",
            "Lu Cheng",
            "Surangika Ranathunga",
            "Meng Fang",
            "Jie Fu",
            "Fei Liu",
            "Ruihong Huang",
            "Eduardo Blanco",
            "Yixin Cao",
            "Rui Zhang",
            "Philip S. Yu",
            "Wenpeng Yin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-24T01:30:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16253v2",
        "arxiv_link": "http://arxiv.org/abs/2406.16253v2",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000032,
        "doi": null,
        "title": "GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets",
        "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP), demonstrating significant capabilities in processing\nand understanding text data. However, recent studies have identified\nlimitations in LLMs' ability to reason about graph-structured data. To address\nthis gap, we introduce GraphEval2000, the first comprehensive graph dataset,\ncomprising 40 graph data structure problems along with 2000 test cases.\nAdditionally, we introduce an evaluation framework based on GraphEval2000,\ndesigned to assess the graph reasoning abilities of LLMs through coding\nchallenges. Our dataset categorizes test cases into four primary and four\nsub-categories, ensuring a comprehensive evaluation. We evaluate eight popular\nLLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of\ndirected graphs compared to undirected ones. While private LLMs consistently\noutperform open-source models, the performance gap is narrowing. Furthermore,\nto improve the usability of our evaluation framework, we propose Structured\nSymbolic Decomposition (SSD), an instruction-based method designed to enhance\nLLM performance on GraphEval2000. Results show that SSD improves the\nperformance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an\nincrease of 11.11\\%, 33.37\\%, and 33.37\\%, respectively.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP), demonstrating significant capabilities in processing\nand understanding text data. However, recent studies have identified\nlimitations in LLMs' ability to reason about graph-structured data. To address\nthis gap, we introduce GraphEval2000, the first comprehensive graph dataset,",
        "authors": [
            "Qiming Wu",
            "Zichen Chen",
            "Will Corcoran",
            "Misha Sra",
            "Ambuj K. Singh"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-23T18:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16176v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16176v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning",
            "Database Applications, Natural Language Processing"
        ]
    },
    {
        "id": 20000032,
        "doi": null,
        "title": "GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets",
        "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP), demonstrating significant capabilities in processing\nand understanding text data. However, recent studies have identified\nlimitations in LLMs' ability to reason about graph-structured data. To address\nthis gap, we introduce GraphEval2000, the first comprehensive graph dataset,\ncomprising 40 graph data structure problems along with 2000 test cases.\nAdditionally, we introduce an evaluation framework based on GraphEval2000,\ndesigned to assess the graph reasoning abilities of LLMs through coding\nchallenges. Our dataset categorizes test cases into four primary and four\nsub-categories, ensuring a comprehensive evaluation. We evaluate eight popular\nLLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of\ndirected graphs compared to undirected ones. While private LLMs consistently\noutperform open-source models, the performance gap is narrowing. Furthermore,\nto improve the usability of our evaluation framework, we propose Structured\nSymbolic Decomposition (SSD), an instruction-based method designed to enhance\nLLM performance on GraphEval2000. Results show that SSD improves the\nperformance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an\nincrease of 11.11\\%, 33.37\\%, and 33.37\\%, respectively.",
        "chunk-id": 2,
        "chunk": "comprising 40 graph data structure problems along with 2000 test cases.\nAdditionally, we introduce an evaluation framework based on GraphEval2000,\ndesigned to assess the graph reasoning abilities of LLMs through coding\nchallenges. Our dataset categorizes test cases into four primary and four\nsub-categories, ensuring a comprehensive evaluation. We evaluate eight popular",
        "authors": [
            "Qiming Wu",
            "Zichen Chen",
            "Will Corcoran",
            "Misha Sra",
            "Ambuj K. Singh"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-23T18:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16176v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16176v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning",
            "Database Applications, Natural Language Processing"
        ]
    },
    {
        "id": 20000032,
        "doi": null,
        "title": "GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets",
        "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP), demonstrating significant capabilities in processing\nand understanding text data. However, recent studies have identified\nlimitations in LLMs' ability to reason about graph-structured data. To address\nthis gap, we introduce GraphEval2000, the first comprehensive graph dataset,\ncomprising 40 graph data structure problems along with 2000 test cases.\nAdditionally, we introduce an evaluation framework based on GraphEval2000,\ndesigned to assess the graph reasoning abilities of LLMs through coding\nchallenges. Our dataset categorizes test cases into four primary and four\nsub-categories, ensuring a comprehensive evaluation. We evaluate eight popular\nLLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of\ndirected graphs compared to undirected ones. While private LLMs consistently\noutperform open-source models, the performance gap is narrowing. Furthermore,\nto improve the usability of our evaluation framework, we propose Structured\nSymbolic Decomposition (SSD), an instruction-based method designed to enhance\nLLM performance on GraphEval2000. Results show that SSD improves the\nperformance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an\nincrease of 11.11\\%, 33.37\\%, and 33.37\\%, respectively.",
        "chunk-id": 3,
        "chunk": "LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of\ndirected graphs compared to undirected ones. While private LLMs consistently\noutperform open-source models, the performance gap is narrowing. Furthermore,\nto improve the usability of our evaluation framework, we propose Structured",
        "authors": [
            "Qiming Wu",
            "Zichen Chen",
            "Will Corcoran",
            "Misha Sra",
            "Ambuj K. Singh"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-23T18:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16176v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16176v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning",
            "Database Applications, Natural Language Processing"
        ]
    },
    {
        "id": 20000032,
        "doi": null,
        "title": "GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets",
        "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP), demonstrating significant capabilities in processing\nand understanding text data. However, recent studies have identified\nlimitations in LLMs' ability to reason about graph-structured data. To address\nthis gap, we introduce GraphEval2000, the first comprehensive graph dataset,\ncomprising 40 graph data structure problems along with 2000 test cases.\nAdditionally, we introduce an evaluation framework based on GraphEval2000,\ndesigned to assess the graph reasoning abilities of LLMs through coding\nchallenges. Our dataset categorizes test cases into four primary and four\nsub-categories, ensuring a comprehensive evaluation. We evaluate eight popular\nLLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of\ndirected graphs compared to undirected ones. While private LLMs consistently\noutperform open-source models, the performance gap is narrowing. Furthermore,\nto improve the usability of our evaluation framework, we propose Structured\nSymbolic Decomposition (SSD), an instruction-based method designed to enhance\nLLM performance on GraphEval2000. Results show that SSD improves the\nperformance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an\nincrease of 11.11\\%, 33.37\\%, and 33.37\\%, respectively.",
        "chunk-id": 4,
        "chunk": "Symbolic Decomposition (SSD), an instruction-based method designed to enhance\nLLM performance on GraphEval2000. Results show that SSD improves the\nperformance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an\nincrease of 11.11\\%, 33.37\\%, and 33.37\\%, respectively.",
        "authors": [
            "Qiming Wu",
            "Zichen Chen",
            "Will Corcoran",
            "Misha Sra",
            "Ambuj K. Singh"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-23T18:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.16176v1",
        "arxiv_link": "http://arxiv.org/abs/2406.16176v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning",
            "Database Applications, Natural Language Processing"
        ]
    },
    {
        "id": 20000033,
        "doi": null,
        "title": "LaMSUM: A Novel Framework for Extractive Summarization of User Generated Content using LLMs",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\na wide range of NLP tasks, including summarization. Inherently LLMs produce\nabstractive summaries, and the task of achieving extractive summaries through\nLLMs still remains largely unexplored. To bridge this gap, in this work, we\npropose a novel framework LaMSUM to generate extractive summaries through LLMs\nfor large user-generated text by leveraging voting algorithms. Our evaluation\non three popular open-source LLMs (Llama 3, Mixtral and Gemini) reveal that the\nLaMSUM outperforms state-of-the-art extractive summarization methods. We\nfurther attempt to provide the rationale behind the output summary produced by\nLLMs. Overall, this is one of the early attempts to achieve extractive\nsummarization for large user-generated text by utilizing LLMs, and likely to\ngenerate further interest in the community.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) have demonstrated impressive performance across\na wide range of NLP tasks, including summarization. Inherently LLMs produce\nabstractive summaries, and the task of achieving extractive summaries through\nLLMs still remains largely unexplored. To bridge this gap, in this work, we",
        "authors": [
            "Garima Chhikara",
            "Anurag Sharma",
            "V. Gurucharan",
            "Kripabandhu Ghosh",
            "Abhijnan Chakraborty"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-22T10:25:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15809v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15809v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000033,
        "doi": null,
        "title": "LaMSUM: A Novel Framework for Extractive Summarization of User Generated Content using LLMs",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\na wide range of NLP tasks, including summarization. Inherently LLMs produce\nabstractive summaries, and the task of achieving extractive summaries through\nLLMs still remains largely unexplored. To bridge this gap, in this work, we\npropose a novel framework LaMSUM to generate extractive summaries through LLMs\nfor large user-generated text by leveraging voting algorithms. Our evaluation\non three popular open-source LLMs (Llama 3, Mixtral and Gemini) reveal that the\nLaMSUM outperforms state-of-the-art extractive summarization methods. We\nfurther attempt to provide the rationale behind the output summary produced by\nLLMs. Overall, this is one of the early attempts to achieve extractive\nsummarization for large user-generated text by utilizing LLMs, and likely to\ngenerate further interest in the community.",
        "chunk-id": 2,
        "chunk": "propose a novel framework LaMSUM to generate extractive summaries through LLMs\nfor large user-generated text by leveraging voting algorithms. Our evaluation\non three popular open-source LLMs (Llama 3, Mixtral and Gemini) reveal that the\nLaMSUM outperforms state-of-the-art extractive summarization methods. We",
        "authors": [
            "Garima Chhikara",
            "Anurag Sharma",
            "V. Gurucharan",
            "Kripabandhu Ghosh",
            "Abhijnan Chakraborty"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-22T10:25:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15809v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15809v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000033,
        "doi": null,
        "title": "LaMSUM: A Novel Framework for Extractive Summarization of User Generated Content using LLMs",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\na wide range of NLP tasks, including summarization. Inherently LLMs produce\nabstractive summaries, and the task of achieving extractive summaries through\nLLMs still remains largely unexplored. To bridge this gap, in this work, we\npropose a novel framework LaMSUM to generate extractive summaries through LLMs\nfor large user-generated text by leveraging voting algorithms. Our evaluation\non three popular open-source LLMs (Llama 3, Mixtral and Gemini) reveal that the\nLaMSUM outperforms state-of-the-art extractive summarization methods. We\nfurther attempt to provide the rationale behind the output summary produced by\nLLMs. Overall, this is one of the early attempts to achieve extractive\nsummarization for large user-generated text by utilizing LLMs, and likely to\ngenerate further interest in the community.",
        "chunk-id": 3,
        "chunk": "further attempt to provide the rationale behind the output summary produced by\nLLMs. Overall, this is one of the early attempts to achieve extractive\nsummarization for large user-generated text by utilizing LLMs, and likely to\ngenerate further interest in the community.",
        "authors": [
            "Garima Chhikara",
            "Anurag Sharma",
            "V. Gurucharan",
            "Kripabandhu Ghosh",
            "Abhijnan Chakraborty"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-22T10:25:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15809v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15809v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000034,
        "doi": null,
        "title": "NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing",
        "abstract": "Scientific literature searches are often exploratory, whereby users are not\nyet familiar with a particular field or concept but are interested in learning\nmore about it. However, existing systems for scientific literature search are\ntypically tailored to keyword-based lookup searches, limiting the possibilities\nfor exploration. We propose NLP-KG, a feature-rich system designed to support\nthe exploration of research literature in unfamiliar natural language\nprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows users\nto easily find survey papers that provide a quick introduction to a field of\ninterest. Further, a Fields of Study hierarchy graph enables users to\nfamiliarize themselves with a field and its related areas. Finally, a chat\ninterface allows users to ask questions about unfamiliar concepts or specific\narticles in NLP and obtain answers grounded in knowledge retrieved from\nscientific publications. Our system provides users with comprehensive\nexploration possibilities, supporting them in investigating the relationships\nbetween different fields, understanding unfamiliar concepts in NLP, and finding\nrelevant research literature. Demo, video, and code are available at:\nhttps://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.",
        "chunk-id": 1,
        "chunk": "Scientific literature searches are often exploratory, whereby users are not\nyet familiar with a particular field or concept but are interested in learning\nmore about it. However, existing systems for scientific literature search are\ntypically tailored to keyword-based lookup searches, limiting the possibilities",
        "authors": [
            "Tim Schopf",
            "Florian Matthes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T16:38:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15294v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15294v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000034,
        "doi": null,
        "title": "NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing",
        "abstract": "Scientific literature searches are often exploratory, whereby users are not\nyet familiar with a particular field or concept but are interested in learning\nmore about it. However, existing systems for scientific literature search are\ntypically tailored to keyword-based lookup searches, limiting the possibilities\nfor exploration. We propose NLP-KG, a feature-rich system designed to support\nthe exploration of research literature in unfamiliar natural language\nprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows users\nto easily find survey papers that provide a quick introduction to a field of\ninterest. Further, a Fields of Study hierarchy graph enables users to\nfamiliarize themselves with a field and its related areas. Finally, a chat\ninterface allows users to ask questions about unfamiliar concepts or specific\narticles in NLP and obtain answers grounded in knowledge retrieved from\nscientific publications. Our system provides users with comprehensive\nexploration possibilities, supporting them in investigating the relationships\nbetween different fields, understanding unfamiliar concepts in NLP, and finding\nrelevant research literature. Demo, video, and code are available at:\nhttps://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.",
        "chunk-id": 2,
        "chunk": "for exploration. We propose NLP-KG, a feature-rich system designed to support\nthe exploration of research literature in unfamiliar natural language\nprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows users\nto easily find survey papers that provide a quick introduction to a field of\ninterest. Further, a Fields of Study hierarchy graph enables users to",
        "authors": [
            "Tim Schopf",
            "Florian Matthes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T16:38:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15294v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15294v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000034,
        "doi": null,
        "title": "NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing",
        "abstract": "Scientific literature searches are often exploratory, whereby users are not\nyet familiar with a particular field or concept but are interested in learning\nmore about it. However, existing systems for scientific literature search are\ntypically tailored to keyword-based lookup searches, limiting the possibilities\nfor exploration. We propose NLP-KG, a feature-rich system designed to support\nthe exploration of research literature in unfamiliar natural language\nprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows users\nto easily find survey papers that provide a quick introduction to a field of\ninterest. Further, a Fields of Study hierarchy graph enables users to\nfamiliarize themselves with a field and its related areas. Finally, a chat\ninterface allows users to ask questions about unfamiliar concepts or specific\narticles in NLP and obtain answers grounded in knowledge retrieved from\nscientific publications. Our system provides users with comprehensive\nexploration possibilities, supporting them in investigating the relationships\nbetween different fields, understanding unfamiliar concepts in NLP, and finding\nrelevant research literature. Demo, video, and code are available at:\nhttps://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.",
        "chunk-id": 3,
        "chunk": "familiarize themselves with a field and its related areas. Finally, a chat\ninterface allows users to ask questions about unfamiliar concepts or specific\narticles in NLP and obtain answers grounded in knowledge retrieved from\nscientific publications. Our system provides users with comprehensive\nexploration possibilities, supporting them in investigating the relationships",
        "authors": [
            "Tim Schopf",
            "Florian Matthes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T16:38:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15294v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15294v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000034,
        "doi": null,
        "title": "NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing",
        "abstract": "Scientific literature searches are often exploratory, whereby users are not\nyet familiar with a particular field or concept but are interested in learning\nmore about it. However, existing systems for scientific literature search are\ntypically tailored to keyword-based lookup searches, limiting the possibilities\nfor exploration. We propose NLP-KG, a feature-rich system designed to support\nthe exploration of research literature in unfamiliar natural language\nprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows users\nto easily find survey papers that provide a quick introduction to a field of\ninterest. Further, a Fields of Study hierarchy graph enables users to\nfamiliarize themselves with a field and its related areas. Finally, a chat\ninterface allows users to ask questions about unfamiliar concepts or specific\narticles in NLP and obtain answers grounded in knowledge retrieved from\nscientific publications. Our system provides users with comprehensive\nexploration possibilities, supporting them in investigating the relationships\nbetween different fields, understanding unfamiliar concepts in NLP, and finding\nrelevant research literature. Demo, video, and code are available at:\nhttps://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.",
        "chunk-id": 4,
        "chunk": "between different fields, understanding unfamiliar concepts in NLP, and finding\nrelevant research literature. Demo, video, and code are available at:\nhttps://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.",
        "authors": [
            "Tim Schopf",
            "Florian Matthes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T16:38:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15294v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15294v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000035,
        "doi": null,
        "title": "Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss",
        "abstract": "Accurately modeling idiomatic or non-compositional language has been a\nlongstanding challenge in Natural Language Processing (NLP). This is partly\nbecause these expressions do not derive their meanings solely from their\nconstituent words, but also due to the scarcity of relevant data resources, and\ntheir impact on the performance of downstream tasks such as machine translation\nand simplification. In this paper we propose an approach to model idiomaticity\neffectively using a triplet loss that incorporates the asymmetric contribution\nof components words to an idiomatic meaning for training language models by\nusing adaptive contrastive learning and resampling miners to build an\nidiomatic-aware learning objective. Our proposed method is evaluated on a\nSemEval challenge and outperforms previous alternatives significantly in many\nmetrics.",
        "chunk-id": 1,
        "chunk": "Accurately modeling idiomatic or non-compositional language has been a\nlongstanding challenge in Natural Language Processing (NLP). This is partly\nbecause these expressions do not derive their meanings solely from their\nconstituent words, but also due to the scarcity of relevant data resources, and\ntheir impact on the performance of downstream tasks such as machine translation",
        "authors": [
            "Wei He",
            "Marco Idiart",
            "Carolina Scarton",
            "Aline Villavicencio"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:21:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15175v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000035,
        "doi": null,
        "title": "Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss",
        "abstract": "Accurately modeling idiomatic or non-compositional language has been a\nlongstanding challenge in Natural Language Processing (NLP). This is partly\nbecause these expressions do not derive their meanings solely from their\nconstituent words, but also due to the scarcity of relevant data resources, and\ntheir impact on the performance of downstream tasks such as machine translation\nand simplification. In this paper we propose an approach to model idiomaticity\neffectively using a triplet loss that incorporates the asymmetric contribution\nof components words to an idiomatic meaning for training language models by\nusing adaptive contrastive learning and resampling miners to build an\nidiomatic-aware learning objective. Our proposed method is evaluated on a\nSemEval challenge and outperforms previous alternatives significantly in many\nmetrics.",
        "chunk-id": 2,
        "chunk": "and simplification. In this paper we propose an approach to model idiomaticity\neffectively using a triplet loss that incorporates the asymmetric contribution\nof components words to an idiomatic meaning for training language models by\nusing adaptive contrastive learning and resampling miners to build an\nidiomatic-aware learning objective. Our proposed method is evaluated on a",
        "authors": [
            "Wei He",
            "Marco Idiart",
            "Carolina Scarton",
            "Aline Villavicencio"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:21:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15175v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000035,
        "doi": null,
        "title": "Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss",
        "abstract": "Accurately modeling idiomatic or non-compositional language has been a\nlongstanding challenge in Natural Language Processing (NLP). This is partly\nbecause these expressions do not derive their meanings solely from their\nconstituent words, but also due to the scarcity of relevant data resources, and\ntheir impact on the performance of downstream tasks such as machine translation\nand simplification. In this paper we propose an approach to model idiomaticity\neffectively using a triplet loss that incorporates the asymmetric contribution\nof components words to an idiomatic meaning for training language models by\nusing adaptive contrastive learning and resampling miners to build an\nidiomatic-aware learning objective. Our proposed method is evaluated on a\nSemEval challenge and outperforms previous alternatives significantly in many\nmetrics.",
        "chunk-id": 3,
        "chunk": "SemEval challenge and outperforms previous alternatives significantly in many\nmetrics.",
        "authors": [
            "Wei He",
            "Marco Idiart",
            "Carolina Scarton",
            "Aline Villavicencio"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:21:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15175v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000036,
        "doi": null,
        "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis",
        "abstract": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.",
        "chunk-id": 1,
        "chunk": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses",
        "authors": [
            "Muhammad Imran",
            "Olga Kellert",
            "Carlos G\u00f3mez-Rodr\u00edguez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:08:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15163v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15163v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000036,
        "doi": null,
        "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis",
        "abstract": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.",
        "chunk-id": 2,
        "chunk": "said bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance",
        "authors": [
            "Muhammad Imran",
            "Olga Kellert",
            "Carlos G\u00f3mez-Rodr\u00edguez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:08:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15163v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15163v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000036,
        "doi": null,
        "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis",
        "abstract": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.",
        "chunk-id": 3,
        "chunk": "and better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one",
        "authors": [
            "Muhammad Imran",
            "Olga Kellert",
            "Carlos G\u00f3mez-Rodr\u00edguez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:08:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15163v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15163v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000036,
        "doi": null,
        "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis",
        "abstract": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.",
        "chunk-id": 4,
        "chunk": "improves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than",
        "authors": [
            "Muhammad Imran",
            "Olga Kellert",
            "Carlos G\u00f3mez-Rodr\u00edguez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:08:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15163v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15163v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000036,
        "doi": null,
        "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis",
        "abstract": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.",
        "chunk-id": 5,
        "chunk": "Transformer-based models in polarity prediction tasks.",
        "authors": [
            "Muhammad Imran",
            "Olga Kellert",
            "Carlos G\u00f3mez-Rodr\u00edguez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T14:08:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15163v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15163v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000037,
        "doi": null,
        "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
        "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
        "chunk-id": 1,
        "chunk": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized",
        "authors": [
            "Xiaohong Ji",
            "Wang Zhen",
            "Zhifeng Gao",
            "Hang Zheng",
            "Linfeng Zhang",
            "Guolin Ke",
            "Weinan E"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T08:28:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14969v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14969v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000037,
        "doi": null,
        "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
        "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
        "chunk-id": 2,
        "chunk": "as the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the",
        "authors": [
            "Xiaohong Ji",
            "Wang Zhen",
            "Zhifeng Gao",
            "Hang Zheng",
            "Linfeng Zhang",
            "Guolin Ke",
            "Weinan E"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T08:28:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14969v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14969v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000037,
        "doi": null,
        "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
        "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
        "chunk-id": 3,
        "chunk": "scaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show",
        "authors": [
            "Xiaohong Ji",
            "Wang Zhen",
            "Zhifeng Gao",
            "Hang Zheng",
            "Linfeng Zhang",
            "Guolin Ke",
            "Weinan E"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T08:28:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14969v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14969v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000037,
        "doi": null,
        "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
        "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
        "chunk-id": 4,
        "chunk": "consistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
        "authors": [
            "Xiaohong Ji",
            "Wang Zhen",
            "Zhifeng Gao",
            "Hang Zheng",
            "Linfeng Zhang",
            "Guolin Ke",
            "Weinan E"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T08:28:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14969v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14969v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000038,
        "doi": null,
        "title": "Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling",
        "abstract": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,\nsuch as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full\ndatasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for\neach benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We\nalso combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "chunk-id": 1,
        "chunk": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,",
        "authors": [
            "Cong Xu",
            "Gayathri Saranathan",
            "Mahammad Parwez Alam",
            "Arpit Shah",
            "James Lim",
            "Soon Yee Wong",
            "Foltin Martin",
            "Suparna Bhattacharya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T07:38:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15527v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15527v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 20000038,
        "doi": null,
        "title": "Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling",
        "abstract": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,\nsuch as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full\ndatasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for\neach benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We\nalso combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "chunk-id": 2,
        "chunk": "such as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full",
        "authors": [
            "Cong Xu",
            "Gayathri Saranathan",
            "Mahammad Parwez Alam",
            "Arpit Shah",
            "James Lim",
            "Soon Yee Wong",
            "Foltin Martin",
            "Suparna Bhattacharya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T07:38:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15527v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15527v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 20000038,
        "doi": null,
        "title": "Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling",
        "abstract": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,\nsuch as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full\ndatasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for\neach benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We\nalso combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "chunk-id": 3,
        "chunk": "datasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for",
        "authors": [
            "Cong Xu",
            "Gayathri Saranathan",
            "Mahammad Parwez Alam",
            "Arpit Shah",
            "James Lim",
            "Soon Yee Wong",
            "Foltin Martin",
            "Suparna Bhattacharya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T07:38:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15527v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15527v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 20000038,
        "doi": null,
        "title": "Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling",
        "abstract": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,\nsuch as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full\ndatasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for\neach benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We\nalso combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "chunk-id": 4,
        "chunk": "each benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We",
        "authors": [
            "Cong Xu",
            "Gayathri Saranathan",
            "Mahammad Parwez Alam",
            "Arpit Shah",
            "James Lim",
            "Soon Yee Wong",
            "Foltin Martin",
            "Suparna Bhattacharya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T07:38:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15527v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15527v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 20000038,
        "doi": null,
        "title": "Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling",
        "abstract": "Evaluating LLMs and text-to-image models is a computationally intensive task\noften overlooked. Efficient evaluation is crucial for understanding the diverse\ncapabilities of these models and enabling comparisons across a growing number\nof new models and benchmarks. To address this, we introduce SubLIME, a\ndata-efficient evaluation framework that employs adaptive sampling techniques,\nsuch as clustering and quality-based methods, to create representative subsets\nof benchmarks. Our approach ensures statistically aligned model rankings\ncompared to full datasets, evidenced by high Pearson correlation coefficients.\nEmpirical analysis across six NLP benchmarks reveals that: (1) quality-based\nsampling consistently achieves strong correlations (0.85 to 0.95) with full\ndatasets at a 10\\% sampling rate such as Quality SE and Quality CPD (2)\nclustering methods excel in specific benchmarks such as MMLU (3) no single\nmethod universally outperforms others across all metrics. Extending this\nframework, we leverage the HEIM leaderboard to cover 25 text-to-image models on\n17 different benchmarks. SubLIME dynamically selects the optimal technique for\neach benchmark, significantly reducing evaluation costs while preserving\nranking integrity and score distribution. Notably, a minimal sampling rate of\n1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that\nemploying difficulty-based sampling to target more challenging benchmark\nsegments enhances model differentiation with broader score distributions. We\nalso combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "chunk-id": 5,
        "chunk": "also combine semantic search, tool use, and GPT-4 review to identify redundancy\nacross benchmarks within specific LLM categories, such as coding benchmarks.\nThis allows us to further reduce the number of samples needed to maintain\ntargeted rank preservation. Overall, SubLIME offers a versatile and\ncost-effective solution for the robust evaluation of LLMs and text-to-image\nmodels.",
        "authors": [
            "Cong Xu",
            "Gayathri Saranathan",
            "Mahammad Parwez Alam",
            "Arpit Shah",
            "James Lim",
            "Soon Yee Wong",
            "Foltin Martin",
            "Suparna Bhattacharya"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T07:38:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15527v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15527v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 20000039,
        "doi": null,
        "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
        "abstract": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP\nfield, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning\ncapabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future\nresearch priorities in this field.",
        "chunk-id": 1,
        "chunk": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP",
        "authors": [
            "Zhengbang Yang",
            "Haotian Xia",
            "Jingxi Li",
            "Zezhi Chen",
            "Zhuangdi Zhu",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T05:57:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14877v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14877v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000039,
        "doi": null,
        "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
        "abstract": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP\nfield, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning\ncapabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future\nresearch priorities in this field.",
        "chunk-id": 2,
        "chunk": "field, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning",
        "authors": [
            "Zhengbang Yang",
            "Haotian Xia",
            "Jingxi Li",
            "Zezhi Chen",
            "Zhuangdi Zhu",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T05:57:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14877v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14877v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000039,
        "doi": null,
        "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
        "abstract": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP\nfield, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning\ncapabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future\nresearch priorities in this field.",
        "chunk-id": 3,
        "chunk": "capabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future",
        "authors": [
            "Zhengbang Yang",
            "Haotian Xia",
            "Jingxi Li",
            "Zezhi Chen",
            "Zhuangdi Zhu",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T05:57:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14877v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14877v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000039,
        "doi": null,
        "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
        "abstract": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP\nfield, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning\ncapabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future\nresearch priorities in this field.",
        "chunk-id": 4,
        "chunk": "research priorities in this field.",
        "authors": [
            "Zhengbang Yang",
            "Haotian Xia",
            "Jingxi Li",
            "Zezhi Chen",
            "Zhuangdi Zhu",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T05:57:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14877v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14877v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000040,
        "doi": null,
        "title": "A review of feature selection strategies utilizing graph data structures and knowledge graphs",
        "abstract": "Feature selection in Knowledge Graphs (KGs) are increasingly utilized in\ndiverse domains, including biomedical research, Natural Language Processing\n(NLP), and personalized recommendation systems. This paper delves into the\nmethodologies for feature selection within KGs, emphasizing their roles in\nenhancing machine learning (ML) model efficacy, hypothesis generation, and\ninterpretability. Through this comprehensive review, we aim to catalyze further\ninnovation in feature selection for KGs, paving the way for more insightful,\nefficient, and interpretable analytical models across various domains. Our\nexploration reveals the critical importance of scalability, accuracy, and\ninterpretability in feature selection techniques, advocating for the\nintegration of domain knowledge to refine the selection process. We highlight\nthe burgeoning potential of multi-objective optimization and interdisciplinary\ncollaboration in advancing KG feature selection, underscoring the\ntransformative impact of such methodologies on precision medicine, among other\nfields. The paper concludes by charting future directions, including the\ndevelopment of scalable, dynamic feature selection algorithms and the\nintegration of explainable AI principles to foster transparency and trust in\nKG-driven models.",
        "chunk-id": 1,
        "chunk": "Feature selection in Knowledge Graphs (KGs) are increasingly utilized in\ndiverse domains, including biomedical research, Natural Language Processing\n(NLP), and personalized recommendation systems. This paper delves into the\nmethodologies for feature selection within KGs, emphasizing their roles in\nenhancing machine learning (ML) model efficacy, hypothesis generation, and",
        "authors": [
            "Sisi Shao",
            "Pedro Henrique Ribeiro",
            "Christina Ramirez",
            "Jason H. Moore"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T04:50:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14864v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14864v1",
        "categories": [
            "Machine Learning",
            "Applications",
            "Machine Learning"
        ]
    },
    {
        "id": 20000040,
        "doi": null,
        "title": "A review of feature selection strategies utilizing graph data structures and knowledge graphs",
        "abstract": "Feature selection in Knowledge Graphs (KGs) are increasingly utilized in\ndiverse domains, including biomedical research, Natural Language Processing\n(NLP), and personalized recommendation systems. This paper delves into the\nmethodologies for feature selection within KGs, emphasizing their roles in\nenhancing machine learning (ML) model efficacy, hypothesis generation, and\ninterpretability. Through this comprehensive review, we aim to catalyze further\ninnovation in feature selection for KGs, paving the way for more insightful,\nefficient, and interpretable analytical models across various domains. Our\nexploration reveals the critical importance of scalability, accuracy, and\ninterpretability in feature selection techniques, advocating for the\nintegration of domain knowledge to refine the selection process. We highlight\nthe burgeoning potential of multi-objective optimization and interdisciplinary\ncollaboration in advancing KG feature selection, underscoring the\ntransformative impact of such methodologies on precision medicine, among other\nfields. The paper concludes by charting future directions, including the\ndevelopment of scalable, dynamic feature selection algorithms and the\nintegration of explainable AI principles to foster transparency and trust in\nKG-driven models.",
        "chunk-id": 2,
        "chunk": "interpretability. Through this comprehensive review, we aim to catalyze further\ninnovation in feature selection for KGs, paving the way for more insightful,\nefficient, and interpretable analytical models across various domains. Our\nexploration reveals the critical importance of scalability, accuracy, and\ninterpretability in feature selection techniques, advocating for the",
        "authors": [
            "Sisi Shao",
            "Pedro Henrique Ribeiro",
            "Christina Ramirez",
            "Jason H. Moore"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T04:50:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14864v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14864v1",
        "categories": [
            "Machine Learning",
            "Applications",
            "Machine Learning"
        ]
    },
    {
        "id": 20000040,
        "doi": null,
        "title": "A review of feature selection strategies utilizing graph data structures and knowledge graphs",
        "abstract": "Feature selection in Knowledge Graphs (KGs) are increasingly utilized in\ndiverse domains, including biomedical research, Natural Language Processing\n(NLP), and personalized recommendation systems. This paper delves into the\nmethodologies for feature selection within KGs, emphasizing their roles in\nenhancing machine learning (ML) model efficacy, hypothesis generation, and\ninterpretability. Through this comprehensive review, we aim to catalyze further\ninnovation in feature selection for KGs, paving the way for more insightful,\nefficient, and interpretable analytical models across various domains. Our\nexploration reveals the critical importance of scalability, accuracy, and\ninterpretability in feature selection techniques, advocating for the\nintegration of domain knowledge to refine the selection process. We highlight\nthe burgeoning potential of multi-objective optimization and interdisciplinary\ncollaboration in advancing KG feature selection, underscoring the\ntransformative impact of such methodologies on precision medicine, among other\nfields. The paper concludes by charting future directions, including the\ndevelopment of scalable, dynamic feature selection algorithms and the\nintegration of explainable AI principles to foster transparency and trust in\nKG-driven models.",
        "chunk-id": 3,
        "chunk": "integration of domain knowledge to refine the selection process. We highlight\nthe burgeoning potential of multi-objective optimization and interdisciplinary\ncollaboration in advancing KG feature selection, underscoring the\ntransformative impact of such methodologies on precision medicine, among other\nfields. The paper concludes by charting future directions, including the",
        "authors": [
            "Sisi Shao",
            "Pedro Henrique Ribeiro",
            "Christina Ramirez",
            "Jason H. Moore"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T04:50:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14864v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14864v1",
        "categories": [
            "Machine Learning",
            "Applications",
            "Machine Learning"
        ]
    },
    {
        "id": 20000040,
        "doi": null,
        "title": "A review of feature selection strategies utilizing graph data structures and knowledge graphs",
        "abstract": "Feature selection in Knowledge Graphs (KGs) are increasingly utilized in\ndiverse domains, including biomedical research, Natural Language Processing\n(NLP), and personalized recommendation systems. This paper delves into the\nmethodologies for feature selection within KGs, emphasizing their roles in\nenhancing machine learning (ML) model efficacy, hypothesis generation, and\ninterpretability. Through this comprehensive review, we aim to catalyze further\ninnovation in feature selection for KGs, paving the way for more insightful,\nefficient, and interpretable analytical models across various domains. Our\nexploration reveals the critical importance of scalability, accuracy, and\ninterpretability in feature selection techniques, advocating for the\nintegration of domain knowledge to refine the selection process. We highlight\nthe burgeoning potential of multi-objective optimization and interdisciplinary\ncollaboration in advancing KG feature selection, underscoring the\ntransformative impact of such methodologies on precision medicine, among other\nfields. The paper concludes by charting future directions, including the\ndevelopment of scalable, dynamic feature selection algorithms and the\nintegration of explainable AI principles to foster transparency and trust in\nKG-driven models.",
        "chunk-id": 4,
        "chunk": "development of scalable, dynamic feature selection algorithms and the\nintegration of explainable AI principles to foster transparency and trust in\nKG-driven models.",
        "authors": [
            "Sisi Shao",
            "Pedro Henrique Ribeiro",
            "Christina Ramirez",
            "Jason H. Moore"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-21T04:50:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14864v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14864v1",
        "categories": [
            "Machine Learning",
            "Applications",
            "Machine Learning"
        ]
    },
    {
        "id": 20000041,
        "doi": null,
        "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
        "abstract": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This\nstudy compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior\nperformance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes.",
        "chunk-id": 1,
        "chunk": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This",
        "authors": [
            "Syed I. Munzir",
            "Daniel B. Hier",
            "Chelsea Oommen",
            "Michael D. Carrithers"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T22:05:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14757v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14757v1",
        "categories": [
            "Artificial Intelligence",
            "Experimental work for problems pertaining to biology",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000041,
        "doi": null,
        "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
        "abstract": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This\nstudy compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior\nperformance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes.",
        "chunk-id": 2,
        "chunk": "study compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior",
        "authors": [
            "Syed I. Munzir",
            "Daniel B. Hier",
            "Chelsea Oommen",
            "Michael D. Carrithers"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T22:05:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14757v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14757v1",
        "categories": [
            "Artificial Intelligence",
            "Experimental work for problems pertaining to biology",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000041,
        "doi": null,
        "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
        "abstract": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This\nstudy compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior\nperformance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes.",
        "chunk-id": 3,
        "chunk": "performance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes.",
        "authors": [
            "Syed I. Munzir",
            "Daniel B. Hier",
            "Chelsea Oommen",
            "Michael D. Carrithers"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T22:05:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14757v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14757v1",
        "categories": [
            "Artificial Intelligence",
            "Experimental work for problems pertaining to biology",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000042,
        "doi": null,
        "title": "Dravidian language family through Universal Dependencies lens",
        "abstract": "The Universal Dependencies (UD) project aims to create a cross-linguistically\nconsistent dependency annotation for multiple languages, to facilitate\nmultilingual NLP. It currently supports 114 languages. Dravidian languages are\nspoken by over 200 million people across the word, and yet there are only two\nlanguages from this family in UD. This paper examines some of the morphological\nand syntactic features of Dravidian languages and explores how they can be\nannotated in the UD framework.",
        "chunk-id": 1,
        "chunk": "The Universal Dependencies (UD) project aims to create a cross-linguistically\nconsistent dependency annotation for multiple languages, to facilitate\nmultilingual NLP. It currently supports 114 languages. Dravidian languages are\nspoken by over 200 million people across the word, and yet there are only two",
        "authors": [
            "Taraka Rama",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T18:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14680v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14680v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000042,
        "doi": null,
        "title": "Dravidian language family through Universal Dependencies lens",
        "abstract": "The Universal Dependencies (UD) project aims to create a cross-linguistically\nconsistent dependency annotation for multiple languages, to facilitate\nmultilingual NLP. It currently supports 114 languages. Dravidian languages are\nspoken by over 200 million people across the word, and yet there are only two\nlanguages from this family in UD. This paper examines some of the morphological\nand syntactic features of Dravidian languages and explores how they can be\nannotated in the UD framework.",
        "chunk-id": 2,
        "chunk": "languages from this family in UD. This paper examines some of the morphological\nand syntactic features of Dravidian languages and explores how they can be\nannotated in the UD framework.",
        "authors": [
            "Taraka Rama",
            "Sowmya Vajjala"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T18:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14680v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14680v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000043,
        "doi": null,
        "title": "DeciMamba: Exploring the Length Extrapolation Potential of Mamba",
        "abstract": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In\nthis paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this\nconstraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context\nlengths that are 25x times longer than the ones seen during training, and does\nso without utilizing additional computational resources. We will release our\ncode and models.",
        "chunk-id": 1,
        "chunk": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In",
        "authors": [
            "Assaf Ben-Kish",
            "Itamar Zimerman",
            "Shady Abu-Hussein",
            "Nadav Cohen",
            "Amir Globerson",
            "Lior Wolf",
            "Raja Giryes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T17:40:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14528v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000043,
        "doi": null,
        "title": "DeciMamba: Exploring the Length Extrapolation Potential of Mamba",
        "abstract": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In\nthis paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this\nconstraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context\nlengths that are 25x times longer than the ones seen during training, and does\nso without utilizing additional computational resources. We will release our\ncode and models.",
        "chunk-id": 2,
        "chunk": "this paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this",
        "authors": [
            "Assaf Ben-Kish",
            "Itamar Zimerman",
            "Shady Abu-Hussein",
            "Nadav Cohen",
            "Amir Globerson",
            "Lior Wolf",
            "Raja Giryes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T17:40:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14528v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000043,
        "doi": null,
        "title": "DeciMamba: Exploring the Length Extrapolation Potential of Mamba",
        "abstract": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In\nthis paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this\nconstraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context\nlengths that are 25x times longer than the ones seen during training, and does\nso without utilizing additional computational resources. We will release our\ncode and models.",
        "chunk-id": 3,
        "chunk": "constraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context",
        "authors": [
            "Assaf Ben-Kish",
            "Itamar Zimerman",
            "Shady Abu-Hussein",
            "Nadav Cohen",
            "Amir Globerson",
            "Lior Wolf",
            "Raja Giryes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T17:40:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14528v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000043,
        "doi": null,
        "title": "DeciMamba: Exploring the Length Extrapolation Potential of Mamba",
        "abstract": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In\nthis paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this\nconstraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context\nlengths that are 25x times longer than the ones seen during training, and does\nso without utilizing additional computational resources. We will release our\ncode and models.",
        "chunk-id": 4,
        "chunk": "lengths that are 25x times longer than the ones seen during training, and does\nso without utilizing additional computational resources. We will release our\ncode and models.",
        "authors": [
            "Assaf Ben-Kish",
            "Itamar Zimerman",
            "Shady Abu-Hussein",
            "Nadav Cohen",
            "Amir Globerson",
            "Lior Wolf",
            "Raja Giryes"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T17:40:18+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14528v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14528v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000044,
        "doi": null,
        "title": "On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier",
        "abstract": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),\nrely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the\nfollowing properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with\nstandard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "chunk-id": 1,
        "chunk": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),",
        "authors": [
            "Jiachen Jiang",
            "Jinxin Zhou",
            "Zhihui Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:41:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14479v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14479v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000044,
        "doi": null,
        "title": "On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier",
        "abstract": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),\nrely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the\nfollowing properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with\nstandard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "chunk-id": 2,
        "chunk": "rely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our",
        "authors": [
            "Jiachen Jiang",
            "Jinxin Zhou",
            "Zhihui Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:41:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14479v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14479v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000044,
        "doi": null,
        "title": "On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier",
        "abstract": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),\nrely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the\nfollowing properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with\nstandard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "chunk-id": 3,
        "chunk": "experimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the",
        "authors": [
            "Jiachen Jiang",
            "Jinxin Zhou",
            "Zhihui Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:41:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14479v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14479v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000044,
        "doi": null,
        "title": "On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier",
        "abstract": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),\nrely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the\nfollowing properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with\nstandard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "chunk-id": 4,
        "chunk": "following properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with",
        "authors": [
            "Jiachen Jiang",
            "Jinxin Zhou",
            "Zhihui Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:41:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14479v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14479v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000044,
        "doi": null,
        "title": "On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier",
        "abstract": "Analyzing the similarity of internal representations within and across\ndifferent models has been an important technique for understanding the behavior\nof deep neural networks. Most existing methods for analyzing the similarity\nbetween representations of high dimensions, such as those based on Canonical\nCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),\nrely on statistical properties of the representations for a set of data points.\nIn this paper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, albeit the similarity decreases when layers\nare far apart. We then propose an aligned training approach to enhance the\nsimilarity between internal representations, with trained models that enjoy the\nfollowing properties: (1) the last-layer classifier can be directly applied\nright after any hidden layers, yielding intermediate layer accuracies much\nhigher than those under standard training, (2) the layer-wise accuracies\nmonotonically increase and reveal the minimal depth needed for the given task,\n(3) when served as multi-exit models, they achieve on-par performance with\nstandard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "chunk-id": 5,
        "chunk": "standard multi-exit architectures which consist of additional classifiers\ndesigned for early exiting in shallow layers. To our knowledge, our work is the\nfirst to show that one common classifier is sufficient for multi-exit models.\nWe conduct experiments on both vision and NLP tasks to demonstrate the\nperformance of the proposed aligned training.",
        "authors": [
            "Jiachen Jiang",
            "Jinxin Zhou",
            "Zhihui Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:41:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14479v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14479v1",
        "categories": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000045,
        "doi": null,
        "title": "Healing Powers of BERT: How Task-Specific Fine-Tuning Recovers Corrupted Language Models",
        "abstract": "Language models like BERT excel at sentence classification tasks due to\nextensive pre-training on general data, but their robustness to parameter\ncorruption is unexplored. To understand this better, we look at what happens if\na language model is \"broken\", in the sense that some of its parameters are\ncorrupted and then recovered by fine-tuning. Strategically corrupting BERT\nvariants at different levels, we find corrupted models struggle to fully\nrecover their original performance, with higher corruption causing more severe\ndegradation. Notably, bottom-layer corruption affecting fundamental linguistic\nfeatures is more detrimental than top-layer corruption. Our insights contribute\nto understanding language model robustness and adaptability under adverse\nconditions, informing strategies for developing resilient NLP systems against\nparameter perturbations.",
        "chunk-id": 1,
        "chunk": "Language models like BERT excel at sentence classification tasks due to\nextensive pre-training on general data, but their robustness to parameter\ncorruption is unexplored. To understand this better, we look at what happens if\na language model is \"broken\", in the sense that some of its parameters are\ncorrupted and then recovered by fine-tuning. Strategically corrupting BERT",
        "authors": [
            "Shijie Han",
            "Zhenyu Zhang",
            "Andrei Arsene Simion"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:18:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000045,
        "doi": null,
        "title": "Healing Powers of BERT: How Task-Specific Fine-Tuning Recovers Corrupted Language Models",
        "abstract": "Language models like BERT excel at sentence classification tasks due to\nextensive pre-training on general data, but their robustness to parameter\ncorruption is unexplored. To understand this better, we look at what happens if\na language model is \"broken\", in the sense that some of its parameters are\ncorrupted and then recovered by fine-tuning. Strategically corrupting BERT\nvariants at different levels, we find corrupted models struggle to fully\nrecover their original performance, with higher corruption causing more severe\ndegradation. Notably, bottom-layer corruption affecting fundamental linguistic\nfeatures is more detrimental than top-layer corruption. Our insights contribute\nto understanding language model robustness and adaptability under adverse\nconditions, informing strategies for developing resilient NLP systems against\nparameter perturbations.",
        "chunk-id": 2,
        "chunk": "variants at different levels, we find corrupted models struggle to fully\nrecover their original performance, with higher corruption causing more severe\ndegradation. Notably, bottom-layer corruption affecting fundamental linguistic\nfeatures is more detrimental than top-layer corruption. Our insights contribute\nto understanding language model robustness and adaptability under adverse",
        "authors": [
            "Shijie Han",
            "Zhenyu Zhang",
            "Andrei Arsene Simion"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:18:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000045,
        "doi": null,
        "title": "Healing Powers of BERT: How Task-Specific Fine-Tuning Recovers Corrupted Language Models",
        "abstract": "Language models like BERT excel at sentence classification tasks due to\nextensive pre-training on general data, but their robustness to parameter\ncorruption is unexplored. To understand this better, we look at what happens if\na language model is \"broken\", in the sense that some of its parameters are\ncorrupted and then recovered by fine-tuning. Strategically corrupting BERT\nvariants at different levels, we find corrupted models struggle to fully\nrecover their original performance, with higher corruption causing more severe\ndegradation. Notably, bottom-layer corruption affecting fundamental linguistic\nfeatures is more detrimental than top-layer corruption. Our insights contribute\nto understanding language model robustness and adaptability under adverse\nconditions, informing strategies for developing resilient NLP systems against\nparameter perturbations.",
        "chunk-id": 3,
        "chunk": "conditions, informing strategies for developing resilient NLP systems against\nparameter perturbations.",
        "authors": [
            "Shijie Han",
            "Zhenyu Zhang",
            "Andrei Arsene Simion"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T16:18:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000046,
        "doi": null,
        "title": "On the Evaluation Practices in Multilingual NLP: Can Machine Translation Offer an Alternative to Human Translations?",
        "abstract": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual\nNLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a\nSOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability\non low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
        "chunk-id": 1,
        "chunk": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual",
        "authors": [
            "Rochelle Choenni",
            "Sara Rajaee",
            "Christof Monz",
            "Ekaterina Shutova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T12:46:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14267v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14267v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000046,
        "doi": null,
        "title": "On the Evaluation Practices in Multilingual NLP: Can Machine Translation Offer an Alternative to Human Translations?",
        "abstract": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual\nNLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a\nSOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability\non low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
        "chunk-id": 2,
        "chunk": "NLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a",
        "authors": [
            "Rochelle Choenni",
            "Sara Rajaee",
            "Christof Monz",
            "Ekaterina Shutova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T12:46:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14267v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14267v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000046,
        "doi": null,
        "title": "On the Evaluation Practices in Multilingual NLP: Can Machine Translation Offer an Alternative to Human Translations?",
        "abstract": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual\nNLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a\nSOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability\non low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
        "chunk-id": 3,
        "chunk": "SOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability",
        "authors": [
            "Rochelle Choenni",
            "Sara Rajaee",
            "Christof Monz",
            "Ekaterina Shutova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T12:46:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14267v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14267v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000046,
        "doi": null,
        "title": "On the Evaluation Practices in Multilingual NLP: Can Machine Translation Offer an Alternative to Human Translations?",
        "abstract": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual\nNLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a\nSOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability\non low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
        "chunk-id": 4,
        "chunk": "on low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
        "authors": [
            "Rochelle Choenni",
            "Sara Rajaee",
            "Christof Monz",
            "Ekaterina Shutova"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T12:46:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14267v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14267v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000047,
        "doi": null,
        "title": "Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning",
        "abstract": "Federated learning is highly susceptible to model poisoning attacks,\nespecially those meticulously crafted for servers. Traditional defense methods\nmainly focus on updating assessments or robust aggregation against manually\ncrafted myopic attacks. When facing advanced attacks, their defense stability\nis notably insufficient. Therefore, it is imperative to develop adaptive\ndefenses against such advanced poisoning attacks. We find that benign clients\nexhibit significantly higher data distribution stability than malicious clients\nin federated learning in both CV and NLP tasks. Therefore, the malicious\nclients can be recognized by observing the stability of their data\ndistribution. In this paper, we propose AdaAggRL, an RL-based Adaptive\nAggregation method, to defend against sophisticated poisoning attacks.\nSpecifically, we first utilize distribution learning to simulate the clients'\ndata distributions. Then, we use the maximum mean discrepancy (MMD) to\ncalculate the pairwise similarity of the current local model data distribution,\nits historical data distribution, and global model data distribution. Finally,\nwe use policy learning to adaptively determine the aggregation weights based on\nthe above similarities. Experiments on four real-world datasets demonstrate\nthat the proposed defense model significantly outperforms widely adopted\ndefense models for sophisticated attacks.",
        "chunk-id": 1,
        "chunk": "Federated learning is highly susceptible to model poisoning attacks,\nespecially those meticulously crafted for servers. Traditional defense methods\nmainly focus on updating assessments or robust aggregation against manually\ncrafted myopic attacks. When facing advanced attacks, their defense stability\nis notably insufficient. Therefore, it is imperative to develop adaptive",
        "authors": [
            "Yujing Wang",
            "Hainan Zhang",
            "Sijia Wen",
            "Wangjie Qiu",
            "Binghui Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T11:33:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14217v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security"
        ]
    },
    {
        "id": 20000047,
        "doi": null,
        "title": "Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning",
        "abstract": "Federated learning is highly susceptible to model poisoning attacks,\nespecially those meticulously crafted for servers. Traditional defense methods\nmainly focus on updating assessments or robust aggregation against manually\ncrafted myopic attacks. When facing advanced attacks, their defense stability\nis notably insufficient. Therefore, it is imperative to develop adaptive\ndefenses against such advanced poisoning attacks. We find that benign clients\nexhibit significantly higher data distribution stability than malicious clients\nin federated learning in both CV and NLP tasks. Therefore, the malicious\nclients can be recognized by observing the stability of their data\ndistribution. In this paper, we propose AdaAggRL, an RL-based Adaptive\nAggregation method, to defend against sophisticated poisoning attacks.\nSpecifically, we first utilize distribution learning to simulate the clients'\ndata distributions. Then, we use the maximum mean discrepancy (MMD) to\ncalculate the pairwise similarity of the current local model data distribution,\nits historical data distribution, and global model data distribution. Finally,\nwe use policy learning to adaptively determine the aggregation weights based on\nthe above similarities. Experiments on four real-world datasets demonstrate\nthat the proposed defense model significantly outperforms widely adopted\ndefense models for sophisticated attacks.",
        "chunk-id": 2,
        "chunk": "defenses against such advanced poisoning attacks. We find that benign clients\nexhibit significantly higher data distribution stability than malicious clients\nin federated learning in both CV and NLP tasks. Therefore, the malicious\nclients can be recognized by observing the stability of their data\ndistribution. In this paper, we propose AdaAggRL, an RL-based Adaptive",
        "authors": [
            "Yujing Wang",
            "Hainan Zhang",
            "Sijia Wen",
            "Wangjie Qiu",
            "Binghui Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T11:33:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14217v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security"
        ]
    },
    {
        "id": 20000047,
        "doi": null,
        "title": "Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning",
        "abstract": "Federated learning is highly susceptible to model poisoning attacks,\nespecially those meticulously crafted for servers. Traditional defense methods\nmainly focus on updating assessments or robust aggregation against manually\ncrafted myopic attacks. When facing advanced attacks, their defense stability\nis notably insufficient. Therefore, it is imperative to develop adaptive\ndefenses against such advanced poisoning attacks. We find that benign clients\nexhibit significantly higher data distribution stability than malicious clients\nin federated learning in both CV and NLP tasks. Therefore, the malicious\nclients can be recognized by observing the stability of their data\ndistribution. In this paper, we propose AdaAggRL, an RL-based Adaptive\nAggregation method, to defend against sophisticated poisoning attacks.\nSpecifically, we first utilize distribution learning to simulate the clients'\ndata distributions. Then, we use the maximum mean discrepancy (MMD) to\ncalculate the pairwise similarity of the current local model data distribution,\nits historical data distribution, and global model data distribution. Finally,\nwe use policy learning to adaptively determine the aggregation weights based on\nthe above similarities. Experiments on four real-world datasets demonstrate\nthat the proposed defense model significantly outperforms widely adopted\ndefense models for sophisticated attacks.",
        "chunk-id": 3,
        "chunk": "Aggregation method, to defend against sophisticated poisoning attacks.\nSpecifically, we first utilize distribution learning to simulate the clients'\ndata distributions. Then, we use the maximum mean discrepancy (MMD) to\ncalculate the pairwise similarity of the current local model data distribution,\nits historical data distribution, and global model data distribution. Finally,",
        "authors": [
            "Yujing Wang",
            "Hainan Zhang",
            "Sijia Wen",
            "Wangjie Qiu",
            "Binghui Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T11:33:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14217v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security"
        ]
    },
    {
        "id": 20000047,
        "doi": null,
        "title": "Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning",
        "abstract": "Federated learning is highly susceptible to model poisoning attacks,\nespecially those meticulously crafted for servers. Traditional defense methods\nmainly focus on updating assessments or robust aggregation against manually\ncrafted myopic attacks. When facing advanced attacks, their defense stability\nis notably insufficient. Therefore, it is imperative to develop adaptive\ndefenses against such advanced poisoning attacks. We find that benign clients\nexhibit significantly higher data distribution stability than malicious clients\nin federated learning in both CV and NLP tasks. Therefore, the malicious\nclients can be recognized by observing the stability of their data\ndistribution. In this paper, we propose AdaAggRL, an RL-based Adaptive\nAggregation method, to defend against sophisticated poisoning attacks.\nSpecifically, we first utilize distribution learning to simulate the clients'\ndata distributions. Then, we use the maximum mean discrepancy (MMD) to\ncalculate the pairwise similarity of the current local model data distribution,\nits historical data distribution, and global model data distribution. Finally,\nwe use policy learning to adaptively determine the aggregation weights based on\nthe above similarities. Experiments on four real-world datasets demonstrate\nthat the proposed defense model significantly outperforms widely adopted\ndefense models for sophisticated attacks.",
        "chunk-id": 4,
        "chunk": "we use policy learning to adaptively determine the aggregation weights based on\nthe above similarities. Experiments on four real-world datasets demonstrate\nthat the proposed defense model significantly outperforms widely adopted\ndefense models for sophisticated attacks.",
        "authors": [
            "Yujing Wang",
            "Hainan Zhang",
            "Sijia Wen",
            "Wangjie Qiu",
            "Binghui Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T11:33:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14217v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14217v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 1,
        "chunk": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 2,
        "chunk": "nanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 3,
        "chunk": "multiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 4,
        "chunk": "Reducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 5,
        "chunk": "reduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000048,
        "doi": null,
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore long-reads",
        "abstract": "In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "chunk-id": 6,
        "chunk": "classical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T10:48:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14187v1",
        "categories": [
            "Genomics"
        ]
    },
    {
        "id": 20000049,
        "doi": null,
        "title": "Leveraging eBPF and AI for Ransomware Nose Out",
        "abstract": "In this work, we propose a two-phased approach for real-time detection and\ndeterrence of ransomware. To achieve this, we leverage the capabilities of eBPF\n(Extended Berkeley Packet Filter) and artificial intelligence to develop both\nproactive and reactive methods. In the first phase, we utilize signature based\ndetection, where we employ custom eBPF programs to trace the execution of new\nprocesses and perform hash-based analysis against a known ransomware dataset.\nIn the second, we employ a behavior-based technique that focuses on monitoring\nthe process activities using a custom eBPF program and the creation of ransom\nnotes, a prominent indicator of ransomware activity through the use of Natural\nLanguage Processing (NLP). By leveraging low-level tracing capabilities of eBPF\nand integrating NLP based machine learning algorithms, our solution achieves an\nimpressive 99.76% accuracy in identifying ransomware incidents within a few\nseconds on the onset of zero-day attacks.",
        "chunk-id": 1,
        "chunk": "In this work, we propose a two-phased approach for real-time detection and\ndeterrence of ransomware. To achieve this, we leverage the capabilities of eBPF\n(Extended Berkeley Packet Filter) and artificial intelligence to develop both\nproactive and reactive methods. In the first phase, we utilize signature based",
        "authors": [
            "Arjun Sekar",
            "Sameer G. Kulkarni",
            "Joy Kuri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T06:35:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14020v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14020v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Networking and Internet Architecture"
        ]
    },
    {
        "id": 20000049,
        "doi": null,
        "title": "Leveraging eBPF and AI for Ransomware Nose Out",
        "abstract": "In this work, we propose a two-phased approach for real-time detection and\ndeterrence of ransomware. To achieve this, we leverage the capabilities of eBPF\n(Extended Berkeley Packet Filter) and artificial intelligence to develop both\nproactive and reactive methods. In the first phase, we utilize signature based\ndetection, where we employ custom eBPF programs to trace the execution of new\nprocesses and perform hash-based analysis against a known ransomware dataset.\nIn the second, we employ a behavior-based technique that focuses on monitoring\nthe process activities using a custom eBPF program and the creation of ransom\nnotes, a prominent indicator of ransomware activity through the use of Natural\nLanguage Processing (NLP). By leveraging low-level tracing capabilities of eBPF\nand integrating NLP based machine learning algorithms, our solution achieves an\nimpressive 99.76% accuracy in identifying ransomware incidents within a few\nseconds on the onset of zero-day attacks.",
        "chunk-id": 2,
        "chunk": "detection, where we employ custom eBPF programs to trace the execution of new\nprocesses and perform hash-based analysis against a known ransomware dataset.\nIn the second, we employ a behavior-based technique that focuses on monitoring\nthe process activities using a custom eBPF program and the creation of ransom",
        "authors": [
            "Arjun Sekar",
            "Sameer G. Kulkarni",
            "Joy Kuri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T06:35:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14020v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14020v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Networking and Internet Architecture"
        ]
    },
    {
        "id": 20000049,
        "doi": null,
        "title": "Leveraging eBPF and AI for Ransomware Nose Out",
        "abstract": "In this work, we propose a two-phased approach for real-time detection and\ndeterrence of ransomware. To achieve this, we leverage the capabilities of eBPF\n(Extended Berkeley Packet Filter) and artificial intelligence to develop both\nproactive and reactive methods. In the first phase, we utilize signature based\ndetection, where we employ custom eBPF programs to trace the execution of new\nprocesses and perform hash-based analysis against a known ransomware dataset.\nIn the second, we employ a behavior-based technique that focuses on monitoring\nthe process activities using a custom eBPF program and the creation of ransom\nnotes, a prominent indicator of ransomware activity through the use of Natural\nLanguage Processing (NLP). By leveraging low-level tracing capabilities of eBPF\nand integrating NLP based machine learning algorithms, our solution achieves an\nimpressive 99.76% accuracy in identifying ransomware incidents within a few\nseconds on the onset of zero-day attacks.",
        "chunk-id": 3,
        "chunk": "notes, a prominent indicator of ransomware activity through the use of Natural\nLanguage Processing (NLP). By leveraging low-level tracing capabilities of eBPF\nand integrating NLP based machine learning algorithms, our solution achieves an\nimpressive 99.76% accuracy in identifying ransomware incidents within a few\nseconds on the onset of zero-day attacks.",
        "authors": [
            "Arjun Sekar",
            "Sameer G. Kulkarni",
            "Joy Kuri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T06:35:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.14020v1",
        "arxiv_link": "http://arxiv.org/abs/2406.14020v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Networking and Internet Architecture"
        ]
    },
    {
        "id": 20000050,
        "doi": null,
        "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
        "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "chunk-id": 1,
        "chunk": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large",
        "authors": [
            "Liang Zhang",
            "Jionghao Lin",
            "Ziyi Kuang",
            "Sheng Xu",
            "Mohammed Yeasin",
            "Xiangen Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T01:18:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13919v2",
        "arxiv_link": "http://arxiv.org/abs/2406.13919v2",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000050,
        "doi": null,
        "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
        "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "chunk-id": 2,
        "chunk": "Language Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated",
        "authors": [
            "Liang Zhang",
            "Jionghao Lin",
            "Ziyi Kuang",
            "Sheng Xu",
            "Mohammed Yeasin",
            "Xiangen Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T01:18:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13919v2",
        "arxiv_link": "http://arxiv.org/abs/2406.13919v2",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000050,
        "doi": null,
        "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
        "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "chunk-id": 3,
        "chunk": "feedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to",
        "authors": [
            "Liang Zhang",
            "Jionghao Lin",
            "Ziyi Kuang",
            "Sheng Xu",
            "Mohammed Yeasin",
            "Xiangen Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T01:18:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13919v2",
        "arxiv_link": "http://arxiv.org/abs/2406.13919v2",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000050,
        "doi": null,
        "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
        "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "chunk-id": 4,
        "chunk": "enhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS",
        "authors": [
            "Liang Zhang",
            "Jionghao Lin",
            "Ziyi Kuang",
            "Sheng Xu",
            "Mohammed Yeasin",
            "Xiangen Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T01:18:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13919v2",
        "arxiv_link": "http://arxiv.org/abs/2406.13919v2",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000050,
        "doi": null,
        "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
        "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "chunk-id": 5,
        "chunk": "functionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
        "authors": [
            "Liang Zhang",
            "Jionghao Lin",
            "Ziyi Kuang",
            "Sheng Xu",
            "Mohammed Yeasin",
            "Xiangen Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T01:18:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13919v2",
        "arxiv_link": "http://arxiv.org/abs/2406.13919v2",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000051,
        "doi": null,
        "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
        "abstract": "Generating free-text rationales is among the emergent capabilities of Large\nLanguage Models (LLMs). These rationales have been found to enhance LLM\nperformance across various NLP tasks. Recently, there has been growing interest\nin using these rationales to provide insights for various important downstream\ntasks. In this paper, we analyze generated free-text rationales in tasks with\nsubjective answers, emphasizing the importance of rationalization in such\nscenarios. We focus on pairwise argument ranking, a highly subjective task with\nsignificant potential for real-world applications, such as debate assistance.\nWe evaluate the persuasiveness of rationales generated by nine LLMs to support\ntheir subjective choices. Our findings suggest that open-source LLMs,\nparticularly Llama2-70B-chat, are capable of providing highly persuasive\nrationalizations, surpassing even GPT models. Additionally, our experiments\nshow that rationale persuasiveness can be improved by controlling its\nparameters through prompting or through self-refinement.",
        "chunk-id": 1,
        "chunk": "Generating free-text rationales is among the emergent capabilities of Large\nLanguage Models (LLMs). These rationales have been found to enhance LLM\nperformance across various NLP tasks. Recently, there has been growing interest\nin using these rationales to provide insights for various important downstream\ntasks. In this paper, we analyze generated free-text rationales in tasks with",
        "authors": [
            "Mohamed Elaraby",
            "Diane Litman",
            "Xiang Lorraine Li",
            "Ahmed Magooda"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T00:28:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13905v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13905v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000051,
        "doi": null,
        "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
        "abstract": "Generating free-text rationales is among the emergent capabilities of Large\nLanguage Models (LLMs). These rationales have been found to enhance LLM\nperformance across various NLP tasks. Recently, there has been growing interest\nin using these rationales to provide insights for various important downstream\ntasks. In this paper, we analyze generated free-text rationales in tasks with\nsubjective answers, emphasizing the importance of rationalization in such\nscenarios. We focus on pairwise argument ranking, a highly subjective task with\nsignificant potential for real-world applications, such as debate assistance.\nWe evaluate the persuasiveness of rationales generated by nine LLMs to support\ntheir subjective choices. Our findings suggest that open-source LLMs,\nparticularly Llama2-70B-chat, are capable of providing highly persuasive\nrationalizations, surpassing even GPT models. Additionally, our experiments\nshow that rationale persuasiveness can be improved by controlling its\nparameters through prompting or through self-refinement.",
        "chunk-id": 2,
        "chunk": "subjective answers, emphasizing the importance of rationalization in such\nscenarios. We focus on pairwise argument ranking, a highly subjective task with\nsignificant potential for real-world applications, such as debate assistance.\nWe evaluate the persuasiveness of rationales generated by nine LLMs to support\ntheir subjective choices. Our findings suggest that open-source LLMs,",
        "authors": [
            "Mohamed Elaraby",
            "Diane Litman",
            "Xiang Lorraine Li",
            "Ahmed Magooda"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T00:28:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13905v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13905v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000051,
        "doi": null,
        "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
        "abstract": "Generating free-text rationales is among the emergent capabilities of Large\nLanguage Models (LLMs). These rationales have been found to enhance LLM\nperformance across various NLP tasks. Recently, there has been growing interest\nin using these rationales to provide insights for various important downstream\ntasks. In this paper, we analyze generated free-text rationales in tasks with\nsubjective answers, emphasizing the importance of rationalization in such\nscenarios. We focus on pairwise argument ranking, a highly subjective task with\nsignificant potential for real-world applications, such as debate assistance.\nWe evaluate the persuasiveness of rationales generated by nine LLMs to support\ntheir subjective choices. Our findings suggest that open-source LLMs,\nparticularly Llama2-70B-chat, are capable of providing highly persuasive\nrationalizations, surpassing even GPT models. Additionally, our experiments\nshow that rationale persuasiveness can be improved by controlling its\nparameters through prompting or through self-refinement.",
        "chunk-id": 3,
        "chunk": "particularly Llama2-70B-chat, are capable of providing highly persuasive\nrationalizations, surpassing even GPT models. Additionally, our experiments\nshow that rationale persuasiveness can be improved by controlling its\nparameters through prompting or through self-refinement.",
        "authors": [
            "Mohamed Elaraby",
            "Diane Litman",
            "Xiang Lorraine Li",
            "Ahmed Magooda"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-20T00:28:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13905v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13905v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000052,
        "doi": null,
        "title": "Open Generative Large Language Models for Galician",
        "abstract": "Large language models (LLMs) have transformed natural language processing.\nYet, their predominantly English-centric training has led to biases and\nperformance disparities across languages. This imbalance marginalizes\nminoritized languages, making equitable access to NLP technologies more\ndifficult for languages with lower resources, such as Galician. We present the\nfirst two generative LLMs focused on Galician to bridge this gap. These models,\nfreely available as open-source resources, were trained using a GPT\narchitecture with 1.3B parameters on a corpus of 2.1B words. Leveraging\ncontinual pretraining, we adapt to Galician two existing LLMs trained on larger\ncorpora, thus mitigating the data constraints that would arise if the training\nwere performed from scratch. The models were evaluated using human judgments\nand task-based datasets from standardized benchmarks. These evaluations reveal\na promising performance, underscoring the importance of linguistic diversity in\ngenerative models.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have transformed natural language processing.\nYet, their predominantly English-centric training has led to biases and\nperformance disparities across languages. This imbalance marginalizes\nminoritized languages, making equitable access to NLP technologies more\ndifficult for languages with lower resources, such as Galician. We present the",
        "authors": [
            "Pablo Gamallo",
            "Pablo Rodr\u00edguez",
            "Iria de-Dios-Flores",
            "Susana Sotelo",
            "Silvia Paniagua",
            "Daniel Bardanca",
            "Jos\u00e9 Ramom Pichel",
            "Marcos Garcia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:49:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13893v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13893v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000052,
        "doi": null,
        "title": "Open Generative Large Language Models for Galician",
        "abstract": "Large language models (LLMs) have transformed natural language processing.\nYet, their predominantly English-centric training has led to biases and\nperformance disparities across languages. This imbalance marginalizes\nminoritized languages, making equitable access to NLP technologies more\ndifficult for languages with lower resources, such as Galician. We present the\nfirst two generative LLMs focused on Galician to bridge this gap. These models,\nfreely available as open-source resources, were trained using a GPT\narchitecture with 1.3B parameters on a corpus of 2.1B words. Leveraging\ncontinual pretraining, we adapt to Galician two existing LLMs trained on larger\ncorpora, thus mitigating the data constraints that would arise if the training\nwere performed from scratch. The models were evaluated using human judgments\nand task-based datasets from standardized benchmarks. These evaluations reveal\na promising performance, underscoring the importance of linguistic diversity in\ngenerative models.",
        "chunk-id": 2,
        "chunk": "first two generative LLMs focused on Galician to bridge this gap. These models,\nfreely available as open-source resources, were trained using a GPT\narchitecture with 1.3B parameters on a corpus of 2.1B words. Leveraging\ncontinual pretraining, we adapt to Galician two existing LLMs trained on larger\ncorpora, thus mitigating the data constraints that would arise if the training",
        "authors": [
            "Pablo Gamallo",
            "Pablo Rodr\u00edguez",
            "Iria de-Dios-Flores",
            "Susana Sotelo",
            "Silvia Paniagua",
            "Daniel Bardanca",
            "Jos\u00e9 Ramom Pichel",
            "Marcos Garcia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:49:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13893v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13893v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000052,
        "doi": null,
        "title": "Open Generative Large Language Models for Galician",
        "abstract": "Large language models (LLMs) have transformed natural language processing.\nYet, their predominantly English-centric training has led to biases and\nperformance disparities across languages. This imbalance marginalizes\nminoritized languages, making equitable access to NLP technologies more\ndifficult for languages with lower resources, such as Galician. We present the\nfirst two generative LLMs focused on Galician to bridge this gap. These models,\nfreely available as open-source resources, were trained using a GPT\narchitecture with 1.3B parameters on a corpus of 2.1B words. Leveraging\ncontinual pretraining, we adapt to Galician two existing LLMs trained on larger\ncorpora, thus mitigating the data constraints that would arise if the training\nwere performed from scratch. The models were evaluated using human judgments\nand task-based datasets from standardized benchmarks. These evaluations reveal\na promising performance, underscoring the importance of linguistic diversity in\ngenerative models.",
        "chunk-id": 3,
        "chunk": "were performed from scratch. The models were evaluated using human judgments\nand task-based datasets from standardized benchmarks. These evaluations reveal\na promising performance, underscoring the importance of linguistic diversity in\ngenerative models.",
        "authors": [
            "Pablo Gamallo",
            "Pablo Rodr\u00edguez",
            "Iria de-Dios-Flores",
            "Susana Sotelo",
            "Silvia Paniagua",
            "Daniel Bardanca",
            "Jos\u00e9 Ramom Pichel",
            "Marcos Garcia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:49:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13893v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13893v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 1,
        "chunk": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 2,
        "chunk": "most existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 3,
        "chunk": "evaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 4,
        "chunk": "diagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 5,
        "chunk": "departments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000053,
        "doi": null,
        "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
        "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
        "chunk-id": 6,
        "chunk": "designing medical agents.",
        "authors": [
            "Weixiang Yan",
            "Haitian Liu",
            "Tengxiao Wu",
            "Qian Chen",
            "Wen Wang",
            "Haoyuan Chai",
            "Jiayi Wang",
            "Weishan Zhao",
            "Yixin Zhang",
            "Renjun Zhang",
            "Li Zhu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T23:44:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13890v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13890v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000054,
        "doi": null,
        "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
        "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
        "chunk-id": 1,
        "chunk": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node",
        "authors": [
            "Yu Song",
            "Haitao Mao",
            "Jiachen Xiao",
            "Jingzhe Liu",
            "Zhikai Chen",
            "Wei Jin",
            "Carl Yang",
            "Jiliang Tang",
            "Hui Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T22:30:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13873v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13873v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000054,
        "doi": null,
        "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
        "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
        "chunk-id": 2,
        "chunk": "feature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).",
        "authors": [
            "Yu Song",
            "Haitao Mao",
            "Jiachen Xiao",
            "Jingzhe Liu",
            "Zhikai Chen",
            "Wei Jin",
            "Carl Yang",
            "Jiliang Tang",
            "Hui Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T22:30:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13873v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13873v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000054,
        "doi": null,
        "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
        "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
        "chunk-id": 3,
        "chunk": "Motivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to",
        "authors": [
            "Yu Song",
            "Haitao Mao",
            "Jiachen Xiao",
            "Jingzhe Liu",
            "Zhikai Chen",
            "Wei Jin",
            "Carl Yang",
            "Jiliang Tang",
            "Hui Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T22:30:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13873v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13873v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000054,
        "doi": null,
        "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
        "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
        "chunk-id": 4,
        "chunk": "capture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success",
        "authors": [
            "Yu Song",
            "Haitao Mao",
            "Jiachen Xiao",
            "Jingzhe Liu",
            "Zhikai Chen",
            "Wei Jin",
            "Carl Yang",
            "Jiliang Tang",
            "Hui Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T22:30:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13873v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13873v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000054,
        "doi": null,
        "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
        "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
        "chunk-id": 5,
        "chunk": "on various datasets.",
        "authors": [
            "Yu Song",
            "Haitao Mao",
            "Jiachen Xiao",
            "Jingzhe Liu",
            "Zhikai Chen",
            "Wei Jin",
            "Carl Yang",
            "Jiliang Tang",
            "Hui Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T22:30:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13873v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13873v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000055,
        "doi": null,
        "title": "Benchmarking Open-Source Language Models for Efficient Question Answering in Industrial Applications",
        "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have demonstrated remarkable capabilities in tasks such\nas question answering (QA). However, the accessibility and practicality of\nutilizing these models for industrial applications pose significant challenges,\nparticularly concerning cost-effectiveness, inference speed, and resource\nefficiency. This paper presents a comprehensive benchmarking study comparing\nopen-source LLMs with their non-open-source counterparts on the task of\nquestion answering. Our objective is to identify open-source alternatives\ncapable of delivering comparable performance to proprietary models while being\nlightweight in terms of resource requirements and suitable for Central\nProcessing Unit (CPU)-based inference. Through rigorous evaluation across\nvarious metrics including accuracy, inference speed, and resource consumption,\nwe aim to provide insights into selecting efficient LLMs for real-world\napplications. Our findings shed light on viable open-source alternatives that\noffer acceptable performance and efficiency, addressing the pressing need for\naccessible and efficient NLP solutions in industry settings.",
        "chunk-id": 1,
        "chunk": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have demonstrated remarkable capabilities in tasks such\nas question answering (QA). However, the accessibility and practicality of\nutilizing these models for industrial applications pose significant challenges,",
        "authors": [
            "Mahaman Sanoussi Yahaya Alassan",
            "Jessica L\u00f3pez Espejel",
            "Merieme Bouhandi",
            "Walid Dahhane",
            "El Hassane Ettifouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T17:11:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13713v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13713v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000055,
        "doi": null,
        "title": "Benchmarking Open-Source Language Models for Efficient Question Answering in Industrial Applications",
        "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have demonstrated remarkable capabilities in tasks such\nas question answering (QA). However, the accessibility and practicality of\nutilizing these models for industrial applications pose significant challenges,\nparticularly concerning cost-effectiveness, inference speed, and resource\nefficiency. This paper presents a comprehensive benchmarking study comparing\nopen-source LLMs with their non-open-source counterparts on the task of\nquestion answering. Our objective is to identify open-source alternatives\ncapable of delivering comparable performance to proprietary models while being\nlightweight in terms of resource requirements and suitable for Central\nProcessing Unit (CPU)-based inference. Through rigorous evaluation across\nvarious metrics including accuracy, inference speed, and resource consumption,\nwe aim to provide insights into selecting efficient LLMs for real-world\napplications. Our findings shed light on viable open-source alternatives that\noffer acceptable performance and efficiency, addressing the pressing need for\naccessible and efficient NLP solutions in industry settings.",
        "chunk-id": 2,
        "chunk": "particularly concerning cost-effectiveness, inference speed, and resource\nefficiency. This paper presents a comprehensive benchmarking study comparing\nopen-source LLMs with their non-open-source counterparts on the task of\nquestion answering. Our objective is to identify open-source alternatives\ncapable of delivering comparable performance to proprietary models while being",
        "authors": [
            "Mahaman Sanoussi Yahaya Alassan",
            "Jessica L\u00f3pez Espejel",
            "Merieme Bouhandi",
            "Walid Dahhane",
            "El Hassane Ettifouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T17:11:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13713v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13713v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000055,
        "doi": null,
        "title": "Benchmarking Open-Source Language Models for Efficient Question Answering in Industrial Applications",
        "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have demonstrated remarkable capabilities in tasks such\nas question answering (QA). However, the accessibility and practicality of\nutilizing these models for industrial applications pose significant challenges,\nparticularly concerning cost-effectiveness, inference speed, and resource\nefficiency. This paper presents a comprehensive benchmarking study comparing\nopen-source LLMs with their non-open-source counterparts on the task of\nquestion answering. Our objective is to identify open-source alternatives\ncapable of delivering comparable performance to proprietary models while being\nlightweight in terms of resource requirements and suitable for Central\nProcessing Unit (CPU)-based inference. Through rigorous evaluation across\nvarious metrics including accuracy, inference speed, and resource consumption,\nwe aim to provide insights into selecting efficient LLMs for real-world\napplications. Our findings shed light on viable open-source alternatives that\noffer acceptable performance and efficiency, addressing the pressing need for\naccessible and efficient NLP solutions in industry settings.",
        "chunk-id": 3,
        "chunk": "lightweight in terms of resource requirements and suitable for Central\nProcessing Unit (CPU)-based inference. Through rigorous evaluation across\nvarious metrics including accuracy, inference speed, and resource consumption,\nwe aim to provide insights into selecting efficient LLMs for real-world\napplications. Our findings shed light on viable open-source alternatives that",
        "authors": [
            "Mahaman Sanoussi Yahaya Alassan",
            "Jessica L\u00f3pez Espejel",
            "Merieme Bouhandi",
            "Walid Dahhane",
            "El Hassane Ettifouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T17:11:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13713v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13713v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000055,
        "doi": null,
        "title": "Benchmarking Open-Source Language Models for Efficient Question Answering in Industrial Applications",
        "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have demonstrated remarkable capabilities in tasks such\nas question answering (QA). However, the accessibility and practicality of\nutilizing these models for industrial applications pose significant challenges,\nparticularly concerning cost-effectiveness, inference speed, and resource\nefficiency. This paper presents a comprehensive benchmarking study comparing\nopen-source LLMs with their non-open-source counterparts on the task of\nquestion answering. Our objective is to identify open-source alternatives\ncapable of delivering comparable performance to proprietary models while being\nlightweight in terms of resource requirements and suitable for Central\nProcessing Unit (CPU)-based inference. Through rigorous evaluation across\nvarious metrics including accuracy, inference speed, and resource consumption,\nwe aim to provide insights into selecting efficient LLMs for real-world\napplications. Our findings shed light on viable open-source alternatives that\noffer acceptable performance and efficiency, addressing the pressing need for\naccessible and efficient NLP solutions in industry settings.",
        "chunk-id": 4,
        "chunk": "offer acceptable performance and efficiency, addressing the pressing need for\naccessible and efficient NLP solutions in industry settings.",
        "authors": [
            "Mahaman Sanoussi Yahaya Alassan",
            "Jessica L\u00f3pez Espejel",
            "Merieme Bouhandi",
            "Walid Dahhane",
            "El Hassane Ettifouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T17:11:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13713v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13713v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000056,
        "doi": null,
        "title": "Multilingual De-Duplication Strategies: Applying scalable similarity search with monolingual & multilingual embedding models",
        "abstract": "This paper addresses the deduplication of multilingual textual data using\nadvanced NLP tools. We compare a two-step method involving translation to\nEnglish followed by embedding with mpnet, and a multilingual embedding model\n(distiluse). The two-step approach achieved a higher F1 score (82% vs. 60%),\nparticularly with less widely used languages, which can be increased up to 89%\nby leveraging expert rules based on domain knowledge. We also highlight\nlimitations related to token length constraints and computational efficiency.\nOur methodology suggests improvements for future multilingual deduplication\ntasks.",
        "chunk-id": 1,
        "chunk": "This paper addresses the deduplication of multilingual textual data using\nadvanced NLP tools. We compare a two-step method involving translation to\nEnglish followed by embedding with mpnet, and a multilingual embedding model\n(distiluse). The two-step approach achieved a higher F1 score (82% vs. 60%),\nparticularly with less widely used languages, which can be increased up to 89%",
        "authors": [
            "Stefan Pasch",
            "Dimitirios Petridis",
            "Jannic Cutura"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:48:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13695v1",
        "categories": [
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 20000056,
        "doi": null,
        "title": "Multilingual De-Duplication Strategies: Applying scalable similarity search with monolingual & multilingual embedding models",
        "abstract": "This paper addresses the deduplication of multilingual textual data using\nadvanced NLP tools. We compare a two-step method involving translation to\nEnglish followed by embedding with mpnet, and a multilingual embedding model\n(distiluse). The two-step approach achieved a higher F1 score (82% vs. 60%),\nparticularly with less widely used languages, which can be increased up to 89%\nby leveraging expert rules based on domain knowledge. We also highlight\nlimitations related to token length constraints and computational efficiency.\nOur methodology suggests improvements for future multilingual deduplication\ntasks.",
        "chunk-id": 2,
        "chunk": "by leveraging expert rules based on domain knowledge. We also highlight\nlimitations related to token length constraints and computational efficiency.\nOur methodology suggests improvements for future multilingual deduplication\ntasks.",
        "authors": [
            "Stefan Pasch",
            "Dimitirios Petridis",
            "Jannic Cutura"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:48:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13695v1",
        "categories": [
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 20000057,
        "doi": null,
        "title": "Leveraging Large Language Models to Measure Gender Bias in Gendered Languages",
        "abstract": "Gender bias in text corpora used in various natural language processing (NLP)\ncontexts, such as for training large language models (LLMs), can lead to the\nperpetuation and amplification of societal inequalities. This is particularly\npronounced in gendered languages like Spanish or French, where grammatical\nstructures inherently encode gender, making the bias analysis more challenging.\nExisting methods designed for English are inadequate for this task due to the\nintrinsic linguistic differences between English and gendered languages. This\npaper introduces a novel methodology that leverages the contextual\nunderstanding capabilities of LLMs to quantitatively analyze gender\nrepresentation in Spanish corpora. By utilizing LLMs to identify and classify\ngendered nouns and pronouns in relation to their reference to human entities,\nour approach provides a nuanced analysis of gender biases. We empirically\nvalidate our method on four widely-used benchmark datasets, uncovering\nsignificant gender disparities with a male-to-female ratio ranging from 4:1 to\n6:1. These findings demonstrate the value of our methodology for bias\nquantification in gendered languages and suggest its application in NLP,\ncontributing to the development of more equitable language technologies.",
        "chunk-id": 1,
        "chunk": "Gender bias in text corpora used in various natural language processing (NLP)\ncontexts, such as for training large language models (LLMs), can lead to the\nperpetuation and amplification of societal inequalities. This is particularly\npronounced in gendered languages like Spanish or French, where grammatical",
        "authors": [
            "Erik Derner",
            "Sara Sansalvador de la Fuente",
            "Yoan Guti\u00e9rrez",
            "Paloma Moreda",
            "Nuria Oliver"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:30:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13677v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13677v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000057,
        "doi": null,
        "title": "Leveraging Large Language Models to Measure Gender Bias in Gendered Languages",
        "abstract": "Gender bias in text corpora used in various natural language processing (NLP)\ncontexts, such as for training large language models (LLMs), can lead to the\nperpetuation and amplification of societal inequalities. This is particularly\npronounced in gendered languages like Spanish or French, where grammatical\nstructures inherently encode gender, making the bias analysis more challenging.\nExisting methods designed for English are inadequate for this task due to the\nintrinsic linguistic differences between English and gendered languages. This\npaper introduces a novel methodology that leverages the contextual\nunderstanding capabilities of LLMs to quantitatively analyze gender\nrepresentation in Spanish corpora. By utilizing LLMs to identify and classify\ngendered nouns and pronouns in relation to their reference to human entities,\nour approach provides a nuanced analysis of gender biases. We empirically\nvalidate our method on four widely-used benchmark datasets, uncovering\nsignificant gender disparities with a male-to-female ratio ranging from 4:1 to\n6:1. These findings demonstrate the value of our methodology for bias\nquantification in gendered languages and suggest its application in NLP,\ncontributing to the development of more equitable language technologies.",
        "chunk-id": 2,
        "chunk": "structures inherently encode gender, making the bias analysis more challenging.\nExisting methods designed for English are inadequate for this task due to the\nintrinsic linguistic differences between English and gendered languages. This\npaper introduces a novel methodology that leverages the contextual\nunderstanding capabilities of LLMs to quantitatively analyze gender",
        "authors": [
            "Erik Derner",
            "Sara Sansalvador de la Fuente",
            "Yoan Guti\u00e9rrez",
            "Paloma Moreda",
            "Nuria Oliver"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:30:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13677v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13677v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000057,
        "doi": null,
        "title": "Leveraging Large Language Models to Measure Gender Bias in Gendered Languages",
        "abstract": "Gender bias in text corpora used in various natural language processing (NLP)\ncontexts, such as for training large language models (LLMs), can lead to the\nperpetuation and amplification of societal inequalities. This is particularly\npronounced in gendered languages like Spanish or French, where grammatical\nstructures inherently encode gender, making the bias analysis more challenging.\nExisting methods designed for English are inadequate for this task due to the\nintrinsic linguistic differences between English and gendered languages. This\npaper introduces a novel methodology that leverages the contextual\nunderstanding capabilities of LLMs to quantitatively analyze gender\nrepresentation in Spanish corpora. By utilizing LLMs to identify and classify\ngendered nouns and pronouns in relation to their reference to human entities,\nour approach provides a nuanced analysis of gender biases. We empirically\nvalidate our method on four widely-used benchmark datasets, uncovering\nsignificant gender disparities with a male-to-female ratio ranging from 4:1 to\n6:1. These findings demonstrate the value of our methodology for bias\nquantification in gendered languages and suggest its application in NLP,\ncontributing to the development of more equitable language technologies.",
        "chunk-id": 3,
        "chunk": "representation in Spanish corpora. By utilizing LLMs to identify and classify\ngendered nouns and pronouns in relation to their reference to human entities,\nour approach provides a nuanced analysis of gender biases. We empirically\nvalidate our method on four widely-used benchmark datasets, uncovering\nsignificant gender disparities with a male-to-female ratio ranging from 4:1 to",
        "authors": [
            "Erik Derner",
            "Sara Sansalvador de la Fuente",
            "Yoan Guti\u00e9rrez",
            "Paloma Moreda",
            "Nuria Oliver"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:30:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13677v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13677v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000057,
        "doi": null,
        "title": "Leveraging Large Language Models to Measure Gender Bias in Gendered Languages",
        "abstract": "Gender bias in text corpora used in various natural language processing (NLP)\ncontexts, such as for training large language models (LLMs), can lead to the\nperpetuation and amplification of societal inequalities. This is particularly\npronounced in gendered languages like Spanish or French, where grammatical\nstructures inherently encode gender, making the bias analysis more challenging.\nExisting methods designed for English are inadequate for this task due to the\nintrinsic linguistic differences between English and gendered languages. This\npaper introduces a novel methodology that leverages the contextual\nunderstanding capabilities of LLMs to quantitatively analyze gender\nrepresentation in Spanish corpora. By utilizing LLMs to identify and classify\ngendered nouns and pronouns in relation to their reference to human entities,\nour approach provides a nuanced analysis of gender biases. We empirically\nvalidate our method on four widely-used benchmark datasets, uncovering\nsignificant gender disparities with a male-to-female ratio ranging from 4:1 to\n6:1. These findings demonstrate the value of our methodology for bias\nquantification in gendered languages and suggest its application in NLP,\ncontributing to the development of more equitable language technologies.",
        "chunk-id": 4,
        "chunk": "6:1. These findings demonstrate the value of our methodology for bias\nquantification in gendered languages and suggest its application in NLP,\ncontributing to the development of more equitable language technologies.",
        "authors": [
            "Erik Derner",
            "Sara Sansalvador de la Fuente",
            "Yoan Guti\u00e9rrez",
            "Paloma Moreda",
            "Nuria Oliver"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T16:30:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13677v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13677v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000058,
        "doi": null,
        "title": "Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines",
        "abstract": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the\nbasis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in\naccuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial\ninformation, offering a powerful tool for stakeholders in the financial\nindustry.",
        "chunk-id": 1,
        "chunk": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the",
        "authors": [
            "Kangtong Mo",
            "Wenyan Liu",
            "Xuanzhen Xu",
            "Chang Yu",
            "Yuelin Zou",
            "Fangqing Xia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:20:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13626v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13626v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000058,
        "doi": null,
        "title": "Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines",
        "abstract": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the\nbasis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in\naccuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial\ninformation, offering a powerful tool for stakeholders in the financial\nindustry.",
        "chunk-id": 2,
        "chunk": "basis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in",
        "authors": [
            "Kangtong Mo",
            "Wenyan Liu",
            "Xuanzhen Xu",
            "Chang Yu",
            "Yuelin Zou",
            "Fangqing Xia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:20:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13626v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13626v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000058,
        "doi": null,
        "title": "Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines",
        "abstract": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the\nbasis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in\naccuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial\ninformation, offering a powerful tool for stakeholders in the financial\nindustry.",
        "chunk-id": 3,
        "chunk": "accuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial",
        "authors": [
            "Kangtong Mo",
            "Wenyan Liu",
            "Xuanzhen Xu",
            "Chang Yu",
            "Yuelin Zou",
            "Fangqing Xia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:20:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13626v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13626v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000058,
        "doi": null,
        "title": "Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines",
        "abstract": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the\nbasis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in\naccuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial\ninformation, offering a powerful tool for stakeholders in the financial\nindustry.",
        "chunk-id": 4,
        "chunk": "information, offering a powerful tool for stakeholders in the financial\nindustry.",
        "authors": [
            "Kangtong Mo",
            "Wenyan Liu",
            "Xuanzhen Xu",
            "Chang Yu",
            "Yuelin Zou",
            "Fangqing Xia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:20:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13626v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13626v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000059,
        "doi": null,
        "title": "Improving Visual Commonsense in Language Models via Multiple Image Generation",
        "abstract": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic\ncommonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making\nprocess by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate\nour approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in\ntraditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "chunk-id": 1,
        "chunk": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic",
        "authors": [
            "Guy Yariv",
            "Idan Schwartz",
            "Yossi Adi",
            "Sagie Benaim"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:17:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13621v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13621v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000059,
        "doi": null,
        "title": "Improving Visual Commonsense in Language Models via Multiple Image Generation",
        "abstract": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic\ncommonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making\nprocess by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate\nour approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in\ntraditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "chunk-id": 2,
        "chunk": "commonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making",
        "authors": [
            "Guy Yariv",
            "Idan Schwartz",
            "Yossi Adi",
            "Sagie Benaim"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:17:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13621v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13621v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000059,
        "doi": null,
        "title": "Improving Visual Commonsense in Language Models via Multiple Image Generation",
        "abstract": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic\ncommonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making\nprocess by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate\nour approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in\ntraditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "chunk-id": 3,
        "chunk": "process by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate",
        "authors": [
            "Guy Yariv",
            "Idan Schwartz",
            "Yossi Adi",
            "Sagie Benaim"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:17:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13621v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13621v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000059,
        "doi": null,
        "title": "Improving Visual Commonsense in Language Models via Multiple Image Generation",
        "abstract": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic\ncommonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making\nprocess by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate\nour approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in\ntraditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "chunk-id": 4,
        "chunk": "our approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in",
        "authors": [
            "Guy Yariv",
            "Idan Schwartz",
            "Yossi Adi",
            "Sagie Benaim"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:17:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13621v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13621v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000059,
        "doi": null,
        "title": "Improving Visual Commonsense in Language Models via Multiple Image Generation",
        "abstract": "Commonsense reasoning is fundamentally based on multimodal knowledge.\nHowever, existing large language models (LLMs) are primarily trained using\ntextual data only, limiting their ability to incorporate essential visual\ninformation. In contrast, Visual Language Models, which excel at\nvisually-oriented tasks, often fail at non-visual tasks such as basic\ncommonsense reasoning. This divergence highlights a critical challenge - the\nintegration of robust visual understanding with foundational text-based\nlanguage reasoning. To this end, we introduce a method aimed at enhancing LLMs'\nvisual commonsense. Specifically, our method generates multiple images based on\nthe input text prompt and integrates these into the model's decision-making\nprocess by mixing their prediction probabilities. To facilitate multimodal\ngrounded language modeling, we employ a late-fusion layer that combines the\nprojected visual features with the output of a pre-trained LLM conditioned on\ntext only. This late-fusion layer enables predictions based on comprehensive\nimage-text knowledge as well as text only when this is required. We evaluate\nour approach using several visual commonsense reasoning tasks together with\ntraditional NLP tasks, including common sense reasoning and reading\ncomprehension. Our experimental results demonstrate significant superiority\nover existing baselines. When applied to recent state-of-the-art LLMs (e.g.,\nLlama3), we observe improvements not only in visual common sense but also in\ntraditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "chunk-id": 5,
        "chunk": "traditional NLP benchmarks. Code and models are available under\nhttps://github.com/guyyariv/vLMIG.",
        "authors": [
            "Guy Yariv",
            "Idan Schwartz",
            "Yossi Adi",
            "Sagie Benaim"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T15:17:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13621v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13621v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 20000060,
        "doi": null,
        "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
        "abstract": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from\na large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits\ndistillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal\nlogits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
        "chunk-id": 1,
        "chunk": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from",
        "authors": [
            "Minchong Li",
            "Feng Zhou",
            "Xiaohui Song"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:44:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13555v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13555v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000060,
        "doi": null,
        "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
        "abstract": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from\na large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits\ndistillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal\nlogits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
        "chunk-id": 2,
        "chunk": "a large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits",
        "authors": [
            "Minchong Li",
            "Feng Zhou",
            "Xiaohui Song"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:44:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13555v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13555v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000060,
        "doi": null,
        "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
        "abstract": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from\na large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits\ndistillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal\nlogits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
        "chunk-id": 3,
        "chunk": "distillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal",
        "authors": [
            "Minchong Li",
            "Feng Zhou",
            "Xiaohui Song"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:44:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13555v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13555v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000060,
        "doi": null,
        "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
        "abstract": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from\na large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits\ndistillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal\nlogits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
        "chunk-id": 4,
        "chunk": "logits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
        "authors": [
            "Minchong Li",
            "Feng Zhou",
            "Xiaohui Song"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:44:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13555v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13555v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000061,
        "doi": null,
        "title": "Mining United Nations General Assembly Debates",
        "abstract": "This project explores the application of Natural Language Processing (NLP)\ntechniques to analyse United Nations General Assembly (UNGA) speeches. Using\nNLP allows for the efficient processing and analysis of large volumes of\ntextual data, enabling the extraction of semantic patterns, sentiment analysis,\nand topic modelling. Our goal is to deliver a comprehensive dataset and a tool\n(interface with descriptive statistics and automatically extracted topics) from\nwhich political scientists can derive insights into international relations and\nhave the opportunity to have a nuanced understanding of global diplomatic\ndiscourse.",
        "chunk-id": 1,
        "chunk": "This project explores the application of Natural Language Processing (NLP)\ntechniques to analyse United Nations General Assembly (UNGA) speeches. Using\nNLP allows for the efficient processing and analysis of large volumes of\ntextual data, enabling the extraction of semantic patterns, sentiment analysis,\nand topic modelling. Our goal is to deliver a comprehensive dataset and a tool",
        "authors": [
            "Mateusz Grzyb",
            "Mateusz Krzyzi\u0144ski",
            "Bart\u0142omiej Sobieski",
            "Miko\u0142aj Spytek",
            "Bartosz Pieli\u0144ski",
            "Daniel Dan",
            "Anna Wr\u00f3blewska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:43:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13553v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13553v1",
        "categories": [
            "Computation and Language",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000061,
        "doi": null,
        "title": "Mining United Nations General Assembly Debates",
        "abstract": "This project explores the application of Natural Language Processing (NLP)\ntechniques to analyse United Nations General Assembly (UNGA) speeches. Using\nNLP allows for the efficient processing and analysis of large volumes of\ntextual data, enabling the extraction of semantic patterns, sentiment analysis,\nand topic modelling. Our goal is to deliver a comprehensive dataset and a tool\n(interface with descriptive statistics and automatically extracted topics) from\nwhich political scientists can derive insights into international relations and\nhave the opportunity to have a nuanced understanding of global diplomatic\ndiscourse.",
        "chunk-id": 2,
        "chunk": "(interface with descriptive statistics and automatically extracted topics) from\nwhich political scientists can derive insights into international relations and\nhave the opportunity to have a nuanced understanding of global diplomatic\ndiscourse.",
        "authors": [
            "Mateusz Grzyb",
            "Mateusz Krzyzi\u0144ski",
            "Bart\u0142omiej Sobieski",
            "Miko\u0142aj Spytek",
            "Bartosz Pieli\u0144ski",
            "Daniel Dan",
            "Anna Wr\u00f3blewska"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T13:43:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13553v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13553v1",
        "categories": [
            "Computation and Language",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000062,
        "doi": null,
        "title": "Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators",
        "abstract": "Large Language Models (LLMs) tend to be unreliable in the factuality of their\nanswers. To address this problem, NLP researchers have proposed a range of\ntechniques to estimate LLM's confidence over facts. However, due to the lack of\na systematic comparison, it is not clear how the different methods compare to\none another. To fill this gap, we present a survey and empirical comparison of\nestimators of factual confidence. We define an experimental framework allowing\nfor fair comparison, covering both fact-verification and question answering.\nOur experiments across a series of LLMs indicate that trained hidden-state\nprobes provide the most reliable confidence estimates, albeit at the expense of\nrequiring access to weights and training data. We also conduct a deeper\nassessment of factual confidence by measuring the consistency of model behavior\nunder meaning-preserving variations in the input. We find that the confidence\nof LLMs is often unstable across semantically equivalent inputs, suggesting\nthat there is much room for improvement of the stability of models' parametric\nknowledge. Our code is available at\n(https://github.com/amazon-science/factual-confidence-of-llms).",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) tend to be unreliable in the factuality of their\nanswers. To address this problem, NLP researchers have proposed a range of\ntechniques to estimate LLM's confidence over facts. However, due to the lack of\na systematic comparison, it is not clear how the different methods compare to",
        "authors": [
            "Mat\u00e9o Mahaut",
            "Laura Aina",
            "Paula Czarnowska",
            "Momchil Hardalov",
            "Thomas M\u00fcller",
            "Llu\u00eds M\u00e0rquez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T10:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13415v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13415v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000062,
        "doi": null,
        "title": "Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators",
        "abstract": "Large Language Models (LLMs) tend to be unreliable in the factuality of their\nanswers. To address this problem, NLP researchers have proposed a range of\ntechniques to estimate LLM's confidence over facts. However, due to the lack of\na systematic comparison, it is not clear how the different methods compare to\none another. To fill this gap, we present a survey and empirical comparison of\nestimators of factual confidence. We define an experimental framework allowing\nfor fair comparison, covering both fact-verification and question answering.\nOur experiments across a series of LLMs indicate that trained hidden-state\nprobes provide the most reliable confidence estimates, albeit at the expense of\nrequiring access to weights and training data. We also conduct a deeper\nassessment of factual confidence by measuring the consistency of model behavior\nunder meaning-preserving variations in the input. We find that the confidence\nof LLMs is often unstable across semantically equivalent inputs, suggesting\nthat there is much room for improvement of the stability of models' parametric\nknowledge. Our code is available at\n(https://github.com/amazon-science/factual-confidence-of-llms).",
        "chunk-id": 2,
        "chunk": "one another. To fill this gap, we present a survey and empirical comparison of\nestimators of factual confidence. We define an experimental framework allowing\nfor fair comparison, covering both fact-verification and question answering.\nOur experiments across a series of LLMs indicate that trained hidden-state",
        "authors": [
            "Mat\u00e9o Mahaut",
            "Laura Aina",
            "Paula Czarnowska",
            "Momchil Hardalov",
            "Thomas M\u00fcller",
            "Llu\u00eds M\u00e0rquez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T10:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13415v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13415v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000062,
        "doi": null,
        "title": "Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators",
        "abstract": "Large Language Models (LLMs) tend to be unreliable in the factuality of their\nanswers. To address this problem, NLP researchers have proposed a range of\ntechniques to estimate LLM's confidence over facts. However, due to the lack of\na systematic comparison, it is not clear how the different methods compare to\none another. To fill this gap, we present a survey and empirical comparison of\nestimators of factual confidence. We define an experimental framework allowing\nfor fair comparison, covering both fact-verification and question answering.\nOur experiments across a series of LLMs indicate that trained hidden-state\nprobes provide the most reliable confidence estimates, albeit at the expense of\nrequiring access to weights and training data. We also conduct a deeper\nassessment of factual confidence by measuring the consistency of model behavior\nunder meaning-preserving variations in the input. We find that the confidence\nof LLMs is often unstable across semantically equivalent inputs, suggesting\nthat there is much room for improvement of the stability of models' parametric\nknowledge. Our code is available at\n(https://github.com/amazon-science/factual-confidence-of-llms).",
        "chunk-id": 3,
        "chunk": "probes provide the most reliable confidence estimates, albeit at the expense of\nrequiring access to weights and training data. We also conduct a deeper\nassessment of factual confidence by measuring the consistency of model behavior\nunder meaning-preserving variations in the input. We find that the confidence",
        "authors": [
            "Mat\u00e9o Mahaut",
            "Laura Aina",
            "Paula Czarnowska",
            "Momchil Hardalov",
            "Thomas M\u00fcller",
            "Llu\u00eds M\u00e0rquez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T10:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13415v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13415v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000062,
        "doi": null,
        "title": "Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators",
        "abstract": "Large Language Models (LLMs) tend to be unreliable in the factuality of their\nanswers. To address this problem, NLP researchers have proposed a range of\ntechniques to estimate LLM's confidence over facts. However, due to the lack of\na systematic comparison, it is not clear how the different methods compare to\none another. To fill this gap, we present a survey and empirical comparison of\nestimators of factual confidence. We define an experimental framework allowing\nfor fair comparison, covering both fact-verification and question answering.\nOur experiments across a series of LLMs indicate that trained hidden-state\nprobes provide the most reliable confidence estimates, albeit at the expense of\nrequiring access to weights and training data. We also conduct a deeper\nassessment of factual confidence by measuring the consistency of model behavior\nunder meaning-preserving variations in the input. We find that the confidence\nof LLMs is often unstable across semantically equivalent inputs, suggesting\nthat there is much room for improvement of the stability of models' parametric\nknowledge. Our code is available at\n(https://github.com/amazon-science/factual-confidence-of-llms).",
        "chunk-id": 4,
        "chunk": "of LLMs is often unstable across semantically equivalent inputs, suggesting\nthat there is much room for improvement of the stability of models' parametric\nknowledge. Our code is available at\n(https://github.com/amazon-science/factual-confidence-of-llms).",
        "authors": [
            "Mat\u00e9o Mahaut",
            "Laura Aina",
            "Paula Czarnowska",
            "Momchil Hardalov",
            "Thomas M\u00fcller",
            "Llu\u00eds M\u00e0rquez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T10:11:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13415v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13415v1",
        "categories": [
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 20000063,
        "doi": null,
        "title": "CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration",
        "abstract": "Existing LLMs exhibit remarkable performance on various NLP tasks, but still\nstruggle with complex real-world tasks, even equipped with advanced strategies\nlike CoT and ReAct. In this work, we propose the CoAct framework, which\ntransfers the hierarchical planning and collaboration patterns in human society\nto LLM systems. Specifically, our CoAct framework involves two agents: (1) A\nglobal planning agent, to comprehend the problem scope, formulate macro-level\nplans and provide detailed sub-task descriptions to local execution agents,\nwhich serves as the initial rendition of a global plan. (2) A local execution\nagent, to operate within the multi-tier task execution structure, focusing on\ndetailed execution and implementation of specific tasks within the global plan.\nExperimental results on the WebArena benchmark show that CoAct can re-arrange\nthe process trajectory when facing failures, and achieves superior performance\nover baseline methods on long-horizon web tasks. Code is available at\nhttps://github.com/xmhou2002/CoAct.",
        "chunk-id": 1,
        "chunk": "Existing LLMs exhibit remarkable performance on various NLP tasks, but still\nstruggle with complex real-world tasks, even equipped with advanced strategies\nlike CoT and ReAct. In this work, we propose the CoAct framework, which\ntransfers the hierarchical planning and collaboration patterns in human society\nto LLM systems. Specifically, our CoAct framework involves two agents: (1) A",
        "authors": [
            "Xinming Hou",
            "Mingming Yang",
            "Wenxiang Jiao",
            "Xing Wang",
            "Zhaopeng Tu",
            "Wayne Xin Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T09:23:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13381v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13381v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000063,
        "doi": null,
        "title": "CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration",
        "abstract": "Existing LLMs exhibit remarkable performance on various NLP tasks, but still\nstruggle with complex real-world tasks, even equipped with advanced strategies\nlike CoT and ReAct. In this work, we propose the CoAct framework, which\ntransfers the hierarchical planning and collaboration patterns in human society\nto LLM systems. Specifically, our CoAct framework involves two agents: (1) A\nglobal planning agent, to comprehend the problem scope, formulate macro-level\nplans and provide detailed sub-task descriptions to local execution agents,\nwhich serves as the initial rendition of a global plan. (2) A local execution\nagent, to operate within the multi-tier task execution structure, focusing on\ndetailed execution and implementation of specific tasks within the global plan.\nExperimental results on the WebArena benchmark show that CoAct can re-arrange\nthe process trajectory when facing failures, and achieves superior performance\nover baseline methods on long-horizon web tasks. Code is available at\nhttps://github.com/xmhou2002/CoAct.",
        "chunk-id": 2,
        "chunk": "global planning agent, to comprehend the problem scope, formulate macro-level\nplans and provide detailed sub-task descriptions to local execution agents,\nwhich serves as the initial rendition of a global plan. (2) A local execution\nagent, to operate within the multi-tier task execution structure, focusing on",
        "authors": [
            "Xinming Hou",
            "Mingming Yang",
            "Wenxiang Jiao",
            "Xing Wang",
            "Zhaopeng Tu",
            "Wayne Xin Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T09:23:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13381v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13381v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000063,
        "doi": null,
        "title": "CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration",
        "abstract": "Existing LLMs exhibit remarkable performance on various NLP tasks, but still\nstruggle with complex real-world tasks, even equipped with advanced strategies\nlike CoT and ReAct. In this work, we propose the CoAct framework, which\ntransfers the hierarchical planning and collaboration patterns in human society\nto LLM systems. Specifically, our CoAct framework involves two agents: (1) A\nglobal planning agent, to comprehend the problem scope, formulate macro-level\nplans and provide detailed sub-task descriptions to local execution agents,\nwhich serves as the initial rendition of a global plan. (2) A local execution\nagent, to operate within the multi-tier task execution structure, focusing on\ndetailed execution and implementation of specific tasks within the global plan.\nExperimental results on the WebArena benchmark show that CoAct can re-arrange\nthe process trajectory when facing failures, and achieves superior performance\nover baseline methods on long-horizon web tasks. Code is available at\nhttps://github.com/xmhou2002/CoAct.",
        "chunk-id": 3,
        "chunk": "detailed execution and implementation of specific tasks within the global plan.\nExperimental results on the WebArena benchmark show that CoAct can re-arrange\nthe process trajectory when facing failures, and achieves superior performance\nover baseline methods on long-horizon web tasks. Code is available at\nhttps://github.com/xmhou2002/CoAct.",
        "authors": [
            "Xinming Hou",
            "Mingming Yang",
            "Wenxiang Jiao",
            "Xing Wang",
            "Zhaopeng Tu",
            "Wayne Xin Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T09:23:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13381v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13381v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000064,
        "doi": null,
        "title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models",
        "abstract": "The recent advancements in large language models (LLMs) have brought\nsignificant progress in solving NLP tasks. Notably, in-context learning (ICL)\nis the key enabling mechanism for LLMs to understand specific tasks and\ngrasping nuances. In this paper, we propose a simple yet effective method to\ncontextualize a task toward a specific LLM, by (1) observing how a given LLM\ndescribes (all or a part of) target datasets, i.e., open-ended zero-shot\ninference, and (2) aggregating the open-ended inference results by the LLM, and\n(3) finally incorporate the aggregated meta-information for the actual task. We\nshow the effectiveness of this approach in text clustering tasks, and also\nhighlight the importance of the contextualization through examples of the above\nprocedure.",
        "chunk-id": 1,
        "chunk": "The recent advancements in large language models (LLMs) have brought\nsignificant progress in solving NLP tasks. Notably, in-context learning (ICL)\nis the key enabling mechanism for LLMs to understand specific tasks and\ngrasping nuances. In this paper, we propose a simple yet effective method to\ncontextualize a task toward a specific LLM, by (1) observing how a given LLM",
        "authors": [
            "Hwiyeol Jo",
            "Hyunwoo Lee",
            "Taiwoo Park"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T08:48:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13342v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13342v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000064,
        "doi": null,
        "title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models",
        "abstract": "The recent advancements in large language models (LLMs) have brought\nsignificant progress in solving NLP tasks. Notably, in-context learning (ICL)\nis the key enabling mechanism for LLMs to understand specific tasks and\ngrasping nuances. In this paper, we propose a simple yet effective method to\ncontextualize a task toward a specific LLM, by (1) observing how a given LLM\ndescribes (all or a part of) target datasets, i.e., open-ended zero-shot\ninference, and (2) aggregating the open-ended inference results by the LLM, and\n(3) finally incorporate the aggregated meta-information for the actual task. We\nshow the effectiveness of this approach in text clustering tasks, and also\nhighlight the importance of the contextualization through examples of the above\nprocedure.",
        "chunk-id": 2,
        "chunk": "describes (all or a part of) target datasets, i.e., open-ended zero-shot\ninference, and (2) aggregating the open-ended inference results by the LLM, and\n(3) finally incorporate the aggregated meta-information for the actual task. We\nshow the effectiveness of this approach in text clustering tasks, and also",
        "authors": [
            "Hwiyeol Jo",
            "Hyunwoo Lee",
            "Taiwoo Park"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T08:48:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13342v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13342v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000064,
        "doi": null,
        "title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models",
        "abstract": "The recent advancements in large language models (LLMs) have brought\nsignificant progress in solving NLP tasks. Notably, in-context learning (ICL)\nis the key enabling mechanism for LLMs to understand specific tasks and\ngrasping nuances. In this paper, we propose a simple yet effective method to\ncontextualize a task toward a specific LLM, by (1) observing how a given LLM\ndescribes (all or a part of) target datasets, i.e., open-ended zero-shot\ninference, and (2) aggregating the open-ended inference results by the LLM, and\n(3) finally incorporate the aggregated meta-information for the actual task. We\nshow the effectiveness of this approach in text clustering tasks, and also\nhighlight the importance of the contextualization through examples of the above\nprocedure.",
        "chunk-id": 3,
        "chunk": "highlight the importance of the contextualization through examples of the above\nprocedure.",
        "authors": [
            "Hwiyeol Jo",
            "Hyunwoo Lee",
            "Taiwoo Park"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T08:48:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13342v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13342v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000065,
        "doi": null,
        "title": "BeHonest: Benchmarking Honesty of Large Language Models",
        "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that\nintensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to\nprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "chunk-id": 1,
        "chunk": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that",
        "authors": [
            "Steffi Chern",
            "Zhulin Hu",
            "Yuqing Yang",
            "Ethan Chern",
            "Yuan Guo",
            "Jiahe Jin",
            "Binjie Wang",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T06:46:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13261v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000065,
        "doi": null,
        "title": "BeHonest: Benchmarking Honesty of Large Language Models",
        "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that\nintensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to\nprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "chunk-id": 2,
        "chunk": "intensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.",
        "authors": [
            "Steffi Chern",
            "Zhulin Hu",
            "Yuqing Yang",
            "Ethan Chern",
            "Yuan Guo",
            "Jiahe Jin",
            "Binjie Wang",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T06:46:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13261v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000065,
        "doi": null,
        "title": "BeHonest: Benchmarking Honesty of Large Language Models",
        "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that\nintensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to\nprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "chunk-id": 3,
        "chunk": "In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed",
        "authors": [
            "Steffi Chern",
            "Zhulin Hu",
            "Yuqing Yang",
            "Ethan Chern",
            "Yuan Guo",
            "Jiahe Jin",
            "Binjie Wang",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T06:46:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13261v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000065,
        "doi": null,
        "title": "BeHonest: Benchmarking Honesty of Large Language Models",
        "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that\nintensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to\nprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "chunk-id": 4,
        "chunk": "10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to",
        "authors": [
            "Steffi Chern",
            "Zhulin Hu",
            "Yuqing Yang",
            "Ethan Chern",
            "Yuan Guo",
            "Jiahe Jin",
            "Binjie Wang",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T06:46:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13261v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000065,
        "doi": null,
        "title": "BeHonest: Benchmarking Honesty of Large Language Models",
        "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\neroding user trust, and causing real-world harm, present severe risks that\nintensify as these models approach superintelligence levels. Enhancing honesty\nin LLMs addresses critical deficiencies and helps uncover latent capabilities\nthat are not readily expressed. This underscores the urgent need for reliable\nmethods and benchmarks to effectively ensure and evaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We also encourage the AI community to\nprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "chunk-id": 5,
        "chunk": "prioritize honesty alignment in LLMs. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
        "authors": [
            "Steffi Chern",
            "Zhulin Hu",
            "Yuqing Yang",
            "Ethan Chern",
            "Yuan Guo",
            "Jiahe Jin",
            "Binjie Wang",
            "Pengfei Liu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T06:46:59+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13261v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13261v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000066,
        "doi": null,
        "title": "Learnable In-Context Vector for Visual Question Answering",
        "abstract": "As language models continue to scale, Large Language Models (LLMs) have\nexhibited emerging capabilities in In-Context Learning (ICL), enabling them to\nsolve language tasks by prefixing a few in-context demonstrations (ICDs) as\ncontext. Inspired by these advancements, researchers have extended these\ntechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.\nHowever, applying ICL usually faces two major challenges: 1) using more ICDs\nwill largely increase the inference time and 2) the performance is sensitive to\nthe selection of ICDs. These challenges are further exacerbated in LMMs due to\nthe integration of multiple data types and the combinational complexity of\nmultimodal ICDs. Recently, to address these challenges, some NLP studies\nintroduce non-learnable In-Context Vectors (ICVs) which extract useful task\ninformation from ICDs into a single vector and then insert it into the LLM to\nhelp solve the corresponding task. However, although useful in simple NLP\ntasks, these non-learnable methods fail to handle complex multimodal tasks like\nVisual Question Answering (VQA). In this study, we propose \\textbf{Learnable\nICV} (L-ICV) to distill essential task information from demonstrations,\nimproving ICL performance in LMMs. Experiments show that L-ICV can\nsignificantly reduce computational costs while enhancing accuracy in VQA tasks\ncompared to traditional ICL and other non-learnable ICV methods.",
        "chunk-id": 1,
        "chunk": "As language models continue to scale, Large Language Models (LLMs) have\nexhibited emerging capabilities in In-Context Learning (ICL), enabling them to\nsolve language tasks by prefixing a few in-context demonstrations (ICDs) as\ncontext. Inspired by these advancements, researchers have extended these\ntechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.",
        "authors": [
            "Yingzhe Peng",
            "Chenduo Hao",
            "Xu Yang",
            "Jiawei Peng",
            "Xinting Hu",
            "Xin Geng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T03:33:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13185v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000066,
        "doi": null,
        "title": "Learnable In-Context Vector for Visual Question Answering",
        "abstract": "As language models continue to scale, Large Language Models (LLMs) have\nexhibited emerging capabilities in In-Context Learning (ICL), enabling them to\nsolve language tasks by prefixing a few in-context demonstrations (ICDs) as\ncontext. Inspired by these advancements, researchers have extended these\ntechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.\nHowever, applying ICL usually faces two major challenges: 1) using more ICDs\nwill largely increase the inference time and 2) the performance is sensitive to\nthe selection of ICDs. These challenges are further exacerbated in LMMs due to\nthe integration of multiple data types and the combinational complexity of\nmultimodal ICDs. Recently, to address these challenges, some NLP studies\nintroduce non-learnable In-Context Vectors (ICVs) which extract useful task\ninformation from ICDs into a single vector and then insert it into the LLM to\nhelp solve the corresponding task. However, although useful in simple NLP\ntasks, these non-learnable methods fail to handle complex multimodal tasks like\nVisual Question Answering (VQA). In this study, we propose \\textbf{Learnable\nICV} (L-ICV) to distill essential task information from demonstrations,\nimproving ICL performance in LMMs. Experiments show that L-ICV can\nsignificantly reduce computational costs while enhancing accuracy in VQA tasks\ncompared to traditional ICL and other non-learnable ICV methods.",
        "chunk-id": 2,
        "chunk": "However, applying ICL usually faces two major challenges: 1) using more ICDs\nwill largely increase the inference time and 2) the performance is sensitive to\nthe selection of ICDs. These challenges are further exacerbated in LMMs due to\nthe integration of multiple data types and the combinational complexity of\nmultimodal ICDs. Recently, to address these challenges, some NLP studies",
        "authors": [
            "Yingzhe Peng",
            "Chenduo Hao",
            "Xu Yang",
            "Jiawei Peng",
            "Xinting Hu",
            "Xin Geng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T03:33:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13185v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000066,
        "doi": null,
        "title": "Learnable In-Context Vector for Visual Question Answering",
        "abstract": "As language models continue to scale, Large Language Models (LLMs) have\nexhibited emerging capabilities in In-Context Learning (ICL), enabling them to\nsolve language tasks by prefixing a few in-context demonstrations (ICDs) as\ncontext. Inspired by these advancements, researchers have extended these\ntechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.\nHowever, applying ICL usually faces two major challenges: 1) using more ICDs\nwill largely increase the inference time and 2) the performance is sensitive to\nthe selection of ICDs. These challenges are further exacerbated in LMMs due to\nthe integration of multiple data types and the combinational complexity of\nmultimodal ICDs. Recently, to address these challenges, some NLP studies\nintroduce non-learnable In-Context Vectors (ICVs) which extract useful task\ninformation from ICDs into a single vector and then insert it into the LLM to\nhelp solve the corresponding task. However, although useful in simple NLP\ntasks, these non-learnable methods fail to handle complex multimodal tasks like\nVisual Question Answering (VQA). In this study, we propose \\textbf{Learnable\nICV} (L-ICV) to distill essential task information from demonstrations,\nimproving ICL performance in LMMs. Experiments show that L-ICV can\nsignificantly reduce computational costs while enhancing accuracy in VQA tasks\ncompared to traditional ICL and other non-learnable ICV methods.",
        "chunk-id": 3,
        "chunk": "introduce non-learnable In-Context Vectors (ICVs) which extract useful task\ninformation from ICDs into a single vector and then insert it into the LLM to\nhelp solve the corresponding task. However, although useful in simple NLP\ntasks, these non-learnable methods fail to handle complex multimodal tasks like\nVisual Question Answering (VQA). In this study, we propose \\textbf{Learnable",
        "authors": [
            "Yingzhe Peng",
            "Chenduo Hao",
            "Xu Yang",
            "Jiawei Peng",
            "Xinting Hu",
            "Xin Geng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T03:33:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13185v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000066,
        "doi": null,
        "title": "Learnable In-Context Vector for Visual Question Answering",
        "abstract": "As language models continue to scale, Large Language Models (LLMs) have\nexhibited emerging capabilities in In-Context Learning (ICL), enabling them to\nsolve language tasks by prefixing a few in-context demonstrations (ICDs) as\ncontext. Inspired by these advancements, researchers have extended these\ntechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.\nHowever, applying ICL usually faces two major challenges: 1) using more ICDs\nwill largely increase the inference time and 2) the performance is sensitive to\nthe selection of ICDs. These challenges are further exacerbated in LMMs due to\nthe integration of multiple data types and the combinational complexity of\nmultimodal ICDs. Recently, to address these challenges, some NLP studies\nintroduce non-learnable In-Context Vectors (ICVs) which extract useful task\ninformation from ICDs into a single vector and then insert it into the LLM to\nhelp solve the corresponding task. However, although useful in simple NLP\ntasks, these non-learnable methods fail to handle complex multimodal tasks like\nVisual Question Answering (VQA). In this study, we propose \\textbf{Learnable\nICV} (L-ICV) to distill essential task information from demonstrations,\nimproving ICL performance in LMMs. Experiments show that L-ICV can\nsignificantly reduce computational costs while enhancing accuracy in VQA tasks\ncompared to traditional ICL and other non-learnable ICV methods.",
        "chunk-id": 4,
        "chunk": "ICV} (L-ICV) to distill essential task information from demonstrations,\nimproving ICL performance in LMMs. Experiments show that L-ICV can\nsignificantly reduce computational costs while enhancing accuracy in VQA tasks\ncompared to traditional ICL and other non-learnable ICV methods.",
        "authors": [
            "Yingzhe Peng",
            "Chenduo Hao",
            "Xu Yang",
            "Jiawei Peng",
            "Xinting Hu",
            "Xin Geng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-19T03:33:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13185v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000067,
        "doi": null,
        "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
        "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
        "chunk-id": 1,
        "chunk": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has",
        "authors": [
            "Harrison Gietz",
            "Jugal Kalita"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T21:27:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13066v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000067,
        "doi": null,
        "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
        "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
        "chunk-id": 2,
        "chunk": "explored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our",
        "authors": [
            "Harrison Gietz",
            "Jugal Kalita"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T21:27:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13066v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000067,
        "doi": null,
        "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
        "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
        "chunk-id": 3,
        "chunk": "novel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both",
        "authors": [
            "Harrison Gietz",
            "Jugal Kalita"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T21:27:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13066v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000067,
        "doi": null,
        "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
        "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
        "chunk-id": 4,
        "chunk": "character-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at",
        "authors": [
            "Harrison Gietz",
            "Jugal Kalita"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T21:27:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13066v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000067,
        "doi": null,
        "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
        "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
        "chunk-id": 5,
        "chunk": "https://github.com/hubarruby/MaskPure.",
        "authors": [
            "Harrison Gietz",
            "Jugal Kalita"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T21:27:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.13066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.13066v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000068,
        "doi": null,
        "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
        "abstract": "NLP in mental health has been primarily social media focused. Real world\npractitioners also have high case loads and often domain specific variables, of\nwhich modern LLMs lack context. We take a dataset made by recruiting 644\nparticipants, including individuals diagnosed with Bipolar Disorder (BD),\nSchizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks\nderived from a standardized mental health instrument, and the resulting data\nwere transcribed and annotated by experts across five clinical variables. This\npaper demonstrates the application of contemporary language models in\nsequence-to-sequence tasks to enhance mental health research. Specifically, we\nillustrate how these models can facilitate the deployment of mental health\ninstruments, data collection, and data annotation with high accuracy and\nscalability. We show that small models are capable of annotation for\ndomain-specific clinical variables, data collection for mental-health\ninstruments, and perform better then commercial large models.",
        "chunk-id": 1,
        "chunk": "NLP in mental health has been primarily social media focused. Real world\npractitioners also have high case loads and often domain specific variables, of\nwhich modern LLMs lack context. We take a dataset made by recruiting 644\nparticipants, including individuals diagnosed with Bipolar Disorder (BD),\nSchizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks",
        "authors": [
            "Ankit Aich",
            "Avery Quynh",
            "Pamela Osseyi",
            "Amy Pinkham",
            "Philip Harvey",
            "Brenda Curtis",
            "Colin Depp",
            "Natalie Parde"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T15:00:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12687v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12687v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000068,
        "doi": null,
        "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
        "abstract": "NLP in mental health has been primarily social media focused. Real world\npractitioners also have high case loads and often domain specific variables, of\nwhich modern LLMs lack context. We take a dataset made by recruiting 644\nparticipants, including individuals diagnosed with Bipolar Disorder (BD),\nSchizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks\nderived from a standardized mental health instrument, and the resulting data\nwere transcribed and annotated by experts across five clinical variables. This\npaper demonstrates the application of contemporary language models in\nsequence-to-sequence tasks to enhance mental health research. Specifically, we\nillustrate how these models can facilitate the deployment of mental health\ninstruments, data collection, and data annotation with high accuracy and\nscalability. We show that small models are capable of annotation for\ndomain-specific clinical variables, data collection for mental-health\ninstruments, and perform better then commercial large models.",
        "chunk-id": 2,
        "chunk": "derived from a standardized mental health instrument, and the resulting data\nwere transcribed and annotated by experts across five clinical variables. This\npaper demonstrates the application of contemporary language models in\nsequence-to-sequence tasks to enhance mental health research. Specifically, we\nillustrate how these models can facilitate the deployment of mental health",
        "authors": [
            "Ankit Aich",
            "Avery Quynh",
            "Pamela Osseyi",
            "Amy Pinkham",
            "Philip Harvey",
            "Brenda Curtis",
            "Colin Depp",
            "Natalie Parde"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T15:00:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12687v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12687v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000068,
        "doi": null,
        "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
        "abstract": "NLP in mental health has been primarily social media focused. Real world\npractitioners also have high case loads and often domain specific variables, of\nwhich modern LLMs lack context. We take a dataset made by recruiting 644\nparticipants, including individuals diagnosed with Bipolar Disorder (BD),\nSchizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks\nderived from a standardized mental health instrument, and the resulting data\nwere transcribed and annotated by experts across five clinical variables. This\npaper demonstrates the application of contemporary language models in\nsequence-to-sequence tasks to enhance mental health research. Specifically, we\nillustrate how these models can facilitate the deployment of mental health\ninstruments, data collection, and data annotation with high accuracy and\nscalability. We show that small models are capable of annotation for\ndomain-specific clinical variables, data collection for mental-health\ninstruments, and perform better then commercial large models.",
        "chunk-id": 3,
        "chunk": "instruments, data collection, and data annotation with high accuracy and\nscalability. We show that small models are capable of annotation for\ndomain-specific clinical variables, data collection for mental-health\ninstruments, and perform better then commercial large models.",
        "authors": [
            "Ankit Aich",
            "Avery Quynh",
            "Pamela Osseyi",
            "Amy Pinkham",
            "Philip Harvey",
            "Brenda Curtis",
            "Colin Depp",
            "Natalie Parde"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T15:00:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12687v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12687v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000069,
        "doi": null,
        "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
        "abstract": "Interpretability and analysis (IA) research is a growing subfield within NLP\nwith the goal of developing a deeper understanding of the behavior or inner\nworkings of NLP systems and methods. Despite growing interest in the subfield,\na commonly voiced criticism is that it lacks actionable insights and therefore\nhas little impact on NLP. In this paper, we seek to quantify the impact of IA\nresearch on the broader field of NLP. We approach this with a mixed-methods\nanalysis of: (1) a citation graph of 185K+ papers built from all papers\npublished at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of\n138 members of the NLP community. Our quantitative results show that IA work is\nwell-cited outside of IA, and central in the NLP citation graph. Through\nqualitative analysis of survey responses and manual annotation of 556 papers,\nwe find that NLP researchers build on findings from IA work and perceive it is\nimportant for progress in NLP, multiple subfields, and rely on its findings and\nterminology for their own work. Many novel methods are proposed based on IA\nfindings and highly influenced by them, but highly influential non-IA work\ncites IA findings without being driven by them. We end by summarizing what is\nmissing in IA work today and provide a call to action, to pave the way for a\nmore impactful future of IA research.",
        "chunk-id": 1,
        "chunk": "Interpretability and analysis (IA) research is a growing subfield within NLP\nwith the goal of developing a deeper understanding of the behavior or inner\nworkings of NLP systems and methods. Despite growing interest in the subfield,\na commonly voiced criticism is that it lacks actionable insights and therefore",
        "authors": [
            "Marius Mosbach",
            "Vagrant Gautam",
            "Tom\u00e1s Vergara-Browne",
            "Dietrich Klakow",
            "Mor Geva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T13:45:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12618v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12618v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000069,
        "doi": null,
        "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
        "abstract": "Interpretability and analysis (IA) research is a growing subfield within NLP\nwith the goal of developing a deeper understanding of the behavior or inner\nworkings of NLP systems and methods. Despite growing interest in the subfield,\na commonly voiced criticism is that it lacks actionable insights and therefore\nhas little impact on NLP. In this paper, we seek to quantify the impact of IA\nresearch on the broader field of NLP. We approach this with a mixed-methods\nanalysis of: (1) a citation graph of 185K+ papers built from all papers\npublished at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of\n138 members of the NLP community. Our quantitative results show that IA work is\nwell-cited outside of IA, and central in the NLP citation graph. Through\nqualitative analysis of survey responses and manual annotation of 556 papers,\nwe find that NLP researchers build on findings from IA work and perceive it is\nimportant for progress in NLP, multiple subfields, and rely on its findings and\nterminology for their own work. Many novel methods are proposed based on IA\nfindings and highly influenced by them, but highly influential non-IA work\ncites IA findings without being driven by them. We end by summarizing what is\nmissing in IA work today and provide a call to action, to pave the way for a\nmore impactful future of IA research.",
        "chunk-id": 2,
        "chunk": "has little impact on NLP. In this paper, we seek to quantify the impact of IA\nresearch on the broader field of NLP. We approach this with a mixed-methods\nanalysis of: (1) a citation graph of 185K+ papers built from all papers\npublished at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of\n138 members of the NLP community. Our quantitative results show that IA work is",
        "authors": [
            "Marius Mosbach",
            "Vagrant Gautam",
            "Tom\u00e1s Vergara-Browne",
            "Dietrich Klakow",
            "Mor Geva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T13:45:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12618v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12618v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000069,
        "doi": null,
        "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
        "abstract": "Interpretability and analysis (IA) research is a growing subfield within NLP\nwith the goal of developing a deeper understanding of the behavior or inner\nworkings of NLP systems and methods. Despite growing interest in the subfield,\na commonly voiced criticism is that it lacks actionable insights and therefore\nhas little impact on NLP. In this paper, we seek to quantify the impact of IA\nresearch on the broader field of NLP. We approach this with a mixed-methods\nanalysis of: (1) a citation graph of 185K+ papers built from all papers\npublished at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of\n138 members of the NLP community. Our quantitative results show that IA work is\nwell-cited outside of IA, and central in the NLP citation graph. Through\nqualitative analysis of survey responses and manual annotation of 556 papers,\nwe find that NLP researchers build on findings from IA work and perceive it is\nimportant for progress in NLP, multiple subfields, and rely on its findings and\nterminology for their own work. Many novel methods are proposed based on IA\nfindings and highly influenced by them, but highly influential non-IA work\ncites IA findings without being driven by them. We end by summarizing what is\nmissing in IA work today and provide a call to action, to pave the way for a\nmore impactful future of IA research.",
        "chunk-id": 3,
        "chunk": "well-cited outside of IA, and central in the NLP citation graph. Through\nqualitative analysis of survey responses and manual annotation of 556 papers,\nwe find that NLP researchers build on findings from IA work and perceive it is\nimportant for progress in NLP, multiple subfields, and rely on its findings and",
        "authors": [
            "Marius Mosbach",
            "Vagrant Gautam",
            "Tom\u00e1s Vergara-Browne",
            "Dietrich Klakow",
            "Mor Geva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T13:45:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12618v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12618v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000069,
        "doi": null,
        "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
        "abstract": "Interpretability and analysis (IA) research is a growing subfield within NLP\nwith the goal of developing a deeper understanding of the behavior or inner\nworkings of NLP systems and methods. Despite growing interest in the subfield,\na commonly voiced criticism is that it lacks actionable insights and therefore\nhas little impact on NLP. In this paper, we seek to quantify the impact of IA\nresearch on the broader field of NLP. We approach this with a mixed-methods\nanalysis of: (1) a citation graph of 185K+ papers built from all papers\npublished at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of\n138 members of the NLP community. Our quantitative results show that IA work is\nwell-cited outside of IA, and central in the NLP citation graph. Through\nqualitative analysis of survey responses and manual annotation of 556 papers,\nwe find that NLP researchers build on findings from IA work and perceive it is\nimportant for progress in NLP, multiple subfields, and rely on its findings and\nterminology for their own work. Many novel methods are proposed based on IA\nfindings and highly influenced by them, but highly influential non-IA work\ncites IA findings without being driven by them. We end by summarizing what is\nmissing in IA work today and provide a call to action, to pave the way for a\nmore impactful future of IA research.",
        "chunk-id": 4,
        "chunk": "terminology for their own work. Many novel methods are proposed based on IA\nfindings and highly influenced by them, but highly influential non-IA work\ncites IA findings without being driven by them. We end by summarizing what is\nmissing in IA work today and provide a call to action, to pave the way for a\nmore impactful future of IA research.",
        "authors": [
            "Marius Mosbach",
            "Vagrant Gautam",
            "Tom\u00e1s Vergara-Browne",
            "Dietrich Klakow",
            "Mor Geva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T13:45:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12618v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12618v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000070,
        "doi": null,
        "title": "QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities",
        "abstract": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of\nLGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based\napproach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness.",
        "chunk-id": 1,
        "chunk": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of",
        "authors": [
            "Mae Sosto",
            "Alberto Barr\u00f3n-Cede\u00f1o"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T08:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12399v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12399v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000070,
        "doi": null,
        "title": "QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities",
        "abstract": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of\nLGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based\napproach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness.",
        "chunk-id": 2,
        "chunk": "LGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based",
        "authors": [
            "Mae Sosto",
            "Alberto Barr\u00f3n-Cede\u00f1o"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T08:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12399v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12399v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000070,
        "doi": null,
        "title": "QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities",
        "abstract": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of\nLGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based\napproach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness.",
        "chunk-id": 3,
        "chunk": "approach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness.",
        "authors": [
            "Mae Sosto",
            "Alberto Barr\u00f3n-Cede\u00f1o"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T08:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12399v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12399v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000071,
        "doi": null,
        "title": "Interpreting Bias in Large Language Models: A Feature-Based Approach",
        "abstract": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing\ninspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in\nLLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing\nusing a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing",
        "authors": [
            "Nirmalendu Prakash",
            "Lee Ka Wei Roy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T07:28:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12347v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12347v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000071,
        "doi": null,
        "title": "Interpreting Bias in Large Language Models: A Feature-Based Approach",
        "abstract": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing\ninspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in\nLLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing\nusing a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation.",
        "chunk-id": 2,
        "chunk": "inspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in",
        "authors": [
            "Nirmalendu Prakash",
            "Lee Ka Wei Roy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T07:28:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12347v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12347v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000071,
        "doi": null,
        "title": "Interpreting Bias in Large Language Models: A Feature-Based Approach",
        "abstract": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing\ninspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in\nLLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing\nusing a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation.",
        "chunk-id": 3,
        "chunk": "LLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing",
        "authors": [
            "Nirmalendu Prakash",
            "Lee Ka Wei Roy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T07:28:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12347v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12347v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000071,
        "doi": null,
        "title": "Interpreting Bias in Large Language Models: A Feature-Based Approach",
        "abstract": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing\ninspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in\nLLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing\nusing a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation.",
        "chunk-id": 4,
        "chunk": "using a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation.",
        "authors": [
            "Nirmalendu Prakash",
            "Lee Ka Wei Roy"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T07:28:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12347v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12347v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000072,
        "doi": null,
        "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
        "abstract": "Instruction-following large language models (LLMs), such as ChatGPT, have\nbecome increasingly popular with the general audience, many of whom are\nincorporating them into their daily routines. However, these LLMs inadvertently\ndisclose personal or copyrighted information, which calls for a machine\nunlearning method to remove selective knowledge. Previous attempts sought to\nforget the link between the target information and its associated entities, but\nit rather led to generating undesirable responses about the target,\ncompromising the end-user experience. In this work, we propose SNAP, an\ninnovative framework designed to selectively unlearn information by 1) training\nan LLM with negative instructions to generate obliterated responses, 2)\naugmenting hard positives to retain the original LLM performance, and 3)\napplying the novel Wasserstein regularization to ensure adequate deviation from\nthe initial weights of the LLM. We evaluate our framework on various NLP\nbenchmarks and demonstrate that our approach retains the original LLM\ncapabilities, while successfully unlearning the specified information.",
        "chunk-id": 1,
        "chunk": "Instruction-following large language models (LLMs), such as ChatGPT, have\nbecome increasingly popular with the general audience, many of whom are\nincorporating them into their daily routines. However, these LLMs inadvertently\ndisclose personal or copyrighted information, which calls for a machine\nunlearning method to remove selective knowledge. Previous attempts sought to",
        "authors": [
            "Minseok Choi",
            "Daniel Rim",
            "Dohyun Lee",
            "Jaegul Choo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T06:54:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12329v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12329v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000072,
        "doi": null,
        "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
        "abstract": "Instruction-following large language models (LLMs), such as ChatGPT, have\nbecome increasingly popular with the general audience, many of whom are\nincorporating them into their daily routines. However, these LLMs inadvertently\ndisclose personal or copyrighted information, which calls for a machine\nunlearning method to remove selective knowledge. Previous attempts sought to\nforget the link between the target information and its associated entities, but\nit rather led to generating undesirable responses about the target,\ncompromising the end-user experience. In this work, we propose SNAP, an\ninnovative framework designed to selectively unlearn information by 1) training\nan LLM with negative instructions to generate obliterated responses, 2)\naugmenting hard positives to retain the original LLM performance, and 3)\napplying the novel Wasserstein regularization to ensure adequate deviation from\nthe initial weights of the LLM. We evaluate our framework on various NLP\nbenchmarks and demonstrate that our approach retains the original LLM\ncapabilities, while successfully unlearning the specified information.",
        "chunk-id": 2,
        "chunk": "forget the link between the target information and its associated entities, but\nit rather led to generating undesirable responses about the target,\ncompromising the end-user experience. In this work, we propose SNAP, an\ninnovative framework designed to selectively unlearn information by 1) training\nan LLM with negative instructions to generate obliterated responses, 2)",
        "authors": [
            "Minseok Choi",
            "Daniel Rim",
            "Dohyun Lee",
            "Jaegul Choo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T06:54:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12329v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12329v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000072,
        "doi": null,
        "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
        "abstract": "Instruction-following large language models (LLMs), such as ChatGPT, have\nbecome increasingly popular with the general audience, many of whom are\nincorporating them into their daily routines. However, these LLMs inadvertently\ndisclose personal or copyrighted information, which calls for a machine\nunlearning method to remove selective knowledge. Previous attempts sought to\nforget the link between the target information and its associated entities, but\nit rather led to generating undesirable responses about the target,\ncompromising the end-user experience. In this work, we propose SNAP, an\ninnovative framework designed to selectively unlearn information by 1) training\nan LLM with negative instructions to generate obliterated responses, 2)\naugmenting hard positives to retain the original LLM performance, and 3)\napplying the novel Wasserstein regularization to ensure adequate deviation from\nthe initial weights of the LLM. We evaluate our framework on various NLP\nbenchmarks and demonstrate that our approach retains the original LLM\ncapabilities, while successfully unlearning the specified information.",
        "chunk-id": 3,
        "chunk": "augmenting hard positives to retain the original LLM performance, and 3)\napplying the novel Wasserstein regularization to ensure adequate deviation from\nthe initial weights of the LLM. We evaluate our framework on various NLP\nbenchmarks and demonstrate that our approach retains the original LLM\ncapabilities, while successfully unlearning the specified information.",
        "authors": [
            "Minseok Choi",
            "Daniel Rim",
            "Dohyun Lee",
            "Jaegul Choo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T06:54:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12329v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12329v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000073,
        "doi": null,
        "title": "Language and Multimodal Models in Sports: A Survey of Datasets and Applications",
        "abstract": "Recent integration of Natural Language Processing (NLP) and multimodal models\nhas advanced the field of sports analytics. This survey presents a\ncomprehensive review of the datasets and applications driving these innovations\npost-2020. We overviewed and categorized datasets into three primary types:\nlanguage-based, multimodal, and convertible datasets. Language-based and\nmultimodal datasets are for tasks involving text or multimodality (e.g., text,\nvideo, audio), respectively. Convertible datasets, initially single-modal\n(video), can be enriched with additional annotations, such as explanations of\nactions and video descriptions, to become multimodal, offering future potential\nfor richer and more diverse applications. Our study highlights the\ncontributions of these datasets to various applications, from improving fan\nexperiences to supporting tactical analysis and medical diagnostics. We also\ndiscuss the challenges and future directions in dataset development,\nemphasizing the need for diverse, high-quality data to support real-time\nprocessing and personalized user experiences. This survey provides a\nfoundational resource for researchers and practitioners aiming to leverage NLP\nand multimodal models in sports, offering insights into current trends and\nfuture opportunities in the field.",
        "chunk-id": 1,
        "chunk": "Recent integration of Natural Language Processing (NLP) and multimodal models\nhas advanced the field of sports analytics. This survey presents a\ncomprehensive review of the datasets and applications driving these innovations\npost-2020. We overviewed and categorized datasets into three primary types:\nlanguage-based, multimodal, and convertible datasets. Language-based and",
        "authors": [
            "Haotian Xia",
            "Zhengbang Yang",
            "Yun Zhao",
            "Yuqing Wang",
            "Jingxi Li",
            "Rhys Tracy",
            "Zhuangdi Zhu",
            "Yuan-fang Wang",
            "Hanjie Chen",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12252v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12252v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000073,
        "doi": null,
        "title": "Language and Multimodal Models in Sports: A Survey of Datasets and Applications",
        "abstract": "Recent integration of Natural Language Processing (NLP) and multimodal models\nhas advanced the field of sports analytics. This survey presents a\ncomprehensive review of the datasets and applications driving these innovations\npost-2020. We overviewed and categorized datasets into three primary types:\nlanguage-based, multimodal, and convertible datasets. Language-based and\nmultimodal datasets are for tasks involving text or multimodality (e.g., text,\nvideo, audio), respectively. Convertible datasets, initially single-modal\n(video), can be enriched with additional annotations, such as explanations of\nactions and video descriptions, to become multimodal, offering future potential\nfor richer and more diverse applications. Our study highlights the\ncontributions of these datasets to various applications, from improving fan\nexperiences to supporting tactical analysis and medical diagnostics. We also\ndiscuss the challenges and future directions in dataset development,\nemphasizing the need for diverse, high-quality data to support real-time\nprocessing and personalized user experiences. This survey provides a\nfoundational resource for researchers and practitioners aiming to leverage NLP\nand multimodal models in sports, offering insights into current trends and\nfuture opportunities in the field.",
        "chunk-id": 2,
        "chunk": "multimodal datasets are for tasks involving text or multimodality (e.g., text,\nvideo, audio), respectively. Convertible datasets, initially single-modal\n(video), can be enriched with additional annotations, such as explanations of\nactions and video descriptions, to become multimodal, offering future potential\nfor richer and more diverse applications. Our study highlights the",
        "authors": [
            "Haotian Xia",
            "Zhengbang Yang",
            "Yun Zhao",
            "Yuqing Wang",
            "Jingxi Li",
            "Rhys Tracy",
            "Zhuangdi Zhu",
            "Yuan-fang Wang",
            "Hanjie Chen",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12252v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12252v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000073,
        "doi": null,
        "title": "Language and Multimodal Models in Sports: A Survey of Datasets and Applications",
        "abstract": "Recent integration of Natural Language Processing (NLP) and multimodal models\nhas advanced the field of sports analytics. This survey presents a\ncomprehensive review of the datasets and applications driving these innovations\npost-2020. We overviewed and categorized datasets into three primary types:\nlanguage-based, multimodal, and convertible datasets. Language-based and\nmultimodal datasets are for tasks involving text or multimodality (e.g., text,\nvideo, audio), respectively. Convertible datasets, initially single-modal\n(video), can be enriched with additional annotations, such as explanations of\nactions and video descriptions, to become multimodal, offering future potential\nfor richer and more diverse applications. Our study highlights the\ncontributions of these datasets to various applications, from improving fan\nexperiences to supporting tactical analysis and medical diagnostics. We also\ndiscuss the challenges and future directions in dataset development,\nemphasizing the need for diverse, high-quality data to support real-time\nprocessing and personalized user experiences. This survey provides a\nfoundational resource for researchers and practitioners aiming to leverage NLP\nand multimodal models in sports, offering insights into current trends and\nfuture opportunities in the field.",
        "chunk-id": 3,
        "chunk": "contributions of these datasets to various applications, from improving fan\nexperiences to supporting tactical analysis and medical diagnostics. We also\ndiscuss the challenges and future directions in dataset development,\nemphasizing the need for diverse, high-quality data to support real-time\nprocessing and personalized user experiences. This survey provides a",
        "authors": [
            "Haotian Xia",
            "Zhengbang Yang",
            "Yun Zhao",
            "Yuqing Wang",
            "Jingxi Li",
            "Rhys Tracy",
            "Zhuangdi Zhu",
            "Yuan-fang Wang",
            "Hanjie Chen",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12252v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12252v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000073,
        "doi": null,
        "title": "Language and Multimodal Models in Sports: A Survey of Datasets and Applications",
        "abstract": "Recent integration of Natural Language Processing (NLP) and multimodal models\nhas advanced the field of sports analytics. This survey presents a\ncomprehensive review of the datasets and applications driving these innovations\npost-2020. We overviewed and categorized datasets into three primary types:\nlanguage-based, multimodal, and convertible datasets. Language-based and\nmultimodal datasets are for tasks involving text or multimodality (e.g., text,\nvideo, audio), respectively. Convertible datasets, initially single-modal\n(video), can be enriched with additional annotations, such as explanations of\nactions and video descriptions, to become multimodal, offering future potential\nfor richer and more diverse applications. Our study highlights the\ncontributions of these datasets to various applications, from improving fan\nexperiences to supporting tactical analysis and medical diagnostics. We also\ndiscuss the challenges and future directions in dataset development,\nemphasizing the need for diverse, high-quality data to support real-time\nprocessing and personalized user experiences. This survey provides a\nfoundational resource for researchers and practitioners aiming to leverage NLP\nand multimodal models in sports, offering insights into current trends and\nfuture opportunities in the field.",
        "chunk-id": 4,
        "chunk": "foundational resource for researchers and practitioners aiming to leverage NLP\nand multimodal models in sports, offering insights into current trends and\nfuture opportunities in the field.",
        "authors": [
            "Haotian Xia",
            "Zhengbang Yang",
            "Yun Zhao",
            "Yuqing Wang",
            "Jingxi Li",
            "Rhys Tracy",
            "Zhuangdi Zhu",
            "Yuan-fang Wang",
            "Hanjie Chen",
            "Weining Shen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:59:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12252v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12252v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000074,
        "doi": null,
        "title": "MCSD: An Efficient Language Model with Diverse Fusion",
        "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
        "chunk-id": 1,
        "chunk": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through",
        "authors": [
            "Hua Yang",
            "Duohai Li",
            "Shiman Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:08:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12230v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000074,
        "doi": null,
        "title": "MCSD: An Efficient Language Model with Diverse Fusion",
        "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
        "chunk-id": 2,
        "chunk": "the multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.",
        "authors": [
            "Hua Yang",
            "Duohai Li",
            "Shiman Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:08:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12230v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000074,
        "doi": null,
        "title": "MCSD: An Efficient Language Model with Diverse Fusion",
        "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
        "chunk-id": 3,
        "chunk": "For inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark",
        "authors": [
            "Hua Yang",
            "Duohai Li",
            "Shiman Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:08:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12230v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000074,
        "doi": null,
        "title": "MCSD: An Efficient Language Model with Diverse Fusion",
        "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
        "chunk-id": 4,
        "chunk": "tests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
        "authors": [
            "Hua Yang",
            "Duohai Li",
            "Shiman Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-18T03:08:01+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12230v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12230v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000075,
        "doi": null,
        "title": "AI \"News\" Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian",
        "abstract": "Large Language Models (LLMs) are increasingly used as \"content farm\" models\n(CFMs), to generate synthetic text that could pass for real news articles. This\nis already happening even for languages that do not have high-quality\nmonolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on\nEnglish, on as little as 40K Italian news articles, is sufficient for producing\nnews-like texts that native speakers of Italian struggle to identify as\nsynthetic.\n  We investigate three LLMs and three methods of detecting synthetic texts\n(log-likelihood, DetectGPT, and supervised classification), finding that they\nall perform better than human raters, but they are all impractical in the real\nworld (requiring either access to token likelihood information or a large\ndataset of CFM texts). We also explore the possibility of creating a proxy CFM:\nan LLM fine-tuned on a similar dataset to one used by the real \"content farm\".\nWe find that even a small amount of fine-tuning data suffices for creating a\nsuccessful detector, but we need to know which base LLM is used, which is a\nmajor challenge.\n  Our results suggest that there are currently no practical methods for\ndetecting synthetic news-like texts 'in the wild', while generating them is too\neasy. We highlight the urgency of more NLP research on this problem.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) are increasingly used as \"content farm\" models\n(CFMs), to generate synthetic text that could pass for real news articles. This\nis already happening even for languages that do not have high-quality\nmonolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on\nEnglish, on as little as 40K Italian news articles, is sufficient for producing",
        "authors": [
            "Giovanni Puccetti",
            "Anna Rogers",
            "Chiara Alzetta",
            "Felice Dell'Orletta",
            "Andrea Esuli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T22:19:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12128v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12128v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000075,
        "doi": null,
        "title": "AI \"News\" Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian",
        "abstract": "Large Language Models (LLMs) are increasingly used as \"content farm\" models\n(CFMs), to generate synthetic text that could pass for real news articles. This\nis already happening even for languages that do not have high-quality\nmonolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on\nEnglish, on as little as 40K Italian news articles, is sufficient for producing\nnews-like texts that native speakers of Italian struggle to identify as\nsynthetic.\n  We investigate three LLMs and three methods of detecting synthetic texts\n(log-likelihood, DetectGPT, and supervised classification), finding that they\nall perform better than human raters, but they are all impractical in the real\nworld (requiring either access to token likelihood information or a large\ndataset of CFM texts). We also explore the possibility of creating a proxy CFM:\nan LLM fine-tuned on a similar dataset to one used by the real \"content farm\".\nWe find that even a small amount of fine-tuning data suffices for creating a\nsuccessful detector, but we need to know which base LLM is used, which is a\nmajor challenge.\n  Our results suggest that there are currently no practical methods for\ndetecting synthetic news-like texts 'in the wild', while generating them is too\neasy. We highlight the urgency of more NLP research on this problem.",
        "chunk-id": 2,
        "chunk": "news-like texts that native speakers of Italian struggle to identify as\nsynthetic.\n  We investigate three LLMs and three methods of detecting synthetic texts\n(log-likelihood, DetectGPT, and supervised classification), finding that they\nall perform better than human raters, but they are all impractical in the real",
        "authors": [
            "Giovanni Puccetti",
            "Anna Rogers",
            "Chiara Alzetta",
            "Felice Dell'Orletta",
            "Andrea Esuli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T22:19:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12128v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12128v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000075,
        "doi": null,
        "title": "AI \"News\" Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian",
        "abstract": "Large Language Models (LLMs) are increasingly used as \"content farm\" models\n(CFMs), to generate synthetic text that could pass for real news articles. This\nis already happening even for languages that do not have high-quality\nmonolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on\nEnglish, on as little as 40K Italian news articles, is sufficient for producing\nnews-like texts that native speakers of Italian struggle to identify as\nsynthetic.\n  We investigate three LLMs and three methods of detecting synthetic texts\n(log-likelihood, DetectGPT, and supervised classification), finding that they\nall perform better than human raters, but they are all impractical in the real\nworld (requiring either access to token likelihood information or a large\ndataset of CFM texts). We also explore the possibility of creating a proxy CFM:\nan LLM fine-tuned on a similar dataset to one used by the real \"content farm\".\nWe find that even a small amount of fine-tuning data suffices for creating a\nsuccessful detector, but we need to know which base LLM is used, which is a\nmajor challenge.\n  Our results suggest that there are currently no practical methods for\ndetecting synthetic news-like texts 'in the wild', while generating them is too\neasy. We highlight the urgency of more NLP research on this problem.",
        "chunk-id": 3,
        "chunk": "world (requiring either access to token likelihood information or a large\ndataset of CFM texts). We also explore the possibility of creating a proxy CFM:\nan LLM fine-tuned on a similar dataset to one used by the real \"content farm\".\nWe find that even a small amount of fine-tuning data suffices for creating a",
        "authors": [
            "Giovanni Puccetti",
            "Anna Rogers",
            "Chiara Alzetta",
            "Felice Dell'Orletta",
            "Andrea Esuli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T22:19:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12128v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12128v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000075,
        "doi": null,
        "title": "AI \"News\" Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian",
        "abstract": "Large Language Models (LLMs) are increasingly used as \"content farm\" models\n(CFMs), to generate synthetic text that could pass for real news articles. This\nis already happening even for languages that do not have high-quality\nmonolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on\nEnglish, on as little as 40K Italian news articles, is sufficient for producing\nnews-like texts that native speakers of Italian struggle to identify as\nsynthetic.\n  We investigate three LLMs and three methods of detecting synthetic texts\n(log-likelihood, DetectGPT, and supervised classification), finding that they\nall perform better than human raters, but they are all impractical in the real\nworld (requiring either access to token likelihood information or a large\ndataset of CFM texts). We also explore the possibility of creating a proxy CFM:\nan LLM fine-tuned on a similar dataset to one used by the real \"content farm\".\nWe find that even a small amount of fine-tuning data suffices for creating a\nsuccessful detector, but we need to know which base LLM is used, which is a\nmajor challenge.\n  Our results suggest that there are currently no practical methods for\ndetecting synthetic news-like texts 'in the wild', while generating them is too\neasy. We highlight the urgency of more NLP research on this problem.",
        "chunk-id": 4,
        "chunk": "successful detector, but we need to know which base LLM is used, which is a\nmajor challenge.\n  Our results suggest that there are currently no practical methods for\ndetecting synthetic news-like texts 'in the wild', while generating them is too\neasy. We highlight the urgency of more NLP research on this problem.",
        "authors": [
            "Giovanni Puccetti",
            "Anna Rogers",
            "Chiara Alzetta",
            "Felice Dell'Orletta",
            "Andrea Esuli"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T22:19:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12128v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12128v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000076,
        "doi": null,
        "title": "Can LLMs Learn Macroeconomic Narratives from Social Media?",
        "abstract": "This study empirically tests the $\\textit{Narrative Economics}$ hypothesis,\nwhich posits that narratives (ideas that are spread virally and affect public\nbeliefs) can influence economic fluctuations. We introduce two curated datasets\ncontaining posts from X (formerly Twitter) which capture economy-related\nnarratives (Data will be shared upon paper acceptance). Employing Natural\nLanguage Processing (NLP) methods, we extract and summarize narratives from the\ntweets. We test their predictive power for $\\textit{macroeconomic}$ forecasting\nby incorporating the tweets' or the extracted narratives' representations in\ndownstream financial prediction tasks. Our work highlights the challenges in\nimproving macroeconomic models with narrative data, paving the way for the\nresearch community to realistically address this important challenge. From a\nscientific perspective, our investigation offers valuable insights and NLP\ntools for narrative extraction and summarization using Large Language Models\n(LLMs), contributing to future research on the role of narratives in economics.",
        "chunk-id": 1,
        "chunk": "This study empirically tests the $\\textit{Narrative Economics}$ hypothesis,\nwhich posits that narratives (ideas that are spread virally and affect public\nbeliefs) can influence economic fluctuations. We introduce two curated datasets\ncontaining posts from X (formerly Twitter) which capture economy-related\nnarratives (Data will be shared upon paper acceptance). Employing Natural",
        "authors": [
            "Almog Gueta",
            "Amir Feder",
            "Zorik Gekhman",
            "Ariel Goldstein",
            "Roi Reichart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T21:37:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12109v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12109v1",
        "categories": [
            "Computation and Language",
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 20000076,
        "doi": null,
        "title": "Can LLMs Learn Macroeconomic Narratives from Social Media?",
        "abstract": "This study empirically tests the $\\textit{Narrative Economics}$ hypothesis,\nwhich posits that narratives (ideas that are spread virally and affect public\nbeliefs) can influence economic fluctuations. We introduce two curated datasets\ncontaining posts from X (formerly Twitter) which capture economy-related\nnarratives (Data will be shared upon paper acceptance). Employing Natural\nLanguage Processing (NLP) methods, we extract and summarize narratives from the\ntweets. We test their predictive power for $\\textit{macroeconomic}$ forecasting\nby incorporating the tweets' or the extracted narratives' representations in\ndownstream financial prediction tasks. Our work highlights the challenges in\nimproving macroeconomic models with narrative data, paving the way for the\nresearch community to realistically address this important challenge. From a\nscientific perspective, our investigation offers valuable insights and NLP\ntools for narrative extraction and summarization using Large Language Models\n(LLMs), contributing to future research on the role of narratives in economics.",
        "chunk-id": 2,
        "chunk": "Language Processing (NLP) methods, we extract and summarize narratives from the\ntweets. We test their predictive power for $\\textit{macroeconomic}$ forecasting\nby incorporating the tweets' or the extracted narratives' representations in\ndownstream financial prediction tasks. Our work highlights the challenges in",
        "authors": [
            "Almog Gueta",
            "Amir Feder",
            "Zorik Gekhman",
            "Ariel Goldstein",
            "Roi Reichart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T21:37:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12109v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12109v1",
        "categories": [
            "Computation and Language",
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 20000076,
        "doi": null,
        "title": "Can LLMs Learn Macroeconomic Narratives from Social Media?",
        "abstract": "This study empirically tests the $\\textit{Narrative Economics}$ hypothesis,\nwhich posits that narratives (ideas that are spread virally and affect public\nbeliefs) can influence economic fluctuations. We introduce two curated datasets\ncontaining posts from X (formerly Twitter) which capture economy-related\nnarratives (Data will be shared upon paper acceptance). Employing Natural\nLanguage Processing (NLP) methods, we extract and summarize narratives from the\ntweets. We test their predictive power for $\\textit{macroeconomic}$ forecasting\nby incorporating the tweets' or the extracted narratives' representations in\ndownstream financial prediction tasks. Our work highlights the challenges in\nimproving macroeconomic models with narrative data, paving the way for the\nresearch community to realistically address this important challenge. From a\nscientific perspective, our investigation offers valuable insights and NLP\ntools for narrative extraction and summarization using Large Language Models\n(LLMs), contributing to future research on the role of narratives in economics.",
        "chunk-id": 3,
        "chunk": "improving macroeconomic models with narrative data, paving the way for the\nresearch community to realistically address this important challenge. From a\nscientific perspective, our investigation offers valuable insights and NLP\ntools for narrative extraction and summarization using Large Language Models\n(LLMs), contributing to future research on the role of narratives in economics.",
        "authors": [
            "Almog Gueta",
            "Amir Feder",
            "Zorik Gekhman",
            "Ariel Goldstein",
            "Roi Reichart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T21:37:09+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12109v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12109v1",
        "categories": [
            "Computation and Language",
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 20000077,
        "doi": null,
        "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
        "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
        "chunk-id": 1,
        "chunk": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators",
        "authors": [
            "Nikhil Khandekar",
            "Qiao Jin",
            "Guangzhi Xiong",
            "Soren Dunn",
            "Serina S Applebaum",
            "Zain Anwar",
            "Maame Sarfo-Gyamfi",
            "Conrad W Safranek",
            "Abid A Anwar",
            "Andrew Zhang",
            "Aidan Gilson",
            "Maxwell B Singer",
            "Amisha Dave",
            "Andrew Taylor",
            "Aidong Zhang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T19:07:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12036v3",
        "arxiv_link": "http://arxiv.org/abs/2406.12036v3",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000077,
        "doi": null,
        "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
        "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
        "chunk-id": 2,
        "chunk": "that follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each",
        "authors": [
            "Nikhil Khandekar",
            "Qiao Jin",
            "Guangzhi Xiong",
            "Soren Dunn",
            "Serina S Applebaum",
            "Zain Anwar",
            "Maame Sarfo-Gyamfi",
            "Conrad W Safranek",
            "Abid A Anwar",
            "Andrew Zhang",
            "Aidan Gilson",
            "Maxwell B Singer",
            "Amisha Dave",
            "Andrew Taylor",
            "Aidong Zhang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T19:07:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12036v3",
        "arxiv_link": "http://arxiv.org/abs/2406.12036v3",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000077,
        "doi": null,
        "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
        "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
        "chunk-id": 3,
        "chunk": "instance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for",
        "authors": [
            "Nikhil Khandekar",
            "Qiao Jin",
            "Guangzhi Xiong",
            "Soren Dunn",
            "Serina S Applebaum",
            "Zain Anwar",
            "Maame Sarfo-Gyamfi",
            "Conrad W Safranek",
            "Abid A Anwar",
            "Andrew Zhang",
            "Aidan Gilson",
            "Maxwell B Singer",
            "Amisha Dave",
            "Andrew Taylor",
            "Aidong Zhang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T19:07:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12036v3",
        "arxiv_link": "http://arxiv.org/abs/2406.12036v3",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000077,
        "doi": null,
        "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
        "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
        "chunk-id": 4,
        "chunk": "clinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,",
        "authors": [
            "Nikhil Khandekar",
            "Qiao Jin",
            "Guangzhi Xiong",
            "Soren Dunn",
            "Serina S Applebaum",
            "Zain Anwar",
            "Maame Sarfo-Gyamfi",
            "Conrad W Safranek",
            "Abid A Anwar",
            "Andrew Zhang",
            "Aidan Gilson",
            "Maxwell B Singer",
            "Amisha Dave",
            "Andrew Taylor",
            "Aidong Zhang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T19:07:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12036v3",
        "arxiv_link": "http://arxiv.org/abs/2406.12036v3",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000077,
        "doi": null,
        "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
        "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
        "chunk-id": 5,
        "chunk": "encouraging future improvements of LLMs for various clinical calculation tasks.",
        "authors": [
            "Nikhil Khandekar",
            "Qiao Jin",
            "Guangzhi Xiong",
            "Soren Dunn",
            "Serina S Applebaum",
            "Zain Anwar",
            "Maame Sarfo-Gyamfi",
            "Conrad W Safranek",
            "Abid A Anwar",
            "Andrew Zhang",
            "Aidan Gilson",
            "Maxwell B Singer",
            "Amisha Dave",
            "Andrew Taylor",
            "Aidong Zhang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T19:07:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12036v3",
        "arxiv_link": "http://arxiv.org/abs/2406.12036v3",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000078,
        "doi": null,
        "title": "FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure",
        "abstract": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an\nonline question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)\ntechniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their\nfine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information\ndisclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "chunk-id": 1,
        "chunk": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an",
        "authors": [
            "Ziyue Xu",
            "Peilin Zhou",
            "Xinyu Shi",
            "Jiageng Wu",
            "Yikang Jiang",
            "Bin Ke",
            "Jie Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T18:25:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12009v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12009v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000078,
        "doi": null,
        "title": "FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure",
        "abstract": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an\nonline question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)\ntechniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their\nfine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information\ndisclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "chunk-id": 2,
        "chunk": "online question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)",
        "authors": [
            "Ziyue Xu",
            "Peilin Zhou",
            "Xinyu Shi",
            "Jiageng Wu",
            "Yikang Jiang",
            "Bin Ke",
            "Jie Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T18:25:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12009v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12009v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000078,
        "doi": null,
        "title": "FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure",
        "abstract": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an\nonline question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)\ntechniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their\nfine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information\ndisclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "chunk-id": 3,
        "chunk": "techniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their",
        "authors": [
            "Ziyue Xu",
            "Peilin Zhou",
            "Xinyu Shi",
            "Jiageng Wu",
            "Yikang Jiang",
            "Bin Ke",
            "Jie Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T18:25:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12009v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12009v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000078,
        "doi": null,
        "title": "FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure",
        "abstract": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an\nonline question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)\ntechniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their\nfine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information\ndisclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "chunk-id": 4,
        "chunk": "fine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information",
        "authors": [
            "Ziyue Xu",
            "Peilin Zhou",
            "Xinyu Shi",
            "Jiageng Wu",
            "Yikang Jiang",
            "Bin Ke",
            "Jie Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T18:25:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12009v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12009v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000078,
        "doi": null,
        "title": "FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure",
        "abstract": "Accurate and transparent financial information disclosure is crucial in the\nfields of accounting and finance, ensuring market efficiency and investor\nconfidence. Among many information disclosure platforms, the Chinese stock\nexchanges' investor interactive platform provides a novel and interactive way\nfor listed firms to disclose information of interest to investors through an\nonline question-and-answer (Q&A) format. However, it is common for listed firms\nto respond to questions with limited or no substantive information, and\nautomatically evaluating the quality of financial information disclosure on\nlarge amounts of Q&A pairs is challenging. This paper builds a benchmark\nFinTruthQA, that can evaluate advanced natural language processing (NLP)\ntechniques for the automatic quality assessment of information disclosure in\nfinancial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries\nand each Q&A was manually annotated based on four conceptual dimensions of\naccounting. We benchmarked various NLP techniques on FinTruthQA, including\nstatistical machine learning models, pre-trained language model and their\nfine-tuned versions, as well as the large language model GPT-4. Experiments\nshowed that existing NLP models have strong predictive ability for real\nquestion identification and question relevance tasks, but are suboptimal for\nanswer relevance and answer readability tasks. By establishing this benchmark,\nwe provide a robust foundation for the automatic evaluation of information\ndisclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "chunk-id": 5,
        "chunk": "disclosure, significantly enhancing the transparency and quality of financial\nreporting. FinTruthQA can be used by auditors, regulators, and financial\nanalysts for real-time monitoring and data-driven decision-making, as well as\nby researchers for advanced studies in accounting and finance, ultimately\nfostering greater trust and efficiency in the financial markets.",
        "authors": [
            "Ziyue Xu",
            "Peilin Zhou",
            "Xinyu Shi",
            "Jiageng Wu",
            "Yikang Jiang",
            "Bin Ke",
            "Jie Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T18:25:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.12009v1",
        "arxiv_link": "http://arxiv.org/abs/2406.12009v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000079,
        "doi": null,
        "title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs",
        "abstract": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make\nthis tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation\nfunction for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel optimizer that outperforms\nbaselines on five of six diverse LM programs using a best-in-class open-source\nmodel (Llama-3-8B), by as high as 12.9% accuracy. We will release our new\noptimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy",
        "chunk-id": 1,
        "chunk": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make",
        "authors": [
            "Krista Opsahl-Ong",
            "Michael J Ryan",
            "Josh Purtell",
            "David Broman",
            "Christopher Potts",
            "Matei Zaharia",
            "Omar Khattab"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T16:12:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11695v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000079,
        "doi": null,
        "title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs",
        "abstract": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make\nthis tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation\nfunction for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel optimizer that outperforms\nbaselines on five of six diverse LM programs using a best-in-class open-source\nmodel (Llama-3-8B), by as high as 12.9% accuracy. We will release our new\noptimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy",
        "chunk-id": 2,
        "chunk": "this tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation",
        "authors": [
            "Krista Opsahl-Ong",
            "Michael J Ryan",
            "Josh Purtell",
            "David Broman",
            "Christopher Potts",
            "Matei Zaharia",
            "Omar Khattab"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T16:12:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11695v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000079,
        "doi": null,
        "title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs",
        "abstract": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make\nthis tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation\nfunction for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel optimizer that outperforms\nbaselines on five of six diverse LM programs using a best-in-class open-source\nmodel (Llama-3-8B), by as high as 12.9% accuracy. We will release our new\noptimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy",
        "chunk-id": 3,
        "chunk": "function for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel optimizer that outperforms\nbaselines on five of six diverse LM programs using a best-in-class open-source\nmodel (Llama-3-8B), by as high as 12.9% accuracy. We will release our new",
        "authors": [
            "Krista Opsahl-Ong",
            "Michael J Ryan",
            "Josh Purtell",
            "David Broman",
            "Christopher Potts",
            "Matei Zaharia",
            "Omar Khattab"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T16:12:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11695v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000079,
        "doi": null,
        "title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs",
        "abstract": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make\nthis tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation\nfunction for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel optimizer that outperforms\nbaselines on five of six diverse LM programs using a best-in-class open-source\nmodel (Llama-3-8B), by as high as 12.9% accuracy. We will release our new\noptimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy",
        "chunk-id": 4,
        "chunk": "optimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy",
        "authors": [
            "Krista Opsahl-Ong",
            "Michael J Ryan",
            "Josh Purtell",
            "David Broman",
            "Christopher Potts",
            "Matei Zaharia",
            "Omar Khattab"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T16:12:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11695v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11695v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 20000080,
        "doi": "10.1145/3637528.3671564",
        "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models",
        "abstract": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
        "chunk-id": 1,
        "chunk": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain",
        "authors": [
            "Shangqing Tu",
            "Yuanchun Wang",
            "Jifan Yu",
            "Yuyang Xie",
            "Yaran Shi",
            "Xiaozhi Wang",
            "Jing Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11681v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11681v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000080,
        "doi": "10.1145/3637528.3671564",
        "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models",
        "abstract": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
        "chunk-id": 2,
        "chunk": "knowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be",
        "authors": [
            "Shangqing Tu",
            "Yuanchun Wang",
            "Jifan Yu",
            "Yuyang Xie",
            "Yaran Shi",
            "Xiaozhi Wang",
            "Jing Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11681v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11681v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000080,
        "doi": "10.1145/3637528.3671564",
        "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models",
        "abstract": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
        "chunk-id": 3,
        "chunk": "user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain",
        "authors": [
            "Shangqing Tu",
            "Yuanchun Wang",
            "Jifan Yu",
            "Yuyang Xie",
            "Yaran Shi",
            "Xiaozhi Wang",
            "Jing Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11681v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11681v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000080,
        "doi": "10.1145/3637528.3671564",
        "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models",
        "abstract": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
        "chunk-id": 4,
        "chunk": "requirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
        "authors": [
            "Shangqing Tu",
            "Yuanchun Wang",
            "Jifan Yu",
            "Yuyang Xie",
            "Yaran Shi",
            "Xiaozhi Wang",
            "Jing Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:59:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11681v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11681v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000081,
        "doi": null,
        "title": "Building Knowledge-Guided Lexica to Model Cultural Variation",
        "abstract": "Cultural variation exists between nations (e.g., the United States vs.\nChina), but also within regions (e.g., California vs. Texas, Los Angeles vs.\nSan Francisco). Measuring this regional cultural variation can illuminate how\nand why people think and behave differently. Historically, it has been\ndifficult to computationally model cultural variation due to a lack of training\ndata and scalability constraints. In this work, we introduce a new research\nproblem for the NLP community: How do we measure variation in cultural\nconstructs across regions using language? We then provide a scalable solution:\nbuilding knowledge-guided lexica to model cultural variation, encouraging\nfuture work at the intersection of NLP and cultural understanding. We also\nhighlight modern LLMs' failure to measure cultural variation or generate\nculturally varied language.",
        "chunk-id": 1,
        "chunk": "Cultural variation exists between nations (e.g., the United States vs.\nChina), but also within regions (e.g., California vs. Texas, Los Angeles vs.\nSan Francisco). Measuring this regional cultural variation can illuminate how\nand why people think and behave differently. Historically, it has been\ndifficult to computationally model cultural variation due to a lack of training",
        "authors": [
            "Shreya Havaldar",
            "Salvatore Giorgi",
            "Sunny Rai",
            "Thomas Talhelm",
            "Sharath Chandra Guntuku",
            "Lyle Ungar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:05:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11622v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11622v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000081,
        "doi": null,
        "title": "Building Knowledge-Guided Lexica to Model Cultural Variation",
        "abstract": "Cultural variation exists between nations (e.g., the United States vs.\nChina), but also within regions (e.g., California vs. Texas, Los Angeles vs.\nSan Francisco). Measuring this regional cultural variation can illuminate how\nand why people think and behave differently. Historically, it has been\ndifficult to computationally model cultural variation due to a lack of training\ndata and scalability constraints. In this work, we introduce a new research\nproblem for the NLP community: How do we measure variation in cultural\nconstructs across regions using language? We then provide a scalable solution:\nbuilding knowledge-guided lexica to model cultural variation, encouraging\nfuture work at the intersection of NLP and cultural understanding. We also\nhighlight modern LLMs' failure to measure cultural variation or generate\nculturally varied language.",
        "chunk-id": 2,
        "chunk": "data and scalability constraints. In this work, we introduce a new research\nproblem for the NLP community: How do we measure variation in cultural\nconstructs across regions using language? We then provide a scalable solution:\nbuilding knowledge-guided lexica to model cultural variation, encouraging\nfuture work at the intersection of NLP and cultural understanding. We also",
        "authors": [
            "Shreya Havaldar",
            "Salvatore Giorgi",
            "Sunny Rai",
            "Thomas Talhelm",
            "Sharath Chandra Guntuku",
            "Lyle Ungar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:05:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11622v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11622v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000081,
        "doi": null,
        "title": "Building Knowledge-Guided Lexica to Model Cultural Variation",
        "abstract": "Cultural variation exists between nations (e.g., the United States vs.\nChina), but also within regions (e.g., California vs. Texas, Los Angeles vs.\nSan Francisco). Measuring this regional cultural variation can illuminate how\nand why people think and behave differently. Historically, it has been\ndifficult to computationally model cultural variation due to a lack of training\ndata and scalability constraints. In this work, we introduce a new research\nproblem for the NLP community: How do we measure variation in cultural\nconstructs across regions using language? We then provide a scalable solution:\nbuilding knowledge-guided lexica to model cultural variation, encouraging\nfuture work at the intersection of NLP and cultural understanding. We also\nhighlight modern LLMs' failure to measure cultural variation or generate\nculturally varied language.",
        "chunk-id": 3,
        "chunk": "highlight modern LLMs' failure to measure cultural variation or generate\nculturally varied language.",
        "authors": [
            "Shreya Havaldar",
            "Salvatore Giorgi",
            "Sunny Rai",
            "Thomas Talhelm",
            "Sharath Chandra Guntuku",
            "Lyle Ungar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T15:05:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11622v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11622v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000082,
        "doi": null,
        "title": "Understanding \"Democratization\" in NLP and ML Research",
        "abstract": "Recent improvements in natural language processing (NLP) and machine learning\n(ML) and increased mainstream adoption have led to researchers frequently\ndiscussing the \"democratization\" of artificial intelligence. In this paper, we\nseek to clarify how democratization is understood in NLP and ML publications,\nthrough large-scale mixed-methods analyses of papers using the keyword\n\"democra*\" published in NLP and adjacent venues. We find that democratization\nis most frequently used to convey (ease of) access to or use of technologies,\nwithout meaningfully engaging with theories of democratization, while research\nusing other invocations of \"democra*\" tends to be grounded in theories of\ndeliberation and debate. Based on our findings, we call for researchers to\nenrich their use of the term democratization with appropriate theory, towards\ndemocratic technologies beyond superficial access.",
        "chunk-id": 1,
        "chunk": "Recent improvements in natural language processing (NLP) and machine learning\n(ML) and increased mainstream adoption have led to researchers frequently\ndiscussing the \"democratization\" of artificial intelligence. In this paper, we\nseek to clarify how democratization is understood in NLP and ML publications,\nthrough large-scale mixed-methods analyses of papers using the keyword",
        "authors": [
            "Arjun Subramonian",
            "Vagrant Gautam",
            "Dietrich Klakow",
            "Zeerak Talat"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:47:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11598v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11598v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000082,
        "doi": null,
        "title": "Understanding \"Democratization\" in NLP and ML Research",
        "abstract": "Recent improvements in natural language processing (NLP) and machine learning\n(ML) and increased mainstream adoption have led to researchers frequently\ndiscussing the \"democratization\" of artificial intelligence. In this paper, we\nseek to clarify how democratization is understood in NLP and ML publications,\nthrough large-scale mixed-methods analyses of papers using the keyword\n\"democra*\" published in NLP and adjacent venues. We find that democratization\nis most frequently used to convey (ease of) access to or use of technologies,\nwithout meaningfully engaging with theories of democratization, while research\nusing other invocations of \"democra*\" tends to be grounded in theories of\ndeliberation and debate. Based on our findings, we call for researchers to\nenrich their use of the term democratization with appropriate theory, towards\ndemocratic technologies beyond superficial access.",
        "chunk-id": 2,
        "chunk": "\"democra*\" published in NLP and adjacent venues. We find that democratization\nis most frequently used to convey (ease of) access to or use of technologies,\nwithout meaningfully engaging with theories of democratization, while research\nusing other invocations of \"democra*\" tends to be grounded in theories of\ndeliberation and debate. Based on our findings, we call for researchers to",
        "authors": [
            "Arjun Subramonian",
            "Vagrant Gautam",
            "Dietrich Klakow",
            "Zeerak Talat"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:47:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11598v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11598v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000082,
        "doi": null,
        "title": "Understanding \"Democratization\" in NLP and ML Research",
        "abstract": "Recent improvements in natural language processing (NLP) and machine learning\n(ML) and increased mainstream adoption have led to researchers frequently\ndiscussing the \"democratization\" of artificial intelligence. In this paper, we\nseek to clarify how democratization is understood in NLP and ML publications,\nthrough large-scale mixed-methods analyses of papers using the keyword\n\"democra*\" published in NLP and adjacent venues. We find that democratization\nis most frequently used to convey (ease of) access to or use of technologies,\nwithout meaningfully engaging with theories of democratization, while research\nusing other invocations of \"democra*\" tends to be grounded in theories of\ndeliberation and debate. Based on our findings, we call for researchers to\nenrich their use of the term democratization with appropriate theory, towards\ndemocratic technologies beyond superficial access.",
        "chunk-id": 3,
        "chunk": "enrich their use of the term democratization with appropriate theory, towards\ndemocratic technologies beyond superficial access.",
        "authors": [
            "Arjun Subramonian",
            "Vagrant Gautam",
            "Dietrich Klakow",
            "Zeerak Talat"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:47:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11598v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11598v1",
        "categories": [
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000083,
        "doi": null,
        "title": "Mathematical Entities: Corpora and Benchmarks",
        "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different\ncontexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim\nto test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition\nextraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical\nlanguage processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "chunk-id": 1,
        "chunk": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different",
        "authors": [
            "Jacob Collard",
            "Valeria de Paiva",
            "Eswaran Subrahmanian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:11:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11577v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11577v1",
        "categories": [
            "Computation and Language",
            "History and Overview"
        ]
    },
    {
        "id": 20000083,
        "doi": null,
        "title": "Mathematical Entities: Corpora and Benchmarks",
        "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different\ncontexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim\nto test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition\nextraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical\nlanguage processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "chunk-id": 2,
        "chunk": "contexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim",
        "authors": [
            "Jacob Collard",
            "Valeria de Paiva",
            "Eswaran Subrahmanian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:11:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11577v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11577v1",
        "categories": [
            "Computation and Language",
            "History and Overview"
        ]
    },
    {
        "id": 20000083,
        "doi": null,
        "title": "Mathematical Entities: Corpora and Benchmarks",
        "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different\ncontexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim\nto test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition\nextraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical\nlanguage processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "chunk-id": 3,
        "chunk": "to test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition",
        "authors": [
            "Jacob Collard",
            "Valeria de Paiva",
            "Eswaran Subrahmanian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:11:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11577v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11577v1",
        "categories": [
            "Computation and Language",
            "History and Overview"
        ]
    },
    {
        "id": 20000083,
        "doi": null,
        "title": "Mathematical Entities: Corpora and Benchmarks",
        "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different\ncontexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim\nto test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition\nextraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical\nlanguage processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "chunk-id": 4,
        "chunk": "extraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical",
        "authors": [
            "Jacob Collard",
            "Valeria de Paiva",
            "Eswaran Subrahmanian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:11:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11577v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11577v1",
        "categories": [
            "Computation and Language",
            "History and Overview"
        ]
    },
    {
        "id": 20000083,
        "doi": null,
        "title": "Mathematical Entities: Corpora and Benchmarks",
        "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges. Despite this, there has been relatively little research on natural\nlanguage processing for mathematical texts, and there are few mathematical\nlanguage resources aimed at NLP. In this paper, we aim to provide annotated\ncorpora that can be used to study the language of mathematics in different\ncontexts, ranging from fundamental concepts found in textbooks to advanced\nresearch mathematics. We preprocess the corpora with a neural parsing model and\nsome manual intervention to provide part-of-speech tags, lemmas, and dependency\ntrees. In total, we provide 182397 sentences across three corpora. We then aim\nto test and evaluate several noteworthy natural language processing models\nusing these corpora, to show how well they can adapt to the domain of\nmathematics and provide useful tools for exploring mathematical language. We\nevaluate several neural and symbolic models against benchmarks that we extract\nfrom the corpus metadata to show that terminology extraction and definition\nextraction do not easily generalize to mathematics, and that additional work is\nneeded to achieve good performance on these metrics. Finally, we provide a\nlearning assistant that grants access to the content of these corpora in a\ncontext-sensitive manner, utilizing text search and entity linking. Though our\ncorpora and benchmarks provide useful metrics for evaluating mathematical\nlanguage processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "chunk-id": 5,
        "chunk": "language processing, further work is necessary to adapt models to mathematics\nin order to provide more effective learning assistants and apply NLP methods to\ndifferent mathematical domains.",
        "authors": [
            "Jacob Collard",
            "Valeria de Paiva",
            "Eswaran Subrahmanian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T14:11:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11577v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11577v1",
        "categories": [
            "Computation and Language",
            "History and Overview"
        ]
    },
    {
        "id": 20000084,
        "doi": null,
        "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
        "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "chunk-id": 1,
        "chunk": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large",
        "authors": [
            "Rick Wilming",
            "Artur Dox",
            "Hjalmar Schulz",
            "Marta Oliveira",
            "Benedict Clark",
            "Stefan Haufe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T13:44:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11547v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11547v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000084,
        "doi": null,
        "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
        "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "chunk-id": 2,
        "chunk": "language models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female",
        "authors": [
            "Rick Wilming",
            "Artur Dox",
            "Hjalmar Schulz",
            "Marta Oliveira",
            "Benedict Clark",
            "Stefan Haufe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T13:44:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11547v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11547v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000084,
        "doi": null,
        "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
        "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "chunk-id": 3,
        "chunk": "forms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate",
        "authors": [
            "Rick Wilming",
            "Artur Dox",
            "Hjalmar Schulz",
            "Marta Oliveira",
            "Benedict Clark",
            "Stefan Haufe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T13:44:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11547v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11547v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000084,
        "doi": null,
        "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
        "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "chunk-id": 4,
        "chunk": "how pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds",
        "authors": [
            "Rick Wilming",
            "Artur Dox",
            "Hjalmar Schulz",
            "Marta Oliveira",
            "Benedict Clark",
            "Stefan Haufe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T13:44:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11547v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11547v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000084,
        "doi": null,
        "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
        "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "chunk-id": 5,
        "chunk": "for models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
        "authors": [
            "Rick Wilming",
            "Artur Dox",
            "Hjalmar Schulz",
            "Marta Oliveira",
            "Benedict Clark",
            "Stefan Haufe"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T13:44:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11547v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11547v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computers and Society"
        ]
    },
    {
        "id": 20000085,
        "doi": null,
        "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
        "abstract": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models\nwere proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD\ngenerally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly\nweaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
        "chunk-id": 1,
        "chunk": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models",
        "authors": [
            "Justin Deschenaux",
            "Caglar Gulcehre"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T12:38:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000085,
        "doi": null,
        "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
        "abstract": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models\nwere proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD\ngenerally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly\nweaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
        "chunk-id": 2,
        "chunk": "were proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD",
        "authors": [
            "Justin Deschenaux",
            "Caglar Gulcehre"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T12:38:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000085,
        "doi": null,
        "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
        "abstract": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models\nwere proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD\ngenerally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly\nweaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
        "chunk-id": 3,
        "chunk": "generally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly",
        "authors": [
            "Justin Deschenaux",
            "Caglar Gulcehre"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T12:38:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000085,
        "doi": null,
        "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
        "abstract": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models\nwere proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD\ngenerally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly\nweaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
        "chunk-id": 4,
        "chunk": "weaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
        "authors": [
            "Justin Deschenaux",
            "Caglar Gulcehre"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T12:38:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000086,
        "doi": null,
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "abstract": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously\nused to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring\nbias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant\nbiases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except\nfor Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "chunk-id": 1,
        "chunk": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously",
        "authors": [
            "Ze Wang",
            "Zekun Wu",
            "Xin Guan",
            "Michael Thaler",
            "Adriano Koshiyama",
            "Skylar Lu",
            "Sachin Beepath",
            "Ediz Ertekin Jr.",
            "Maria Perez-Ortiz"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T09:15:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15484v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15484v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000086,
        "doi": null,
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "abstract": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously\nused to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring\nbias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant\nbiases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except\nfor Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "chunk-id": 2,
        "chunk": "used to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring",
        "authors": [
            "Ze Wang",
            "Zekun Wu",
            "Xin Guan",
            "Michael Thaler",
            "Adriano Koshiyama",
            "Skylar Lu",
            "Sachin Beepath",
            "Ediz Ertekin Jr.",
            "Maria Perez-Ortiz"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T09:15:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15484v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15484v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000086,
        "doi": null,
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "abstract": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously\nused to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring\nbias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant\nbiases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except\nfor Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "chunk-id": 3,
        "chunk": "bias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant",
        "authors": [
            "Ze Wang",
            "Zekun Wu",
            "Xin Guan",
            "Michael Thaler",
            "Adriano Koshiyama",
            "Skylar Lu",
            "Sachin Beepath",
            "Ediz Ertekin Jr.",
            "Maria Perez-Ortiz"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T09:15:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15484v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15484v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000086,
        "doi": null,
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "abstract": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously\nused to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring\nbias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant\nbiases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except\nfor Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "chunk-id": 4,
        "chunk": "biases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except",
        "authors": [
            "Ze Wang",
            "Zekun Wu",
            "Xin Guan",
            "Michael Thaler",
            "Adriano Koshiyama",
            "Skylar Lu",
            "Sachin Beepath",
            "Ediz Ertekin Jr.",
            "Maria Perez-Ortiz"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T09:15:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15484v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15484v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000086,
        "doi": null,
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "abstract": "This paper presents a novel framework for benchmarking hierarchical gender\nhiring bias in Large Language Models (LLMs) for resume scoring, revealing\nsignificant issues of reverse bias and overdebiasing. Our contributions are\nfourfold: First, we introduce a framework using a real, anonymized resume\ndataset from the Healthcare, Finance, and Construction industries, meticulously\nused to avoid confounding factors. It evaluates gender hiring biases across\nhierarchical levels, including Level bias, Spread bias, Taste-based bias, and\nStatistical bias. This framework can be generalized to other social traits and\ntasks easily. Second, we propose novel statistical and computational hiring\nbias metrics based on a counterfactual approach, including Rank After Scoring\n(RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed\nEffects Model-based Metrics. These metrics, rooted in labor economics, NLP, and\nlaw, enable holistic evaluation of hiring biases. Third, we analyze hiring\nbiases in ten state-of-the-art LLMs. Six out of ten LLMs show significant\nbiases against males in healthcare and finance. An industry-effect regression\nreveals that the healthcare industry is the most biased against males. GPT-4o\nand GPT-3.5 are the most biased models, showing significant bias in all three\nindustries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and\nLlama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except\nfor Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "chunk-id": 5,
        "chunk": "for Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of\nrandom expansion or reduction of resume content. Finally, we offer a\nuser-friendly demo to facilitate adoption and practical application of the\nframework.",
        "authors": [
            "Ze Wang",
            "Zekun Wu",
            "Xin Guan",
            "Michael Thaler",
            "Adriano Koshiyama",
            "Skylar Lu",
            "Sachin Beepath",
            "Ediz Ertekin Jr.",
            "Maria Perez-Ortiz"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T09:15:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15484v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15484v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ]
    },
    {
        "id": 20000087,
        "doi": null,
        "title": "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences",
        "abstract": "The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid\nanswering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or\nviolate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,\nalthough only the latter mitigates most reasoning biases without harming model\nconsistency.",
        "chunk-id": 1,
        "chunk": "The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid",
        "authors": [
            "Leonardo Bertolazzi",
            "Albert Gatt",
            "Raffaella Bernardi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:59:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11341v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000087,
        "doi": null,
        "title": "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences",
        "abstract": "The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid\nanswering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or\nviolate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,\nalthough only the latter mitigates most reasoning biases without harming model\nconsistency.",
        "chunk-id": 2,
        "chunk": "answering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or",
        "authors": [
            "Leonardo Bertolazzi",
            "Albert Gatt",
            "Raffaella Bernardi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:59:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11341v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000087,
        "doi": null,
        "title": "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences",
        "abstract": "The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid\nanswering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or\nviolate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,\nalthough only the latter mitigates most reasoning biases without harming model\nconsistency.",
        "chunk-id": 3,
        "chunk": "violate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,",
        "authors": [
            "Leonardo Bertolazzi",
            "Albert Gatt",
            "Raffaella Bernardi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:59:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11341v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000087,
        "doi": null,
        "title": "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences",
        "abstract": "The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid\nanswering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or\nviolate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,\nalthough only the latter mitigates most reasoning biases without harming model\nconsistency.",
        "chunk-id": 4,
        "chunk": "although only the latter mitigates most reasoning biases without harming model\nconsistency.",
        "authors": [
            "Leonardo Bertolazzi",
            "Albert Gatt",
            "Raffaella Bernardi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:59:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11341v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000088,
        "doi": null,
        "title": "An Empirical Investigation of Matrix Factorization Methods for Pre-trained Transformers",
        "abstract": "The increasing size of transformer-based models in NLP makes the question of\ncompressing them important. In this work, we present a comprehensive analysis\nof factorization based model compression techniques. Specifically, we focus on\ncomparing straightforward low-rank factorization against the recently\nintroduced Monarch factorization, which exhibits impressive performance\npreservation on the GLUE benchmark. To mitigate stability issues associated\nwith low-rank factorization of the matrices in pre-trained transformers, we\nintroduce a staged factorization approach wherein layers are factorized one by\none instead of being factorized simultaneously. Through this strategy we\nsignificantly enhance the stability and reliability of the compression process.\nFurther, we introduce a simple block-wise low-rank factorization method, which\nhas a close relationship to Monarch factorization. Our experiments lead to the\nsurprising conclusion that straightforward low-rank factorization consistently\noutperforms Monarch factorization across both different compression ratios and\nsix different text classification tasks.",
        "chunk-id": 1,
        "chunk": "The increasing size of transformer-based models in NLP makes the question of\ncompressing them important. In this work, we present a comprehensive analysis\nof factorization based model compression techniques. Specifically, we focus on\ncomparing straightforward low-rank factorization against the recently\nintroduced Monarch factorization, which exhibits impressive performance",
        "authors": [
            "Ashim Gupta",
            "Sina Mahdipour Saravani",
            "P. Sadayappan",
            "Vivek Srikumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000088,
        "doi": null,
        "title": "An Empirical Investigation of Matrix Factorization Methods for Pre-trained Transformers",
        "abstract": "The increasing size of transformer-based models in NLP makes the question of\ncompressing them important. In this work, we present a comprehensive analysis\nof factorization based model compression techniques. Specifically, we focus on\ncomparing straightforward low-rank factorization against the recently\nintroduced Monarch factorization, which exhibits impressive performance\npreservation on the GLUE benchmark. To mitigate stability issues associated\nwith low-rank factorization of the matrices in pre-trained transformers, we\nintroduce a staged factorization approach wherein layers are factorized one by\none instead of being factorized simultaneously. Through this strategy we\nsignificantly enhance the stability and reliability of the compression process.\nFurther, we introduce a simple block-wise low-rank factorization method, which\nhas a close relationship to Monarch factorization. Our experiments lead to the\nsurprising conclusion that straightforward low-rank factorization consistently\noutperforms Monarch factorization across both different compression ratios and\nsix different text classification tasks.",
        "chunk-id": 2,
        "chunk": "preservation on the GLUE benchmark. To mitigate stability issues associated\nwith low-rank factorization of the matrices in pre-trained transformers, we\nintroduce a staged factorization approach wherein layers are factorized one by\none instead of being factorized simultaneously. Through this strategy we\nsignificantly enhance the stability and reliability of the compression process.",
        "authors": [
            "Ashim Gupta",
            "Sina Mahdipour Saravani",
            "P. Sadayappan",
            "Vivek Srikumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000088,
        "doi": null,
        "title": "An Empirical Investigation of Matrix Factorization Methods for Pre-trained Transformers",
        "abstract": "The increasing size of transformer-based models in NLP makes the question of\ncompressing them important. In this work, we present a comprehensive analysis\nof factorization based model compression techniques. Specifically, we focus on\ncomparing straightforward low-rank factorization against the recently\nintroduced Monarch factorization, which exhibits impressive performance\npreservation on the GLUE benchmark. To mitigate stability issues associated\nwith low-rank factorization of the matrices in pre-trained transformers, we\nintroduce a staged factorization approach wherein layers are factorized one by\none instead of being factorized simultaneously. Through this strategy we\nsignificantly enhance the stability and reliability of the compression process.\nFurther, we introduce a simple block-wise low-rank factorization method, which\nhas a close relationship to Monarch factorization. Our experiments lead to the\nsurprising conclusion that straightforward low-rank factorization consistently\noutperforms Monarch factorization across both different compression ratios and\nsix different text classification tasks.",
        "chunk-id": 3,
        "chunk": "Further, we introduce a simple block-wise low-rank factorization method, which\nhas a close relationship to Monarch factorization. Our experiments lead to the\nsurprising conclusion that straightforward low-rank factorization consistently\noutperforms Monarch factorization across both different compression ratios and\nsix different text classification tasks.",
        "authors": [
            "Ashim Gupta",
            "Sina Mahdipour Saravani",
            "P. Sadayappan",
            "Vivek Srikumar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T08:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11307v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11307v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000089,
        "doi": null,
        "title": "Duplicate Detection with GenAI",
        "abstract": "Customer data is often stored as records in Customer Relations Management\nsystems (CRMs). Data which is manually entered into such systems by one of more\nusers over time leads to data replication, partial duplication or fuzzy\nduplication. This in turn means that there no longer a single source of truth\nfor customers, contacts, accounts, etc. Downstream business processes become\nincreasing complex and contrived without a unique mapping between a record in a\nCRM and the target customer. Current methods to detect and de-duplicate records\nuse traditional Natural Language Processing techniques known as Entity\nMatching. In this paper we show how using the latest advancements in Large\nLanguage Models and Generative AI can vastly improve the identification and\nrepair of duplicated records. On common benchmark datasets we find an\nimprovement in the accuracy of data de-duplication rates from 30 percent using\nNLP techniques to almost 60 percent using our proposed method.",
        "chunk-id": 1,
        "chunk": "Customer data is often stored as records in Customer Relations Management\nsystems (CRMs). Data which is manually entered into such systems by one of more\nusers over time leads to data replication, partial duplication or fuzzy\nduplication. This in turn means that there no longer a single source of truth\nfor customers, contacts, accounts, etc. Downstream business processes become",
        "authors": [
            "Ian Ormesher"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15483v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15483v1",
        "categories": [
            "Computation and Language",
            "Databases",
            "Machine Learning"
        ]
    },
    {
        "id": 20000089,
        "doi": null,
        "title": "Duplicate Detection with GenAI",
        "abstract": "Customer data is often stored as records in Customer Relations Management\nsystems (CRMs). Data which is manually entered into such systems by one of more\nusers over time leads to data replication, partial duplication or fuzzy\nduplication. This in turn means that there no longer a single source of truth\nfor customers, contacts, accounts, etc. Downstream business processes become\nincreasing complex and contrived without a unique mapping between a record in a\nCRM and the target customer. Current methods to detect and de-duplicate records\nuse traditional Natural Language Processing techniques known as Entity\nMatching. In this paper we show how using the latest advancements in Large\nLanguage Models and Generative AI can vastly improve the identification and\nrepair of duplicated records. On common benchmark datasets we find an\nimprovement in the accuracy of data de-duplication rates from 30 percent using\nNLP techniques to almost 60 percent using our proposed method.",
        "chunk-id": 2,
        "chunk": "increasing complex and contrived without a unique mapping between a record in a\nCRM and the target customer. Current methods to detect and de-duplicate records\nuse traditional Natural Language Processing techniques known as Entity\nMatching. In this paper we show how using the latest advancements in Large\nLanguage Models and Generative AI can vastly improve the identification and",
        "authors": [
            "Ian Ormesher"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15483v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15483v1",
        "categories": [
            "Computation and Language",
            "Databases",
            "Machine Learning"
        ]
    },
    {
        "id": 20000089,
        "doi": null,
        "title": "Duplicate Detection with GenAI",
        "abstract": "Customer data is often stored as records in Customer Relations Management\nsystems (CRMs). Data which is manually entered into such systems by one of more\nusers over time leads to data replication, partial duplication or fuzzy\nduplication. This in turn means that there no longer a single source of truth\nfor customers, contacts, accounts, etc. Downstream business processes become\nincreasing complex and contrived without a unique mapping between a record in a\nCRM and the target customer. Current methods to detect and de-duplicate records\nuse traditional Natural Language Processing techniques known as Entity\nMatching. In this paper we show how using the latest advancements in Large\nLanguage Models and Generative AI can vastly improve the identification and\nrepair of duplicated records. On common benchmark datasets we find an\nimprovement in the accuracy of data de-duplication rates from 30 percent using\nNLP techniques to almost 60 percent using our proposed method.",
        "chunk-id": 3,
        "chunk": "repair of duplicated records. On common benchmark datasets we find an\nimprovement in the accuracy of data de-duplication rates from 30 percent using\nNLP techniques to almost 60 percent using our proposed method.",
        "authors": [
            "Ian Ormesher"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15483v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15483v1",
        "categories": [
            "Computation and Language",
            "Databases",
            "Machine Learning"
        ]
    },
    {
        "id": 20000090,
        "doi": null,
        "title": "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs",
        "abstract": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered\nby the sharing of personal experiences through narratives. However, modeling\nempathy using NLP approaches remains challenging due to its deep\ninterconnection with human interaction dynamics. Previous approaches, which\ninvolve fine-tuning language models (LMs) on human-annotated empathic datasets,\nhave had limited success. In our pursuit of improving empathy understanding in\nLMs, we propose several strategies, including contrastive learning with masked\nLMs and supervised fine-tuning with Large Language Models (LLMs). While these\nmethods show improvements over previous methods, the overall results remain\nunsatisfactory. To better understand this trend, we performed an analysis which\nreveals a low agreement among annotators. This lack of consensus hinders\ntraining and highlights the subjective nature of the task. We also explore the\ncultural impact on annotations. To study this, we meticulously collected story\npairs in Urdu language and find that subjectivity in interpreting empathy among\nannotators appears to be independent of cultural background. The insights from\nour systematic exploration of LMs' understanding of empathy suggest that there\nis considerable room for exploration in both task formulation and modeling.",
        "chunk-id": 1,
        "chunk": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered\nby the sharing of personal experiences through narratives. However, modeling\nempathy using NLP approaches remains challenging due to its deep\ninterconnection with human interaction dynamics. Previous approaches, which\ninvolve fine-tuning language models (LMs) on human-annotated empathic datasets,",
        "authors": [
            "Muhammad Arslan Manzoor",
            "Yuxia Wang",
            "Minghan Wang",
            "Preslav Nakov"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:22:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11250v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11250v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000090,
        "doi": null,
        "title": "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs",
        "abstract": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered\nby the sharing of personal experiences through narratives. However, modeling\nempathy using NLP approaches remains challenging due to its deep\ninterconnection with human interaction dynamics. Previous approaches, which\ninvolve fine-tuning language models (LMs) on human-annotated empathic datasets,\nhave had limited success. In our pursuit of improving empathy understanding in\nLMs, we propose several strategies, including contrastive learning with masked\nLMs and supervised fine-tuning with Large Language Models (LLMs). While these\nmethods show improvements over previous methods, the overall results remain\nunsatisfactory. To better understand this trend, we performed an analysis which\nreveals a low agreement among annotators. This lack of consensus hinders\ntraining and highlights the subjective nature of the task. We also explore the\ncultural impact on annotations. To study this, we meticulously collected story\npairs in Urdu language and find that subjectivity in interpreting empathy among\nannotators appears to be independent of cultural background. The insights from\nour systematic exploration of LMs' understanding of empathy suggest that there\nis considerable room for exploration in both task formulation and modeling.",
        "chunk-id": 2,
        "chunk": "have had limited success. In our pursuit of improving empathy understanding in\nLMs, we propose several strategies, including contrastive learning with masked\nLMs and supervised fine-tuning with Large Language Models (LLMs). While these\nmethods show improvements over previous methods, the overall results remain",
        "authors": [
            "Muhammad Arslan Manzoor",
            "Yuxia Wang",
            "Minghan Wang",
            "Preslav Nakov"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:22:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11250v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11250v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000090,
        "doi": null,
        "title": "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs",
        "abstract": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered\nby the sharing of personal experiences through narratives. However, modeling\nempathy using NLP approaches remains challenging due to its deep\ninterconnection with human interaction dynamics. Previous approaches, which\ninvolve fine-tuning language models (LMs) on human-annotated empathic datasets,\nhave had limited success. In our pursuit of improving empathy understanding in\nLMs, we propose several strategies, including contrastive learning with masked\nLMs and supervised fine-tuning with Large Language Models (LLMs). While these\nmethods show improvements over previous methods, the overall results remain\nunsatisfactory. To better understand this trend, we performed an analysis which\nreveals a low agreement among annotators. This lack of consensus hinders\ntraining and highlights the subjective nature of the task. We also explore the\ncultural impact on annotations. To study this, we meticulously collected story\npairs in Urdu language and find that subjectivity in interpreting empathy among\nannotators appears to be independent of cultural background. The insights from\nour systematic exploration of LMs' understanding of empathy suggest that there\nis considerable room for exploration in both task formulation and modeling.",
        "chunk-id": 3,
        "chunk": "unsatisfactory. To better understand this trend, we performed an analysis which\nreveals a low agreement among annotators. This lack of consensus hinders\ntraining and highlights the subjective nature of the task. We also explore the\ncultural impact on annotations. To study this, we meticulously collected story",
        "authors": [
            "Muhammad Arslan Manzoor",
            "Yuxia Wang",
            "Minghan Wang",
            "Preslav Nakov"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:22:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11250v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11250v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000090,
        "doi": null,
        "title": "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs",
        "abstract": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered\nby the sharing of personal experiences through narratives. However, modeling\nempathy using NLP approaches remains challenging due to its deep\ninterconnection with human interaction dynamics. Previous approaches, which\ninvolve fine-tuning language models (LMs) on human-annotated empathic datasets,\nhave had limited success. In our pursuit of improving empathy understanding in\nLMs, we propose several strategies, including contrastive learning with masked\nLMs and supervised fine-tuning with Large Language Models (LLMs). While these\nmethods show improvements over previous methods, the overall results remain\nunsatisfactory. To better understand this trend, we performed an analysis which\nreveals a low agreement among annotators. This lack of consensus hinders\ntraining and highlights the subjective nature of the task. We also explore the\ncultural impact on annotations. To study this, we meticulously collected story\npairs in Urdu language and find that subjectivity in interpreting empathy among\nannotators appears to be independent of cultural background. The insights from\nour systematic exploration of LMs' understanding of empathy suggest that there\nis considerable room for exploration in both task formulation and modeling.",
        "chunk-id": 4,
        "chunk": "pairs in Urdu language and find that subjectivity in interpreting empathy among\nannotators appears to be independent of cultural background. The insights from\nour systematic exploration of LMs' understanding of empathy suggest that there\nis considerable room for exploration in both task formulation and modeling.",
        "authors": [
            "Muhammad Arslan Manzoor",
            "Yuxia Wang",
            "Minghan Wang",
            "Preslav Nakov"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T06:22:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11250v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11250v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000091,
        "doi": null,
        "title": "Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance",
        "abstract": "The integration of pretrained language models (PLMs) like BERT and GPT has\nrevolutionized NLP, particularly for English, but it has also created\nlinguistic imbalances. This paper strategically identifies the need for\nlinguistic equity by examining several knowledge editing techniques in\nmultilingual contexts. We evaluate the performance of models such as Mistral,\nTowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including\nEnglish, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our\nresearch identifies significant discrepancies in normal and merged models\nconcerning cross-lingual consistency. We employ strategies like 'each language\nfor itself' (ELFI) and 'each language for others' (ELFO) to stress-test these\nmodels. Our findings demonstrate the potential for LLMs to overcome linguistic\nbarriers, laying the groundwork for future research in achieving linguistic\ninclusivity in AI technologies.",
        "chunk-id": 1,
        "chunk": "The integration of pretrained language models (PLMs) like BERT and GPT has\nrevolutionized NLP, particularly for English, but it has also created\nlinguistic imbalances. This paper strategically identifies the need for\nlinguistic equity by examining several knowledge editing techniques in\nmultilingual contexts. We evaluate the performance of models such as Mistral,",
        "authors": [
            "Somnath Banerjee",
            "Avik Halder",
            "Rajarshi Mandal",
            "Sayan Layek",
            "Ian Soboroff",
            "Rima Hazra",
            "Animesh Mukherjee"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T01:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11139v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11139v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000091,
        "doi": null,
        "title": "Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance",
        "abstract": "The integration of pretrained language models (PLMs) like BERT and GPT has\nrevolutionized NLP, particularly for English, but it has also created\nlinguistic imbalances. This paper strategically identifies the need for\nlinguistic equity by examining several knowledge editing techniques in\nmultilingual contexts. We evaluate the performance of models such as Mistral,\nTowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including\nEnglish, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our\nresearch identifies significant discrepancies in normal and merged models\nconcerning cross-lingual consistency. We employ strategies like 'each language\nfor itself' (ELFI) and 'each language for others' (ELFO) to stress-test these\nmodels. Our findings demonstrate the potential for LLMs to overcome linguistic\nbarriers, laying the groundwork for future research in achieving linguistic\ninclusivity in AI technologies.",
        "chunk-id": 2,
        "chunk": "TowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including\nEnglish, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our\nresearch identifies significant discrepancies in normal and merged models\nconcerning cross-lingual consistency. We employ strategies like 'each language\nfor itself' (ELFI) and 'each language for others' (ELFO) to stress-test these",
        "authors": [
            "Somnath Banerjee",
            "Avik Halder",
            "Rajarshi Mandal",
            "Sayan Layek",
            "Ian Soboroff",
            "Rima Hazra",
            "Animesh Mukherjee"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T01:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11139v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11139v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000091,
        "doi": null,
        "title": "Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance",
        "abstract": "The integration of pretrained language models (PLMs) like BERT and GPT has\nrevolutionized NLP, particularly for English, but it has also created\nlinguistic imbalances. This paper strategically identifies the need for\nlinguistic equity by examining several knowledge editing techniques in\nmultilingual contexts. We evaluate the performance of models such as Mistral,\nTowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including\nEnglish, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our\nresearch identifies significant discrepancies in normal and merged models\nconcerning cross-lingual consistency. We employ strategies like 'each language\nfor itself' (ELFI) and 'each language for others' (ELFO) to stress-test these\nmodels. Our findings demonstrate the potential for LLMs to overcome linguistic\nbarriers, laying the groundwork for future research in achieving linguistic\ninclusivity in AI technologies.",
        "chunk-id": 3,
        "chunk": "models. Our findings demonstrate the potential for LLMs to overcome linguistic\nbarriers, laying the groundwork for future research in achieving linguistic\ninclusivity in AI technologies.",
        "authors": [
            "Somnath Banerjee",
            "Avik Halder",
            "Rajarshi Mandal",
            "Sayan Layek",
            "Ian Soboroff",
            "Rima Hazra",
            "Animesh Mukherjee"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-17T01:54:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11139v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11139v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 1,
        "chunk": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 2,
        "chunk": "time-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 3,
        "chunk": "language use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 4,
        "chunk": "\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 5,
        "chunk": "Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000092,
        "doi": null,
        "title": "Enhancing Class Diagram Dynamics: A Natural Language Approach with ChatGPT",
        "abstract": "Integrating artificial intelligence (AI) into software engineering can\ntransform traditional practices by enhancing efficiency, accuracy, and\ninnovation. This study explores using ChatGPT, an advanced AI language model,\nto enhance UML class diagrams dynamically, an underexplored area.\nTraditionally, creating and maintaining class diagrams are manual,\ntime-consuming, and error-prone processes. This research leverages natural\nlanguage processing (NLP) techniques to automate the extraction of methods and\ninteractions from detailed use case tables and integrate them into class\ndiagrams.\n  The methodology involves several steps: (1) developing detailed natural\nlanguage use case tables by master's degree students for a \"Waste Recycling\nPlatform,\" (2) creating an initial static class diagram based on these tables,\n(3) iteratively enriching the class diagram through ChatGPT integration to\nanalyze use cases and suggest methods, (4) reviewing and incorporating these\nmethods into the class diagram, and (5) dynamically updating the PlantUML\n\\cite{plantuml} class diagram, followed by evaluation and refinement. Findings\nindicate that the AI-driven approach significantly improves the accuracy and\ncompleteness of the class diagram. Additionally, dynamic enhancement aligns\nwell with Agile development practices, facilitating rapid iterations and\ncontinuous improvement.\n  Key contributions include demonstrating the feasibility and benefits of\nintegrating AI into software modeling tasks, providing a comprehensive\nrepresentation of system behaviors and interactions, and highlighting AI's\npotential to streamline and improve existing software engineering processes.\nFuture research should address identified limitations and explore AI\napplications in other software models.",
        "chunk-id": 6,
        "chunk": "applications in other software models.",
        "authors": [
            "Djaber Rouabhia",
            "Ismail Hadjadj"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T16:30:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.11002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.11002v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 20000093,
        "doi": null,
        "title": "Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?",
        "abstract": "Modeling legal reasoning and argumentation justifying decisions in cases has\nalways been central to AI & Law, yet contemporary developments in legal NLP\nhave increasingly focused on statistically classifying legal conclusions from\ntext. While conceptually simpler, these approaches often fall short in\nproviding usable justifications connecting to appropriate legal concepts. This\npaper reviews both traditional symbolic works in AI & Law and recent advances\nin legal NLP, and distills possibilities of integrating expert-informed\nknowledge to strike a balance between scalability and explanation in symbolic\nvs. data-driven approaches. We identify open challenges and discuss the\npotential of modern NLP models and methods that integrate",
        "chunk-id": 1,
        "chunk": "Modeling legal reasoning and argumentation justifying decisions in cases has\nalways been central to AI & Law, yet contemporary developments in legal NLP\nhave increasingly focused on statistically classifying legal conclusions from\ntext. While conceptually simpler, these approaches often fall short in\nproviding usable justifications connecting to appropriate legal concepts. This",
        "authors": [
            "T. Y. S. S Santosh",
            "Kevin D. Ashley",
            "Katie Atkinson",
            "Matthias Grabmair"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T15:15:44+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10974v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10974v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000093,
        "doi": null,
        "title": "Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?",
        "abstract": "Modeling legal reasoning and argumentation justifying decisions in cases has\nalways been central to AI & Law, yet contemporary developments in legal NLP\nhave increasingly focused on statistically classifying legal conclusions from\ntext. While conceptually simpler, these approaches often fall short in\nproviding usable justifications connecting to appropriate legal concepts. This\npaper reviews both traditional symbolic works in AI & Law and recent advances\nin legal NLP, and distills possibilities of integrating expert-informed\nknowledge to strike a balance between scalability and explanation in symbolic\nvs. data-driven approaches. We identify open challenges and discuss the\npotential of modern NLP models and methods that integrate",
        "chunk-id": 2,
        "chunk": "paper reviews both traditional symbolic works in AI & Law and recent advances\nin legal NLP, and distills possibilities of integrating expert-informed\nknowledge to strike a balance between scalability and explanation in symbolic\nvs. data-driven approaches. We identify open challenges and discuss the\npotential of modern NLP models and methods that integrate",
        "authors": [
            "T. Y. S. S Santosh",
            "Kevin D. Ashley",
            "Katie Atkinson",
            "Matthias Grabmair"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T15:15:44+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10974v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10974v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000094,
        "doi": null,
        "title": "ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language",
        "abstract": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains\nunderexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)\nyields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including quality filters, optimization strategies,\nand multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle\ncompared to our baseline. We release $\\texttt{ptt5-v2}$ pretrained checkpoints\nand the finetuned MonoT5 rerankers on HuggingFace at\nhttps://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0\nand\nhttps://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d.",
        "chunk-id": 1,
        "chunk": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains",
        "authors": [
            "Marcos Piau",
            "Roberto Lotufo",
            "Rodrigo Nogueira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T05:17:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10806v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10806v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000094,
        "doi": null,
        "title": "ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language",
        "abstract": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains\nunderexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)\nyields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including quality filters, optimization strategies,\nand multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle\ncompared to our baseline. We release $\\texttt{ptt5-v2}$ pretrained checkpoints\nand the finetuned MonoT5 rerankers on HuggingFace at\nhttps://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0\nand\nhttps://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d.",
        "chunk-id": 2,
        "chunk": "underexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)",
        "authors": [
            "Marcos Piau",
            "Roberto Lotufo",
            "Rodrigo Nogueira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T05:17:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10806v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10806v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000094,
        "doi": null,
        "title": "ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language",
        "abstract": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains\nunderexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)\nyields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including quality filters, optimization strategies,\nand multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle\ncompared to our baseline. We release $\\texttt{ptt5-v2}$ pretrained checkpoints\nand the finetuned MonoT5 rerankers on HuggingFace at\nhttps://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0\nand\nhttps://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d.",
        "chunk-id": 3,
        "chunk": "yields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including quality filters, optimization strategies,\nand multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle\ncompared to our baseline. We release $\\texttt{ptt5-v2}$ pretrained checkpoints\nand the finetuned MonoT5 rerankers on HuggingFace at",
        "authors": [
            "Marcos Piau",
            "Roberto Lotufo",
            "Rodrigo Nogueira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T05:17:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10806v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10806v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000094,
        "doi": null,
        "title": "ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language",
        "abstract": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains\nunderexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)\nyields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including quality filters, optimization strategies,\nand multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle\ncompared to our baseline. We release $\\texttt{ptt5-v2}$ pretrained checkpoints\nand the finetuned MonoT5 rerankers on HuggingFace at\nhttps://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0\nand\nhttps://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d.",
        "chunk-id": 4,
        "chunk": "https://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0\nand\nhttps://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d.",
        "authors": [
            "Marcos Piau",
            "Roberto Lotufo",
            "Rodrigo Nogueira"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T05:17:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10806v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10806v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 20000095,
        "doi": null,
        "title": "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning",
        "abstract": "Pre-trained language models, trained on large-scale corpora, demonstrate\nstrong generalizability across various NLP tasks. Fine-tuning these models for\nspecific tasks typically involves updating all parameters, which is\nresource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the\npopular LoRA family, introduce low-rank matrices to learn only a few parameters\nefficiently. However, during inference, the product of these matrices updates\nall pre-trained parameters, complicating tasks like knowledge editing that\nrequire selective updates. We propose a novel PEFT method, which conducts\n\\textbf{r}ow and c\\textbf{o}lumn-wise spar\\textbf{se}\n\\textbf{lo}w-\\textbf{r}ank \\textbf{a}daptation (RoseLoRA), to address this\nchallenge. RoseLoRA identifies and updates only the most important parameters\nfor a specific task, maintaining efficiency while preserving other model\nknowledge. By adding a sparsity constraint on the product of low-rank matrices\nand converting it to row and column-wise sparsity, we ensure efficient and\nprecise model updates. Our theoretical analysis guarantees the lower bound of\nthe sparsity with respective to the matrix product. Extensive experiments on\nfive benchmarks across twenty datasets demonstrate that RoseLoRA outperforms\nbaselines in both general fine-tuning and knowledge editing tasks.",
        "chunk-id": 1,
        "chunk": "Pre-trained language models, trained on large-scale corpora, demonstrate\nstrong generalizability across various NLP tasks. Fine-tuning these models for\nspecific tasks typically involves updating all parameters, which is\nresource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the\npopular LoRA family, introduce low-rank matrices to learn only a few parameters",
        "authors": [
            "Haoyu Wang",
            "Tianci Liu",
            "Tuo Zhao",
            "Jing Gao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T02:08:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10777v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10777v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000095,
        "doi": null,
        "title": "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning",
        "abstract": "Pre-trained language models, trained on large-scale corpora, demonstrate\nstrong generalizability across various NLP tasks. Fine-tuning these models for\nspecific tasks typically involves updating all parameters, which is\nresource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the\npopular LoRA family, introduce low-rank matrices to learn only a few parameters\nefficiently. However, during inference, the product of these matrices updates\nall pre-trained parameters, complicating tasks like knowledge editing that\nrequire selective updates. We propose a novel PEFT method, which conducts\n\\textbf{r}ow and c\\textbf{o}lumn-wise spar\\textbf{se}\n\\textbf{lo}w-\\textbf{r}ank \\textbf{a}daptation (RoseLoRA), to address this\nchallenge. RoseLoRA identifies and updates only the most important parameters\nfor a specific task, maintaining efficiency while preserving other model\nknowledge. By adding a sparsity constraint on the product of low-rank matrices\nand converting it to row and column-wise sparsity, we ensure efficient and\nprecise model updates. Our theoretical analysis guarantees the lower bound of\nthe sparsity with respective to the matrix product. Extensive experiments on\nfive benchmarks across twenty datasets demonstrate that RoseLoRA outperforms\nbaselines in both general fine-tuning and knowledge editing tasks.",
        "chunk-id": 2,
        "chunk": "efficiently. However, during inference, the product of these matrices updates\nall pre-trained parameters, complicating tasks like knowledge editing that\nrequire selective updates. We propose a novel PEFT method, which conducts\n\\textbf{r}ow and c\\textbf{o}lumn-wise spar\\textbf{se}\n\\textbf{lo}w-\\textbf{r}ank \\textbf{a}daptation (RoseLoRA), to address this",
        "authors": [
            "Haoyu Wang",
            "Tianci Liu",
            "Tuo Zhao",
            "Jing Gao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T02:08:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10777v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10777v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000095,
        "doi": null,
        "title": "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning",
        "abstract": "Pre-trained language models, trained on large-scale corpora, demonstrate\nstrong generalizability across various NLP tasks. Fine-tuning these models for\nspecific tasks typically involves updating all parameters, which is\nresource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the\npopular LoRA family, introduce low-rank matrices to learn only a few parameters\nefficiently. However, during inference, the product of these matrices updates\nall pre-trained parameters, complicating tasks like knowledge editing that\nrequire selective updates. We propose a novel PEFT method, which conducts\n\\textbf{r}ow and c\\textbf{o}lumn-wise spar\\textbf{se}\n\\textbf{lo}w-\\textbf{r}ank \\textbf{a}daptation (RoseLoRA), to address this\nchallenge. RoseLoRA identifies and updates only the most important parameters\nfor a specific task, maintaining efficiency while preserving other model\nknowledge. By adding a sparsity constraint on the product of low-rank matrices\nand converting it to row and column-wise sparsity, we ensure efficient and\nprecise model updates. Our theoretical analysis guarantees the lower bound of\nthe sparsity with respective to the matrix product. Extensive experiments on\nfive benchmarks across twenty datasets demonstrate that RoseLoRA outperforms\nbaselines in both general fine-tuning and knowledge editing tasks.",
        "chunk-id": 3,
        "chunk": "challenge. RoseLoRA identifies and updates only the most important parameters\nfor a specific task, maintaining efficiency while preserving other model\nknowledge. By adding a sparsity constraint on the product of low-rank matrices\nand converting it to row and column-wise sparsity, we ensure efficient and\nprecise model updates. Our theoretical analysis guarantees the lower bound of",
        "authors": [
            "Haoyu Wang",
            "Tianci Liu",
            "Tuo Zhao",
            "Jing Gao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T02:08:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10777v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10777v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000095,
        "doi": null,
        "title": "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning",
        "abstract": "Pre-trained language models, trained on large-scale corpora, demonstrate\nstrong generalizability across various NLP tasks. Fine-tuning these models for\nspecific tasks typically involves updating all parameters, which is\nresource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the\npopular LoRA family, introduce low-rank matrices to learn only a few parameters\nefficiently. However, during inference, the product of these matrices updates\nall pre-trained parameters, complicating tasks like knowledge editing that\nrequire selective updates. We propose a novel PEFT method, which conducts\n\\textbf{r}ow and c\\textbf{o}lumn-wise spar\\textbf{se}\n\\textbf{lo}w-\\textbf{r}ank \\textbf{a}daptation (RoseLoRA), to address this\nchallenge. RoseLoRA identifies and updates only the most important parameters\nfor a specific task, maintaining efficiency while preserving other model\nknowledge. By adding a sparsity constraint on the product of low-rank matrices\nand converting it to row and column-wise sparsity, we ensure efficient and\nprecise model updates. Our theoretical analysis guarantees the lower bound of\nthe sparsity with respective to the matrix product. Extensive experiments on\nfive benchmarks across twenty datasets demonstrate that RoseLoRA outperforms\nbaselines in both general fine-tuning and knowledge editing tasks.",
        "chunk-id": 4,
        "chunk": "the sparsity with respective to the matrix product. Extensive experiments on\nfive benchmarks across twenty datasets demonstrate that RoseLoRA outperforms\nbaselines in both general fine-tuning and knowledge editing tasks.",
        "authors": [
            "Haoyu Wang",
            "Tianci Liu",
            "Tuo Zhao",
            "Jing Gao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-16T02:08:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10777v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10777v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000096,
        "doi": null,
        "title": "A Comprehensive Survey of Foundation Models in Medicine",
        "abstract": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.",
        "chunk-id": 1,
        "chunk": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural",
        "authors": [
            "Wasif Khan",
            "Seowung Leem",
            "Kyle B. See",
            "Joshua K. Wong",
            "Shaoting Zhang",
            "Ruogu Fang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T20:04:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10729v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10729v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000096,
        "doi": null,
        "title": "A Comprehensive Survey of Foundation Models in Medicine",
        "abstract": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.",
        "chunk-id": 2,
        "chunk": "language processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,",
        "authors": [
            "Wasif Khan",
            "Seowung Leem",
            "Kyle B. See",
            "Joshua K. Wong",
            "Shaoting Zhang",
            "Ruogu Fang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T20:04:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10729v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10729v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000096,
        "doi": null,
        "title": "A Comprehensive Survey of Foundation Models in Medicine",
        "abstract": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.",
        "chunk-id": 3,
        "chunk": "and challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,",
        "authors": [
            "Wasif Khan",
            "Seowung Leem",
            "Kyle B. See",
            "Joshua K. Wong",
            "Shaoting Zhang",
            "Ruogu Fang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T20:04:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10729v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10729v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000096,
        "doi": null,
        "title": "A Comprehensive Survey of Foundation Models in Medicine",
        "abstract": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.",
        "chunk-id": 4,
        "chunk": "medical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment",
        "authors": [
            "Wasif Khan",
            "Seowung Leem",
            "Kyle B. See",
            "Joshua K. Wong",
            "Shaoting Zhang",
            "Ruogu Fang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T20:04:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10729v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10729v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000096,
        "doi": null,
        "title": "A Comprehensive Survey of Foundation Models in Medicine",
        "abstract": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.",
        "chunk-id": 5,
        "chunk": "and mitigate associated risks.",
        "authors": [
            "Wasif Khan",
            "Seowung Leem",
            "Kyle B. See",
            "Joshua K. Wong",
            "Shaoting Zhang",
            "Ruogu Fang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T20:04:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10729v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10729v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 20000097,
        "doi": null,
        "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
        "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional Natural Language Processing (NLP)\napproaches prioritize generating meaningful and coherent output. Also, the\ncurrent state-of-the-art methods often lack the expressiveness and constraint\nsatisfaction capabilities to handle such tasks effectively. This paper presents\nthe Constraints First Framework to remedy this issue. This framework considers\na constrained text generation problem as a discrete combinatorial optimization\nproblem. It is solved by a constraint programming method that combines\nlinguistic properties (e.g., n-grams or language level) with other more\nclassical constraints (e.g., the number of characters, syllables, or words).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using a large language model. The effectiveness of this\napproach is demonstrated by tackling a new more tediously constrained text\ngeneration problem: the iconic RADNER sentences problem. This problem aims to\ngenerate sentences respecting a set of quite strict rules defined by their use\nin vision and clinical research. Thanks to our CP-based approach, many new\nstrongly constrained sentences have been successfully generated in an automatic\nmanner. This highlights the potential of our approach to handle unreasonably\nconstrained text generation scenarios.",
        "chunk-id": 1,
        "chunk": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional Natural Language Processing (NLP)\napproaches prioritize generating meaningful and coherent output. Also, the\ncurrent state-of-the-art methods often lack the expressiveness and constraint\nsatisfaction capabilities to handle such tasks effectively. This paper presents",
        "authors": [
            "Alexandre Bonlarron",
            "Jean-Charles R\u00e9gin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T17:40:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000097,
        "doi": null,
        "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
        "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional Natural Language Processing (NLP)\napproaches prioritize generating meaningful and coherent output. Also, the\ncurrent state-of-the-art methods often lack the expressiveness and constraint\nsatisfaction capabilities to handle such tasks effectively. This paper presents\nthe Constraints First Framework to remedy this issue. This framework considers\na constrained text generation problem as a discrete combinatorial optimization\nproblem. It is solved by a constraint programming method that combines\nlinguistic properties (e.g., n-grams or language level) with other more\nclassical constraints (e.g., the number of characters, syllables, or words).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using a large language model. The effectiveness of this\napproach is demonstrated by tackling a new more tediously constrained text\ngeneration problem: the iconic RADNER sentences problem. This problem aims to\ngenerate sentences respecting a set of quite strict rules defined by their use\nin vision and clinical research. Thanks to our CP-based approach, many new\nstrongly constrained sentences have been successfully generated in an automatic\nmanner. This highlights the potential of our approach to handle unreasonably\nconstrained text generation scenarios.",
        "chunk-id": 2,
        "chunk": "the Constraints First Framework to remedy this issue. This framework considers\na constrained text generation problem as a discrete combinatorial optimization\nproblem. It is solved by a constraint programming method that combines\nlinguistic properties (e.g., n-grams or language level) with other more\nclassical constraints (e.g., the number of characters, syllables, or words).",
        "authors": [
            "Alexandre Bonlarron",
            "Jean-Charles R\u00e9gin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T17:40:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000097,
        "doi": null,
        "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
        "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional Natural Language Processing (NLP)\napproaches prioritize generating meaningful and coherent output. Also, the\ncurrent state-of-the-art methods often lack the expressiveness and constraint\nsatisfaction capabilities to handle such tasks effectively. This paper presents\nthe Constraints First Framework to remedy this issue. This framework considers\na constrained text generation problem as a discrete combinatorial optimization\nproblem. It is solved by a constraint programming method that combines\nlinguistic properties (e.g., n-grams or language level) with other more\nclassical constraints (e.g., the number of characters, syllables, or words).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using a large language model. The effectiveness of this\napproach is demonstrated by tackling a new more tediously constrained text\ngeneration problem: the iconic RADNER sentences problem. This problem aims to\ngenerate sentences respecting a set of quite strict rules defined by their use\nin vision and clinical research. Thanks to our CP-based approach, many new\nstrongly constrained sentences have been successfully generated in an automatic\nmanner. This highlights the potential of our approach to handle unreasonably\nconstrained text generation scenarios.",
        "chunk-id": 3,
        "chunk": "Eventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using a large language model. The effectiveness of this\napproach is demonstrated by tackling a new more tediously constrained text\ngeneration problem: the iconic RADNER sentences problem. This problem aims to",
        "authors": [
            "Alexandre Bonlarron",
            "Jean-Charles R\u00e9gin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T17:40:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000097,
        "doi": null,
        "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
        "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional Natural Language Processing (NLP)\napproaches prioritize generating meaningful and coherent output. Also, the\ncurrent state-of-the-art methods often lack the expressiveness and constraint\nsatisfaction capabilities to handle such tasks effectively. This paper presents\nthe Constraints First Framework to remedy this issue. This framework considers\na constrained text generation problem as a discrete combinatorial optimization\nproblem. It is solved by a constraint programming method that combines\nlinguistic properties (e.g., n-grams or language level) with other more\nclassical constraints (e.g., the number of characters, syllables, or words).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using a large language model. The effectiveness of this\napproach is demonstrated by tackling a new more tediously constrained text\ngeneration problem: the iconic RADNER sentences problem. This problem aims to\ngenerate sentences respecting a set of quite strict rules defined by their use\nin vision and clinical research. Thanks to our CP-based approach, many new\nstrongly constrained sentences have been successfully generated in an automatic\nmanner. This highlights the potential of our approach to handle unreasonably\nconstrained text generation scenarios.",
        "chunk-id": 4,
        "chunk": "generate sentences respecting a set of quite strict rules defined by their use\nin vision and clinical research. Thanks to our CP-based approach, many new\nstrongly constrained sentences have been successfully generated in an automatic\nmanner. This highlights the potential of our approach to handle unreasonably\nconstrained text generation scenarios.",
        "authors": [
            "Alexandre Bonlarron",
            "Jean-Charles R\u00e9gin"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T17:40:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.15473v1",
        "arxiv_link": "http://arxiv.org/abs/2406.15473v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 20000098,
        "doi": null,
        "title": "Multilingual Large Language Models and Curse of Multilinguality",
        "abstract": "Multilingual Large Language Models (LLMs) have gained large popularity among\nNatural Language Processing (NLP) researchers and practitioners. These models,\ntrained on huge datasets, show proficiency across various languages and\ndemonstrate effectiveness in numerous downstream tasks. This paper navigates\nthe landscape of multilingual LLMs, providing an introductory overview of their\ntechnical aspects. It explains underlying architectures, objective functions,\npre-training data sources, and tokenization methods. This work explores the\nunique features of different model types: encoder-only (mBERT, XLM-R),\ndecoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,\nmBART). Additionally, it addresses one of the significant limitations of\nmultilingual LLMs - the curse of multilinguality - and discusses current\nattempts to overcome it.",
        "chunk-id": 1,
        "chunk": "Multilingual Large Language Models (LLMs) have gained large popularity among\nNatural Language Processing (NLP) researchers and practitioners. These models,\ntrained on huge datasets, show proficiency across various languages and\ndemonstrate effectiveness in numerous downstream tasks. This paper navigates\nthe landscape of multilingual LLMs, providing an introductory overview of their",
        "authors": [
            "Daniil Gurgurov",
            "Tanja B\u00e4umel",
            "Tatiana Anikina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T11:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10602v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10602v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000098,
        "doi": null,
        "title": "Multilingual Large Language Models and Curse of Multilinguality",
        "abstract": "Multilingual Large Language Models (LLMs) have gained large popularity among\nNatural Language Processing (NLP) researchers and practitioners. These models,\ntrained on huge datasets, show proficiency across various languages and\ndemonstrate effectiveness in numerous downstream tasks. This paper navigates\nthe landscape of multilingual LLMs, providing an introductory overview of their\ntechnical aspects. It explains underlying architectures, objective functions,\npre-training data sources, and tokenization methods. This work explores the\nunique features of different model types: encoder-only (mBERT, XLM-R),\ndecoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,\nmBART). Additionally, it addresses one of the significant limitations of\nmultilingual LLMs - the curse of multilinguality - and discusses current\nattempts to overcome it.",
        "chunk-id": 2,
        "chunk": "technical aspects. It explains underlying architectures, objective functions,\npre-training data sources, and tokenization methods. This work explores the\nunique features of different model types: encoder-only (mBERT, XLM-R),\ndecoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,\nmBART). Additionally, it addresses one of the significant limitations of",
        "authors": [
            "Daniil Gurgurov",
            "Tanja B\u00e4umel",
            "Tatiana Anikina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T11:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10602v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10602v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000098,
        "doi": null,
        "title": "Multilingual Large Language Models and Curse of Multilinguality",
        "abstract": "Multilingual Large Language Models (LLMs) have gained large popularity among\nNatural Language Processing (NLP) researchers and practitioners. These models,\ntrained on huge datasets, show proficiency across various languages and\ndemonstrate effectiveness in numerous downstream tasks. This paper navigates\nthe landscape of multilingual LLMs, providing an introductory overview of their\ntechnical aspects. It explains underlying architectures, objective functions,\npre-training data sources, and tokenization methods. This work explores the\nunique features of different model types: encoder-only (mBERT, XLM-R),\ndecoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,\nmBART). Additionally, it addresses one of the significant limitations of\nmultilingual LLMs - the curse of multilinguality - and discusses current\nattempts to overcome it.",
        "chunk-id": 3,
        "chunk": "multilingual LLMs - the curse of multilinguality - and discusses current\nattempts to overcome it.",
        "authors": [
            "Daniil Gurgurov",
            "Tanja B\u00e4umel",
            "Tatiana Anikina"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T11:31:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10602v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10602v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000099,
        "doi": null,
        "title": "CancerLLM: A Large Language Model in Cancer Domain",
        "abstract": "Medical Large Language Models (LLMs) such as ClinicalCamel 70B,\nLlama3-OpenBioLLM 70B have demonstrated impressive performance on a wide\nvariety of medical NLP task.However, there still lacks a large language model\n(LLM) specifically designed for cancer domain. Moreover, these LLMs typically\nhave billions of parameters, making them computationally expensive for\nhealthcare systems.Thus, in this study, we propose CancerLLM, a model with 7\nbillion parameters and a Mistral-style architecture, pre-trained on 2,676,642\nclinical notes and 515,524 pathology reports covering 17 cancer types, followed\nby fine-tuning on three cancer-relevant tasks, including cancer phenotypes\nextraction, cancer diagnosis generation, and cancer treatment plan generation.\nOur evaluation demonstrated that CancerLLM achieves state-of-the-art results\ncompared to other existing LLMs, with an average F1 score improvement of 8.1\\%.\nAdditionally, CancerLLM outperforms other models on two proposed robustness\ntestbeds. This illustrates that CancerLLM can be effectively applied to\nclinical AI systems, enhancing clinical research and healthcare delivery in the\nfield of cancer.",
        "chunk-id": 1,
        "chunk": "Medical Large Language Models (LLMs) such as ClinicalCamel 70B,\nLlama3-OpenBioLLM 70B have demonstrated impressive performance on a wide\nvariety of medical NLP task.However, there still lacks a large language model\n(LLM) specifically designed for cancer domain. Moreover, these LLMs typically\nhave billions of parameters, making them computationally expensive for",
        "authors": [
            "Mingchen Li",
            "Anne Blaes",
            "Steven Johnson",
            "Hongfang Liu",
            "Hua Xu",
            "Rui Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T01:02:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000099,
        "doi": null,
        "title": "CancerLLM: A Large Language Model in Cancer Domain",
        "abstract": "Medical Large Language Models (LLMs) such as ClinicalCamel 70B,\nLlama3-OpenBioLLM 70B have demonstrated impressive performance on a wide\nvariety of medical NLP task.However, there still lacks a large language model\n(LLM) specifically designed for cancer domain. Moreover, these LLMs typically\nhave billions of parameters, making them computationally expensive for\nhealthcare systems.Thus, in this study, we propose CancerLLM, a model with 7\nbillion parameters and a Mistral-style architecture, pre-trained on 2,676,642\nclinical notes and 515,524 pathology reports covering 17 cancer types, followed\nby fine-tuning on three cancer-relevant tasks, including cancer phenotypes\nextraction, cancer diagnosis generation, and cancer treatment plan generation.\nOur evaluation demonstrated that CancerLLM achieves state-of-the-art results\ncompared to other existing LLMs, with an average F1 score improvement of 8.1\\%.\nAdditionally, CancerLLM outperforms other models on two proposed robustness\ntestbeds. This illustrates that CancerLLM can be effectively applied to\nclinical AI systems, enhancing clinical research and healthcare delivery in the\nfield of cancer.",
        "chunk-id": 2,
        "chunk": "healthcare systems.Thus, in this study, we propose CancerLLM, a model with 7\nbillion parameters and a Mistral-style architecture, pre-trained on 2,676,642\nclinical notes and 515,524 pathology reports covering 17 cancer types, followed\nby fine-tuning on three cancer-relevant tasks, including cancer phenotypes",
        "authors": [
            "Mingchen Li",
            "Anne Blaes",
            "Steven Johnson",
            "Hongfang Liu",
            "Hua Xu",
            "Rui Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T01:02:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000099,
        "doi": null,
        "title": "CancerLLM: A Large Language Model in Cancer Domain",
        "abstract": "Medical Large Language Models (LLMs) such as ClinicalCamel 70B,\nLlama3-OpenBioLLM 70B have demonstrated impressive performance on a wide\nvariety of medical NLP task.However, there still lacks a large language model\n(LLM) specifically designed for cancer domain. Moreover, these LLMs typically\nhave billions of parameters, making them computationally expensive for\nhealthcare systems.Thus, in this study, we propose CancerLLM, a model with 7\nbillion parameters and a Mistral-style architecture, pre-trained on 2,676,642\nclinical notes and 515,524 pathology reports covering 17 cancer types, followed\nby fine-tuning on three cancer-relevant tasks, including cancer phenotypes\nextraction, cancer diagnosis generation, and cancer treatment plan generation.\nOur evaluation demonstrated that CancerLLM achieves state-of-the-art results\ncompared to other existing LLMs, with an average F1 score improvement of 8.1\\%.\nAdditionally, CancerLLM outperforms other models on two proposed robustness\ntestbeds. This illustrates that CancerLLM can be effectively applied to\nclinical AI systems, enhancing clinical research and healthcare delivery in the\nfield of cancer.",
        "chunk-id": 3,
        "chunk": "extraction, cancer diagnosis generation, and cancer treatment plan generation.\nOur evaluation demonstrated that CancerLLM achieves state-of-the-art results\ncompared to other existing LLMs, with an average F1 score improvement of 8.1\\%.\nAdditionally, CancerLLM outperforms other models on two proposed robustness\ntestbeds. This illustrates that CancerLLM can be effectively applied to",
        "authors": [
            "Mingchen Li",
            "Anne Blaes",
            "Steven Johnson",
            "Hongfang Liu",
            "Hua Xu",
            "Rui Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T01:02:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10459v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 20000099,
        "doi": null,
        "title": "CancerLLM: A Large Language Model in Cancer Domain",
        "abstract": "Medical Large Language Models (LLMs) such as ClinicalCamel 70B,\nLlama3-OpenBioLLM 70B have demonstrated impressive performance on a wide\nvariety of medical NLP task.However, there still lacks a large language model\n(LLM) specifically designed for cancer domain. Moreover, these LLMs typically\nhave billions of parameters, making them computationally expensive for\nhealthcare systems.Thus, in this study, we propose CancerLLM, a model with 7\nbillion parameters and a Mistral-style architecture, pre-trained on 2,676,642\nclinical notes and 515,524 pathology reports covering 17 cancer types, followed\nby fine-tuning on three cancer-relevant tasks, including cancer phenotypes\nextraction, cancer diagnosis generation, and cancer treatment plan generation.\nOur evaluation demonstrated that CancerLLM achieves state-of-the-art results\ncompared to other existing LLMs, with an average F1 score improvement of 8.1\\%.\nAdditionally, CancerLLM outperforms other models on two proposed robustness\ntestbeds. This illustrates that CancerLLM can be effectively applied to\nclinical AI systems, enhancing clinical research and healthcare delivery in the\nfield of cancer.",
        "chunk-id": 4,
        "chunk": "clinical AI systems, enhancing clinical research and healthcare delivery in the\nfield of cancer.",
        "authors": [
            "Mingchen Li",
            "Anne Blaes",
            "Steven Johnson",
            "Hongfang Liu",
            "Hua Xu",
            "Rui Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-15T01:02:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.10459v1",
        "arxiv_link": "http://arxiv.org/abs/2406.10459v1",
        "categories": [
            "Computation and Language"
        ]
    }
]