[
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 1,
        "chunk": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 2,
        "chunk": "information loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 3,
        "chunk": "proposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000000,
        "doi": null,
        "title": "SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation",
        "abstract": "Financial market simulation (FMS) serves as a promising tool for\nunderstanding market anomalies and the underlying trading behaviors. To ensure\nhigh-fidelity simulations, it is crucial to calibrate the FMS model for\ngenerating data closely resembling the observed market data. Previous efforts\nprimarily focused on calibrating the mid-price data, leading to essential\ninformation loss of the market activities and thus biasing the calibrated\nmodel. The Limit Order Book (LOB) data is the fundamental data fully capturing\nthe market micro-structure and is adopted by worldwide exchanges. However, LOB\nis not applicable to existing calibration objective functions due to its\ntabular structure not suitable for the vectorized input requirement. This paper\nproposes to explicitly learn the vectorized representations of LOB with a\nTransformer-based autoencoder. Then the latent vector, which captures the major\ninformation of LOB, can be applied for calibration. Extensive experiments show\nthat the learned latent representation not only preserves the non-linear\nauto-correlation in the temporal axis, but the precedence between successive\nprice levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "chunk-id": 4,
        "chunk": "price levels of LOB. Besides, it is verified that the performance of the\nrepresentation learning stage is consistent with the downstream calibration\ntasks. Thus, this work also progresses the FMS on LOB data, for the first time.",
        "authors": [
            "Yuanzhe Li",
            "Yue Wu",
            "Peng Yang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:58+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19396v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19396v1",
        "categories": [
            "Computational Engineering, Finance, and Science"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 1,
        "chunk": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 2,
        "chunk": "address this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000001,
        "doi": null,
        "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
        "abstract": "Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "chunk-id": 3,
        "chunk": "alignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.",
        "authors": [
            "Ankan Bhunia",
            "Changjian Li",
            "Hakan Bilen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19393v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19393v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 1,
        "chunk": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 2,
        "chunk": "relationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 3,
        "chunk": "Our benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000002,
        "doi": null,
        "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
        "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "chunk-id": 4,
        "chunk": "generated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.",
        "authors": [
            "Jr-Jen Chen",
            "Yu-Chien Liao",
            "Hsi-Che Lin",
            "Yu-Chu Yu",
            "Yen-Chun Chen",
            "Yu-Chiang Frank Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:45+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19392v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19392v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 1,
        "chunk": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 2,
        "chunk": "works have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 3,
        "chunk": "often fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 4,
        "chunk": "proximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 5,
        "chunk": "learning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000003,
        "doi": null,
        "title": "Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads",
        "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "chunk-id": 6,
        "chunk": "to standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.",
        "authors": [
            "Ali Khaleghi Rahimian",
            "Manish Kumar Govind",
            "Subhajit Maity",
            "Dominick Reilly",
            "Christian K\u00fcmmerle",
            "Srijan Das",
            "Aritra Dutta"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:40+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19391v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19391v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 1,
        "chunk": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 2,
        "chunk": "subsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000004,
        "doi": null,
        "title": "SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas",
        "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "chunk-id": 3,
        "chunk": "without sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.",
        "authors": [
            "John Lambert",
            "Yuguang Li",
            "Ivaylo Boyadzhiev",
            "Lambert Wixson",
            "Manjunath Narayana",
            "Will Hutchcroft",
            "James Hays",
            "Frank Dellaert",
            "Sing Bing Kang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:59:06+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19390v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19390v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 1,
        "chunk": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 2,
        "chunk": "experiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000005,
        "doi": null,
        "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
        "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "chunk-id": 3,
        "chunk": "features. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
        "authors": [
            "Vedang Lad",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19384v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19384v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 1,
        "chunk": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 2,
        "chunk": "differential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000006,
        "doi": null,
        "title": "A Machine Learning Method for Monte Carlo Calculations of Radiative Processes",
        "abstract": "Radiative processes such as synchrotron radiation and Compton scattering play\nan important role in astrophysics. Radiative processes are fundamentally\nstochastic in nature, and the best tools currently used for resolving these\nprocesses computationally are Monte Carlo (MC) methods. These methods typically\ndraw a large number of samples from a complex distribution such as the\ndifferential cross section for electron-photon scattering, and then use these\nsamples to compute the radiation properties such as angular distribution,\nspectrum, and polarization. In this work we propose a machine learning (ML)\ntechnique for efficient sampling from arbitrary known probability distributions\nthat can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "chunk-id": 3,
        "chunk": "that can be used to accelerate Monte Carlo calculation of radiative processes\nin astrophysical scenarios. In particular, we apply our technique to inverse\nCompton radiation and find that our ML method can be up to an order of\nmagnitude faster than traditional methods currently in use.",
        "authors": [
            "William Charles",
            "Alexander Y. Chen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:57:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19385v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19385v1",
        "categories": [
            "High Energy Astrophysical Phenomena"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 1,
        "chunk": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 2,
        "chunk": "tabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 3,
        "chunk": "feature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 4,
        "chunk": "range of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000007,
        "doi": null,
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "abstract": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "chunk-id": 5,
        "chunk": "datasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
        "authors": [
            "Ivan Rubachev",
            "Nikolay Kartashev",
            "Yury Gorishniy",
            "Artem Babenko"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:55:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19380v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19380v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 1,
        "chunk": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 2,
        "chunk": "Component Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000008,
        "doi": null,
        "title": "Quartic quantum speedups for planted inference",
        "abstract": "We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also\nknown as sparse Learning Parity with Noise) that achieves a nearly quartic\n($4$th power) speedup over the best known classical algorithm while also only\nusing logarithmically many qubits. Our work generalizes and simplifies prior\nwork of Hastings, by building on his quantum algorithm for the Tensor Principal\nComponent Analysis (PCA) problem. We achieve our quantum speedup using a\ngeneral framework based on the Kikuchi Method (recovering the quartic speedup\nfor Tensor PCA), and we anticipate it will yield similar speedups for further\nplanted inference problems. These speedups rely on the fact that planted\ninference problems naturally instantiate the Guided Sparse Hamiltonian problem.\nSince the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "chunk-id": 3,
        "chunk": "Since the Planted Noisy $k$XOR problem has been used as a component of certain\ncryptographic constructions, our work suggests that some of these are\nsusceptible to super-quadratic quantum attacks.",
        "authors": [
            "Alexander Schmidhuber",
            "Ryan O'Donnell",
            "Robin Kothari",
            "Ryan Babbush"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:54:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19378v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19378v1",
        "categories": [
            "Quantum Physics",
            "Computational Complexity",
            "Cryptography and Security"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 1,
        "chunk": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 2,
        "chunk": "manipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 3,
        "chunk": "which a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 4,
        "chunk": "model possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000009,
        "doi": null,
        "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
        "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "chunk-id": 5,
        "chunk": "that emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
        "authors": [
            "Core Francisco Park",
            "Maya Okawa",
            "Andrew Lee",
            "Ekdeep Singh Lubana",
            "Hidenori Tanaka"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:50:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19370v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19370v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 1,
        "chunk": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 2,
        "chunk": "solution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 3,
        "chunk": "the absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 4,
        "chunk": "challenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000010,
        "doi": "10.1109/TIV.2024.3397194",
        "title": "STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning",
        "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "chunk-id": 5,
        "chunk": "a Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.",
        "authors": [
            "Yanan Zhang",
            "Chao Zhou",
            "Di Huang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:43:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19362v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19362v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 1,
        "chunk": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 2,
        "chunk": "crucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 3,
        "chunk": "MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000011,
        "doi": null,
        "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
        "abstract": "High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "chunk-id": 4,
        "chunk": "human evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.",
        "authors": [
            "Nigel Fernandez",
            "Alexander Scarlatos",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:37:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19356v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19356v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 1,
        "chunk": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 2,
        "chunk": "a storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 3,
        "chunk": "problems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 4,
        "chunk": "entailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000012,
        "doi": null,
        "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
        "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "chunk-id": 5,
        "chunk": "a desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
        "authors": [
            "Peter Hase",
            "Thomas Hofweber",
            "Xiang Zhou",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:33:03+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19354v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19354v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 1,
        "chunk": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 2,
        "chunk": "learned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 3,
        "chunk": "process, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000013,
        "doi": null,
        "title": "Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation",
        "abstract": "Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "chunk-id": 4,
        "chunk": "instance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.",
        "authors": [
            "Yushun Tang",
            "Shuoshuo Chen",
            "Zhehan Kan",
            "Yi Zhang",
            "Qinghai Guo",
            "Zhihai He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T17:16:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19341v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19341v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 1,
        "chunk": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 2,
        "chunk": "text-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000014,
        "doi": null,
        "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
        "abstract": "We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "chunk-id": 3,
        "chunk": "rhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.",
        "authors": [
            "Ivan Villa-Renteria",
            "Mason L. Wang",
            "Zachary Shah",
            "Zhe Li",
            "Soohyun Kim",
            "Neelesh Ramachandran",
            "Mert Pilanci"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:59:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19328v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19328v1",
        "categories": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 1,
        "chunk": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 2,
        "chunk": "simulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000015,
        "doi": null,
        "title": "Efficient World Models with Context-Aware Tokenization",
        "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "chunk-id": 3,
        "chunk": "the art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
        "authors": [
            "Vincent Micheli",
            "Eloi Alonso",
            "Fran\u00e7ois Fleuret"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:54:12+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19320v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19320v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 1,
        "chunk": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 2,
        "chunk": "simulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000016,
        "doi": null,
        "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
        "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "chunk-id": 3,
        "chunk": "models. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
        "authors": [
            "Parand A. Alamdari",
            "Yanshuai Cao",
            "Kevin H. Wilson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:52:19+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19317v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19317v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 1,
        "chunk": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 2,
        "chunk": "hard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 3,
        "chunk": "(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 4,
        "chunk": "Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000017,
        "doi": null,
        "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
        "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "chunk-id": 5,
        "chunk": "of tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.",
        "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:47:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19314v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19314v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 1,
        "chunk": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 2,
        "chunk": "climate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 3,
        "chunk": "coordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000018,
        "doi": null,
        "title": "Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors",
        "abstract": "In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "chunk-id": 4,
        "chunk": "ecosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.",
        "authors": [
            "Burak Ekim",
            "Michael Schmitt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19302v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19302v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 1,
        "chunk": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 2,
        "chunk": "reducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 3,
        "chunk": "compression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000019,
        "doi": null,
        "title": "MCNC: Manifold Constrained Network Compression",
        "abstract": "The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "chunk-id": 4,
        "chunk": "compression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.",
        "authors": [
            "Chayne Thrash",
            "Ali Abbasi",
            "Parsa Nooralinejad",
            "Soroush Abbasi Koohpayegani",
            "Reed Andreas",
            "Hamed Pirsiavash",
            "Soheil Kolouri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:17:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19301v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19301v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 1,
        "chunk": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 2,
        "chunk": "of the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000020,
        "doi": null,
        "title": "scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data",
        "abstract": "We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.",
        "chunk-id": 3,
        "chunk": "integrating batch correction directly into the clustering procedure.",
        "authors": [
            "Moritz Vandenhirtz",
            "Florian Barkmann",
            "Laura Manduchi",
            "Julia E. Vogt",
            "Valentina Boeva"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:16:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19300v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19300v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 1,
        "chunk": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 2,
        "chunk": "under the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 3,
        "chunk": "components in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000021,
        "doi": null,
        "title": "Compositional Image Decomposition with Diffusion Models",
        "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "chunk-id": 4,
        "chunk": "flexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.",
        "authors": [
            "Jocelin Su",
            "Nan Liu",
            "Yanbo Wang",
            "Joshua B. Tenenbaum",
            "Yilun Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:13:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19298v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19298v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 1,
        "chunk": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 2,
        "chunk": "demonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000022,
        "doi": null,
        "title": "Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation",
        "abstract": "Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "chunk-id": 3,
        "chunk": "approach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.",
        "authors": [
            "Malvina Nikandrou",
            "Georgios Pantazopoulos",
            "Ioannis Konstas",
            "Alessandro Suglia"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:12:57+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19297v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19297v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 1,
        "chunk": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 2,
        "chunk": "Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 3,
        "chunk": "Turbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000023,
        "doi": null,
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "chunk-id": 4,
        "chunk": "highlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
        "authors": [
            "Zheyang Xiong",
            "Vasilis Papageorgiou",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:05:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19292v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19292v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 1,
        "chunk": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 2,
        "chunk": "application areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000024,
        "doi": null,
        "title": "Human Modelling and Pose Estimation Overview",
        "abstract": "Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "chunk-id": 3,
        "chunk": "algorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.",
        "authors": [
            "Pawel Knap"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T16:04:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19290v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19290v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Scene Analysis"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 1,
        "chunk": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 2,
        "chunk": "PubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 3,
        "chunk": "creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000025,
        "doi": null,
        "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
        "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "chunk-id": 4,
        "chunk": "data quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
        "authors": [
            "Junying Chen",
            "Ruyi Ouyang",
            "Anningzhe Gao",
            "Shunian Chen",
            "Guiming Hardy Chen",
            "Xidong Wang",
            "Ruifei Zhang",
            "Zhenyang Cai",
            "Ke Ji",
            "Guangjun Yu",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:50:41+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19280v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19280v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 1,
        "chunk": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 2,
        "chunk": "Models (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 3,
        "chunk": "training and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000026,
        "doi": null,
        "title": "Stochastic Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "chunk-id": 4,
        "chunk": "setting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.",
        "authors": [
            "Moritz Vandenhirtz",
            "Sonia Laguna",
            "Ri\u010dards Marcinkevi\u010ds",
            "Julia E. Vogt"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:38:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19272v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19272v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 1,
        "chunk": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 2,
        "chunk": "limitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 3,
        "chunk": "Additionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000027,
        "doi": null,
        "title": "Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers",
        "abstract": "While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "chunk-id": 4,
        "chunk": "superiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.",
        "authors": [
            "Jinsong Chen",
            "Hanpeng Liu",
            "John E. Hopcroft",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:29:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19258v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19258v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 1,
        "chunk": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 2,
        "chunk": "frameworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 3,
        "chunk": "data quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000028,
        "doi": null,
        "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
        "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "chunk-id": 4,
        "chunk": "Reusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
        "authors": [
            "Kaveen Hiniduma",
            "Suren Byna",
            "Jean Luca Bez",
            "Ravi Madduri"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:26:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19256v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19256v1",
        "categories": [
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 1,
        "chunk": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 2,
        "chunk": "structural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 3,
        "chunk": "SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 4,
        "chunk": "spatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000029,
        "doi": "10.1109/TPAMI.2024.3393452",
        "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
        "abstract": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "chunk-id": 5,
        "chunk": "On 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.",
        "authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua",
            "Shuicheng Yan"
        ],
        "journal_ref": "[J].IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, 2024",
        "published": "2024-06-27T15:23:36+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19255v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19255v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 1,
        "chunk": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 2,
        "chunk": "significantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 3,
        "chunk": "methods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 4,
        "chunk": "the variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 5,
        "chunk": "groups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000030,
        "doi": null,
        "title": "Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes",
        "abstract": "During software development, poor design and implementation choices can\ndetrimentally impact software maintainability. Design smells, recurring\npatterns of poorly designed fragments, signify these issues. Role-stereotypes\ndenote the generic responsibilities that classes assume in system design.\nAlthough the concepts of role-stereotypes and design smells differ, both\nsignificantly contribute to the design and maintenance of software systems.\nUnderstanding the relationship between these aspects is crucial for enhancing\nsoftware maintainability, code quality, efficient code review, guided\nrefactoring, and the design of role-specific metrics. This paper employs an\nexploratory approach, combining statistical analysis and unsupervised learning\nmethods, to understand how design smells relate to role-stereotypes across\ndesktop and mobile applications. Analyzing 11,350 classes from 30 GitHub\nrepositories, we identified several design smells that frequently co-occur\nwithin certain role-stereotypes. Specifically, three (3) out of six (6)\nrole-stereotypes we studied are more prone to design smells. We also examined\nthe variation of design smells across the two ecosystems, driven by notable\ndifferences in their underlying architecture. Findings revealed that design\nsmells are more prevalent in desktop than in mobile applications, especially\nwithin the Service Provider and Information Holder role-stereotypes.\nAdditionally, the unsupervised learning method showed that certain pairs or\ngroups of role-stereotypes are prone to similar types of design smells. We\nbelieve these relationships are associated with the characteristic and\ncollaborative properties between role-stereotypes. The insights from this\nresearch provide valuable guidance for software teams on implementing design\nsmell prevention and correction mechanisms, ensuring conceptual integrity\nduring design and maintenance phases.",
        "chunk-id": 6,
        "chunk": "during design and maintenance phases.",
        "authors": [
            "Daniel Ogenrwot",
            "Joyce Nakatumba-Nabende",
            "John Businge",
            "Michel R. V. Chaudron"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19254v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19254v1",
        "categories": [
            "Software Engineering",
            "Distribution, Maintenance, and Enhancement; Software Management"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 1,
        "chunk": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 2,
        "chunk": "approaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000031,
        "doi": null,
        "title": "Advection Augmented Convolutional Neural Networks",
        "abstract": "Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "chunk-id": 3,
        "chunk": "compared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.",
        "authors": [
            "Niloufar Zakariaei",
            "Siddharth Rout",
            "Eldad Haber",
            "Moshe Eliasof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:22:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19253v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19253v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 1,
        "chunk": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 2,
        "chunk": "multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 3,
        "chunk": "optimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000032,
        "doi": null,
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
        "chunk-id": 4,
        "chunk": "scenarios. The code will be made available at https://aka.ms/autorag.",
        "authors": [
            "Jia Fu",
            "Xiaoting Qin",
            "Fangkai Yang",
            "Lu Wang",
            "Jue Zhang",
            "Qingwei Lin",
            "Yubo Chen",
            "Dongmei Zhang",
            "Saravan Rajmohan",
            "Qi Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:18:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19251v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19251v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 1,
        "chunk": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 2,
        "chunk": "observe that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 3,
        "chunk": "Transformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 4,
        "chunk": "comprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000033,
        "doi": null,
        "title": "NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification",
        "abstract": "Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "chunk-id": 5,
        "chunk": "different scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.",
        "authors": [
            "Jinsong Chen",
            "Siyu Jiang",
            "Kun He"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:16:00+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19249v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19249v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000034,
        "doi": null,
        "title": "Staggered Quantizers for Perfect Perceptual Quality: A Connection between Quantizers with Common Randomness and Without",
        "abstract": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,\nwe provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "chunk-id": 1,
        "chunk": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,",
        "authors": [
            "Ruida Zhou",
            "Chao Tian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:15:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19248v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19248v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000034,
        "doi": null,
        "title": "Staggered Quantizers for Perfect Perceptual Quality: A Connection between Quantizers with Common Randomness and Without",
        "abstract": "The rate-distortion-perception (RDP) framework has attracted significant\nrecent attention due to its application in neural compression. It is important\nto understand the underlying mechanism connecting procedures with common\nrandomness and those without. Different from previous efforts, we study this\nproblem from a quantizer design perspective. By analyzing an idealized setting,\nwe provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "chunk-id": 2,
        "chunk": "we provide an interpretation of the advantage of dithered quantization in the\nRDP setting, which further allows us to make a conceptual connection between\nrandomized (dithered) quantizers and quantizers without common randomness. This\nnew understanding leads to a new procedure for RDP coding based on staggered\nquantizers.",
        "authors": [
            "Ruida Zhou",
            "Chao Tian"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:15:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19248v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19248v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 1,
        "chunk": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 2,
        "chunk": "methods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 3,
        "chunk": "Image Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 4,
        "chunk": "inter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000035,
        "doi": null,
        "title": "Local Manifold Learning for No-Reference Image Quality Assessment",
        "abstract": "Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "chunk-id": 5,
        "chunk": "state-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).",
        "authors": [
            "Timin Gao",
            "Wensheng Pan",
            "Yan Zhang",
            "Sicheng Zhao",
            "Shengchuan Zhang",
            "Xiawu Zheng",
            "Ke Li",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:14:23+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19247v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19247v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 1,
        "chunk": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 2,
        "chunk": "enhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 3,
        "chunk": "information to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 4,
        "chunk": "inject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000036,
        "doi": "10.1145/3580305.3599390",
        "title": "Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information",
        "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "chunk-id": 5,
        "chunk": "achieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.",
        "authors": [
            "Tianjun Yao",
            "Yiongxu Wang",
            "Kun Zhang",
            "Shangsong Liang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:10:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19244v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19244v1",
        "categories": [
            "Machine Learning",
            "Learning"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 1,
        "chunk": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 2,
        "chunk": "analyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000037,
        "doi": null,
        "title": "Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review",
        "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality\nand maintainability. And Deep Learning (DL) techniques have emerged as a\npromising approach for CSD due to their superior performance. However, the\neffectiveness of DL-based CSD methods heavily relies on the quality of the\ntraining data. Despite its importance, little attention has been paid to\nanalyzing the data preparation process. This systematic literature review\nanalyzes the data preparation techniques used in DL-based CSD methods. We\nidentify 36 relevant papers published by December 2023 and provide a thorough\nanalysis of the critical considerations in constructing CSD datasets, including\ndata requirements, collection, labeling, and cleaning. We also summarize seven\nprimary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "chunk-id": 3,
        "chunk": "primary challenges and corresponding solutions in the literature. Finally, we\noffer actionable recommendations for preparing and accessing high-quality CSD\ndata, emphasizing the importance of data diversity, standardization, and\naccessibility. This survey provides valuable insights for researchers and\npractitioners to harness the full potential of DL techniques in CSD.",
        "authors": [
            "Fengji Zhang",
            "Zexian Zhang",
            "Jacky Wai Keung",
            "Xiangru Tang",
            "Zhen Yang",
            "Xiao Yu",
            "Wenhua Hu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:04:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19240v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19240v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 1,
        "chunk": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 2,
        "chunk": "and there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 3,
        "chunk": "justifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000038,
        "doi": null,
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "abstract": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "chunk-id": 4,
        "chunk": "well as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
        "authors": [
            "Dustin Wright",
            "Arnav Arora",
            "Nadav Borenstein",
            "Srishti Yadav",
            "Serge Belongie",
            "Isabelle Augenstein"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19238v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19238v1",
        "categories": [
            "Computation and Language",
            "Computers and Society",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 1,
        "chunk": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 2,
        "chunk": "human-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000039,
        "doi": null,
        "title": "FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts",
        "abstract": "Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "chunk-id": 3,
        "chunk": "proprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.",
        "authors": [
            "Shubhankar Singh",
            "Purvi Chaurasia",
            "Yerram Varun",
            "Pranshu Pandya",
            "Vatsal Gupta",
            "Vivek Gupta",
            "Dan Roth"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T15:01:48+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19237v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19237v1",
        "categories": [
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Machine Learning"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 1,
        "chunk": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 2,
        "chunk": "systems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 3,
        "chunk": "using only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000040,
        "doi": null,
        "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "chunk-id": 4,
        "chunk": "We then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.",
        "authors": [
            "Yuying Li",
            "Gaoyang Liu",
            "Yang Yang",
            "Chen Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:58:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19234v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19234v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000041,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 1,
        "chunk": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000041,
        "doi": null,
        "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
        "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "chunk-id": 2,
        "chunk": "\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
        "authors": [
            "Jimin Sun",
            "So Yeon Min",
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:52:34+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19228v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19228v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 1,
        "chunk": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 2,
        "chunk": "to lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 3,
        "chunk": "with student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 4,
        "chunk": "finally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 5,
        "chunk": "thoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000042,
        "doi": null,
        "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
        "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in\nvarious tasks. Local deployment of LLMs on edge devices is necessary when\nhandling privacy-sensitive data or latency-sensitive tasks. The computational\nconstraints of such devices make direct deployment of powerful large-scale LLMs\nimpractical, necessitating the Knowledge Distillation from large-scale models\nto lightweight models. Lots of work has been done to elicit diversity and\nquality training examples from LLMs, but little attention has been paid to\naligning teacher instructional content based on student preferences, akin to\n\"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning\nTeacheR with StudenT PreferencEs, a framework that aligns the teacher model\nwith student preferences to generate tailored training examples for Knowledge\nDistillation. Specifically, we elicit draft questions and rationales from the\nteacher model, then collect student preferences on these questions and\nrationales using students' performance with in-context learning as a proxy, and\nfinally align the teacher model with student preferences. In the end, we repeat\nthe first step with the aligned teacher model to elicit tailored training\nexamples for the student model on the target task. Extensive experiments on\nacademic benchmarks demonstrate the superiority of ARTE over existing\ninstruction-tuning datasets distilled from powerful LLMs. Moreover, we\nthoroughly investigate the generalization of ARTE, including the generalization\nof fine-tuned student models in reasoning ability and the generalization of\naligned teacher models to generate tailored training data across tasks and\nstudents. In summary, our contributions lie in proposing a novel framework for\ntailored training example generation, demonstrating its efficacy in\nexperiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "chunk-id": 6,
        "chunk": "experiments, and investigating the generalization of both student & aligned\nteacher models in ARTE.",
        "authors": [
            "Yantao Liu",
            "Zhao Zhang",
            "Zijun Yao",
            "Shulin Cao",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19227v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19227v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 1,
        "chunk": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 2,
        "chunk": "propose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 3,
        "chunk": "educational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000043,
        "doi": null,
        "title": "Simulating Classroom Education with LLM-Empowered Agents",
        "abstract": "Large language models (LLMs) have been employed in various intelligent\neducational tasks to assist teaching. While preliminary explorations have\nfocused on independent LLM-empowered agents for specific educational tasks, the\npotential for LLMs within a multi-agent collaborative framework to simulate a\nclassroom with real user participation remains unexplored. In this work, we\npropose SimClass, a multi-agent classroom simulation framework involving user\nparticipation. We recognize representative class roles and introduce a novel\nclass control mechanism for automatic classroom teaching, and conduct user\nexperiments in two real-world courses. Utilizing the Flanders Interactive\nAnalysis System and Community of Inquiry theoretical frame works from\neducational analysis, we demonstrate that LLMs can simulate traditional\nclassroom interaction patterns effectively while enhancing user's experience.\nWe also observe emergent group behaviors among agents in SimClass, where agents\ncollaborate to create enlivening interactions in classrooms to improve user\nlearning process. We hope this work pioneers the application of LLM-empowered\nmulti-agent systems in virtual classroom teaching.",
        "chunk-id": 4,
        "chunk": "multi-agent systems in virtual classroom teaching.",
        "authors": [
            "Zheyuan Zhang",
            "Daniel Zhang-Li",
            "Jifan Yu",
            "Linlu Gong",
            "Jinchang Zhou",
            "Zhiyuan Liu",
            "Lei Hou",
            "Juanzi Li"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:51:07+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19226v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19226v1",
        "categories": [
            "Computation and Language",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 1,
        "chunk": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 2,
        "chunk": "focus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 3,
        "chunk": "are commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 4,
        "chunk": "However, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000044,
        "doi": null,
        "title": "ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation",
        "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "chunk-id": 5,
        "chunk": "act as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.",
        "authors": [
            "Nazanin Moradinasab",
            "Laura S. Shankman",
            "Rebecca A. Deaton",
            "Gary K. Owens",
            "Donald E. Brown"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:50:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19225v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19225v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 1,
        "chunk": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 2,
        "chunk": "effectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000045,
        "doi": null,
        "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
        "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "chunk-id": 3,
        "chunk": "exhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
        "authors": [
            "Bj\u00f6rn Deiseroth",
            "Manuel Brack",
            "Patrick Schramowski",
            "Kristian Kersting",
            "Samuel Weinbach"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:49:08+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19223v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19223v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 1,
        "chunk": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 2,
        "chunk": "machine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 3,
        "chunk": "databases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000046,
        "doi": null,
        "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
        "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "chunk-id": 4,
        "chunk": "detection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
        "authors": [
            "Sidahmed Benabderrahmane",
            "Ngoc Hoang",
            "Petko Valtchev",
            "James Cheney",
            "Talal Rahwan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:45:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19220v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19220v1",
        "categories": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 1,
        "chunk": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 2,
        "chunk": "suggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 3,
        "chunk": "guarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000047,
        "doi": null,
        "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
        "abstract": "Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "chunk-id": 4,
        "chunk": "synthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.",
        "authors": [
            "Zeqin Yang",
            "Weilin Chen",
            "Ruichu Cai",
            "Yuguang Yan",
            "Zhifeng Hao",
            "Zhipeng Yu",
            "Zhichao Zou",
            "Zhen Peng",
            "Jiecheng Guo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:13:46+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19195v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19195v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 1,
        "chunk": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 2,
        "chunk": "the CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 3,
        "chunk": "(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000048,
        "doi": null,
        "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
        "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "chunk-id": 4,
        "chunk": "low as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
        "authors": [
            "Luca Benfenati",
            "Thorir Mar Ingolfsson",
            "Andrea Cossettini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:09:10+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19189v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19189v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 1,
        "chunk": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 2,
        "chunk": "contrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 3,
        "chunk": "a principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000049,
        "doi": null,
        "title": "Averaging log-likelihoods in direct alignment",
        "abstract": "To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.",
        "chunk-id": 4,
        "chunk": "generations and their scores.",
        "authors": [
            "Nathan Grinsztajn",
            "Yannis Flet-Berliac",
            "Mohammad Gheshlaghi Azar",
            "Florian Strub",
            "Bill Wu",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:07:38+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19188v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19188v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 1,
        "chunk": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 2,
        "chunk": "the preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 3,
        "chunk": "mathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000050,
        "doi": null,
        "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
        "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "chunk-id": 4,
        "chunk": "generalize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.",
        "authors": [
            "Yannis Flet-Berliac",
            "Nathan Grinsztajn",
            "Florian Strub",
            "Eugene Choi",
            "Chris Cremer",
            "Arash Ahmadian",
            "Yash Chandak",
            "Mohammad Gheshlaghi Azar",
            "Olivier Pietquin",
            "Matthieu Geist"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T14:03:49+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19185v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19185v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 1,
        "chunk": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 2,
        "chunk": "inadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 3,
        "chunk": "X-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 4,
        "chunk": "available annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000051,
        "doi": null,
        "title": "Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data",
        "abstract": "In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.",
        "chunk-id": 5,
        "chunk": "budget in applied machine learning projects.",
        "authors": [
            "Lukas Malte Kemeter",
            "Rasmus Hvingelby",
            "Paulina Sierak",
            "Tobias Sch\u00f6n",
            "Bishwajit Gosswam"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:51:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19175v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19175v1",
        "categories": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 1,
        "chunk": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 2,
        "chunk": "possibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000052,
        "doi": null,
        "title": "Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)",
        "abstract": "The farming domain has seen a tremendous shift towards digital solutions.\nHowever, capturing farmers' requirements regarding Digital Farming (DF)\ntechnology remains a difficult task due to domain-specific challenges. Farmers\nform a diverse and international crowd of practitioners who use a common pool\nof agricultural products and services, which means we can consider the\npossibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF:\nCrowdRE4DF. We found that online user feedback in this domain is limited,\nnecessitating a way of capturing user feedback from farmers in situ. Our\nsolution, the Farmers' Voice application, uses speech-to-text, Machine Learning\n(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "chunk-id": 3,
        "chunk": "(ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed\ngood technology acceptance, and accurate transcription and ML analysis even in\nnoisy farm settings. Our findings help to drive the development of DF\ntechnology through in-situ requirements elicitation.",
        "authors": [
            "Eduard C. Groen",
            "Kazi Rezoanur Rahman",
            "Nikita Narsinghani",
            "Joerg Doerr"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:45:21+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19171v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19171v1",
        "categories": [
            "Software Engineering"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 1,
        "chunk": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 2,
        "chunk": "measurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000053,
        "doi": "10.1088/0256-307X/41/7/070302",
        "title": "Quantum voting machine encoded with microwave photons",
        "abstract": "We propose a simple quantum voting machine using microwave photon qubit\nencoding, based on a setup comprising multiple microwave cavities and a coupled\nsuperconducting flux qutrit. This approach primarily relies on a multi-control\nsingle-target quantum phase gate. The scheme offers operational simplicity,\nrequiring only a single step, while ensuring verifiability through the\nmeasurement of a single qubit phase information to obtain the voting results.\nAnd it provides voter anonymity, as the voting outcome is solely tied to the\ntotal number of affirmative votes. Our quantum voting machine also has\nscalability in terms of the number of voters. Additionally, the physical\nrealization of the quantum voting machine is general and not limited to circuit\nQED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "chunk-id": 3,
        "chunk": "QED. Quantum voting machine can be implemented as long as the multi-control\nsingle-phase quantum phase gate is realized in other physical systems.\nNumerical simulations indicate the feasibility of this quantum voting machine\nwithin the current quantum technology.",
        "authors": [
            "Yu Zhang",
            "Chuiping Yang",
            "Qiping Su",
            "Yihao Kang",
            "Wen Zheng",
            "Shaoxiong Li",
            "Yang Yu"
        ],
        "journal_ref": "Chin. Phys. Lett. 41 070302 (2024)",
        "published": "2024-06-27T13:40:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19167v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19167v1",
        "categories": [
            "Quantum Physics",
            "Applications to specific physical systems"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 1,
        "chunk": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 2,
        "chunk": "triple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 3,
        "chunk": "causal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000054,
        "doi": null,
        "title": "Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction",
        "abstract": "The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "chunk-id": 4,
        "chunk": "experiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.",
        "authors": [
            "Kexin Zhang",
            "Feng Huang",
            "Luotao Liu",
            "Zhankun Xiong",
            "Hongyu Zhang",
            "Yuan Quan",
            "Wen Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:17:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19156v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19156v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 1,
        "chunk": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 2,
        "chunk": "network (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000055,
        "doi": null,
        "title": "Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)",
        "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "chunk-id": 3,
        "chunk": "Monitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.",
        "authors": [
            "Shengjuan Cai",
            "Fangxin Fang",
            "Vincent-Henri Peuch",
            "Mihai Alexe",
            "Ionel Michael Navon",
            "Yanghua Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:14:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19154v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19154v1",
        "categories": [
            "Machine Learning",
            "Atmospheric and Oceanic Physics"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 1,
        "chunk": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 2,
        "chunk": "by the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 3,
        "chunk": "the need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000056,
        "doi": null,
        "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
        "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "chunk-id": 4,
        "chunk": "to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
        "authors": [
            "Varun Nagaraj Rao",
            "Siddharth Choudhary",
            "Aditya Deshpande",
            "Ravi Kumar Satzoda",
            "Srikar Appalaraju"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:08:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19150v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19150v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 1,
        "chunk": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 2,
        "chunk": "and the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 3,
        "chunk": "sector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000057,
        "doi": null,
        "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
        "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "chunk-id": 4,
        "chunk": "out-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
        "authors": [
            "Kit Mills Bransby",
            "Arian Beqiri",
            "Woo-Jin Cho Kim",
            "Jorge Oliveira",
            "Agisilaos Chartsias",
            "Alberto Gomez"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:06:47+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19148v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19148v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 1,
        "chunk": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 2,
        "chunk": "cost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000058,
        "doi": null,
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models",
        "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "chunk-id": 3,
        "chunk": "learning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.",
        "authors": [
            "Tomer Porian",
            "Mitchell Wortsman",
            "Jenia Jitsev",
            "Ludwig Schmidt",
            "Yair Carmon"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T13:02:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19146v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19146v1",
        "categories": [
            "Machine Learning",
            "Computation and Language"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 1,
        "chunk": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 2,
        "chunk": "on Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 3,
        "chunk": "enhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 4,
        "chunk": "and 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000059,
        "doi": null,
        "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
        "abstract": "The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "chunk-id": 5,
        "chunk": "future. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.",
        "authors": [
            "Chenxu Wang",
            "Haowei Ming",
            "Jian He",
            "Yao Lu"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:40:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19136v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19136v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 1,
        "chunk": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 2,
        "chunk": "clinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 3,
        "chunk": "supervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000060,
        "doi": null,
        "title": "Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis",
        "abstract": "Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "chunk-id": 4,
        "chunk": "mitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.",
        "authors": [
            "Yibo Gao",
            "Zheyao Gao",
            "Xin Gao",
            "Yuanye Liu",
            "Bomin Wang",
            "Xiahai Zhuang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:29:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19130v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19130v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 1,
        "chunk": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 2,
        "chunk": "progressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 3,
        "chunk": "language models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000061,
        "doi": null,
        "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
        "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "chunk-id": 4,
        "chunk": "validate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
        "authors": [
            "Giacomo Camposampiero",
            "Michael Hersche",
            "Aleksandar Terzi\u0107",
            "Roger Wattenhofer",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T12:05:55+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19121v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19121v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Symbolic Computation"
        ]
    },
    {
        "id": 10000062,
        "doi": null,
        "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
        "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "chunk-id": 1,
        "chunk": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information",
        "authors": [
            "Hsuvas Borkakoty",
            "Luis Espinosa-Anke"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:53:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19116v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19116v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000062,
        "doi": null,
        "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
        "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "chunk-id": 2,
        "chunk": "available, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
        "authors": [
            "Hsuvas Borkakoty",
            "Luis Espinosa-Anke"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:53:15+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19116v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19116v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 1,
        "chunk": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 2,
        "chunk": "suggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000063,
        "doi": null,
        "title": "A Teacher Is Worth A Million Instructions",
        "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "chunk-id": 3,
        "chunk": "domain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
        "authors": [
            "Nikhil Kothari",
            "Ravindra Nayak",
            "Shreyas Shetty",
            "Amey Patil",
            "Nikesh Garera"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:48:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19112v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19112v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 1,
        "chunk": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 2,
        "chunk": "dynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 3,
        "chunk": "programming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000064,
        "doi": null,
        "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
        "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "chunk-id": 4,
        "chunk": "and without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Jyrki Alakuijala",
            "James Evans",
            "Ben Laurie",
            "Alexander Mordvintsev",
            "Eyvind Niklasson",
            "Ettore Randazzo",
            "Luca Versari"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19108v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19108v1",
        "categories": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Nonnumerical Algorithms and Problems; Distributed Artificial Intelligence"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 1,
        "chunk": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 2,
        "chunk": "functions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000065,
        "doi": null,
        "title": "FDLite: A Single Stage Lightweight Face Detector Network",
        "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "chunk-id": 3,
        "chunk": "independent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.",
        "authors": [
            "Yogesh Aggarwal",
            "Prithwijit Guha"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:34:27+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19107v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19107v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 1,
        "chunk": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 2,
        "chunk": "in the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000066,
        "doi": null,
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "chunk-id": 3,
        "chunk": "Statement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
        "authors": [
            "Lokesh Mishra",
            "Sohayl Dhibi",
            "Yusik Kim",
            "Cesar Berrospi Ramis",
            "Shubham Gupta",
            "Michele Dolfi",
            "Peter Staar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19102v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19102v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 1,
        "chunk": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 2,
        "chunk": "theoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000067,
        "doi": null,
        "title": "Double Mpemba effect in the cooling of trapped colloids",
        "abstract": "The Mpemba effect describes the phenomenon that a system at a hot initial\ntemperature cools faster than at an initial warm temperature in the same\nenvironment. Such an anomalous cooling has recently been predicted and realized\nfor trapped colloids. Here, we investigate the freezing behavior of a passive\ncolloidal particle by employing numerical Brownian dynamics simulations and\ntheoretical calculations with a model that can be directly tested in\nexperiments. During the cooling process, the colloidal particle exhibits\nmultiple non-monotonic regimes in cooling rates, with the cooling time\ndecreasing twice as a function of the initial temperature-an unexpected\nphenomenon we refer to as the Double Mpemba effect. Additionally, we\ndemonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "chunk-id": 3,
        "chunk": "demonstrate that both the Mpemba and Double Mpemba effects can be predicted by\nvarious machine learning methods, which expedite the analysis of complex,\ncomputationally intensive systems.",
        "authors": [
            "Isha Malhotra",
            "Hartmut L\u00f6wen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:26:54+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19098v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19098v1",
        "categories": [
            "Soft Condensed Matter"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 1,
        "chunk": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 2,
        "chunk": "running average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 3,
        "chunk": "Adaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000068,
        "doi": null,
        "title": "Adaptive Stochastic Weight Averaging",
        "abstract": "Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "chunk-id": 4,
        "chunk": "running model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets",
        "authors": [
            "Caglar Demir",
            "Arnab Sharma",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:17:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19092v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19092v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 1,
        "chunk": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 2,
        "chunk": "comparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000069,
        "doi": null,
        "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
        "abstract": "Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "chunk-id": 3,
        "chunk": "in-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.",
        "authors": [
            "Florian P. Mahner",
            "Lukas Muttenthaler",
            "Umut G\u00fc\u00e7l\u00fc",
            "Martin N. Hebart"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:14:14+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19087v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19087v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 1,
        "chunk": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 2,
        "chunk": "covariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 3,
        "chunk": "models not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000070,
        "doi": null,
        "title": "Gratia: An R package for exploring generalized additive models",
        "abstract": "Generalized additive models (GAMs, Hastie & Tibshirani, 1990; Wood, 2017) are\nan extension of the generalized linear model that allows the effects of\ncovariates to be modelled as smooth functions. GAMs are increasingly used in\nmany areas of science (e.g. Pedersen, Miller, Simpson, & Ross, 2019; Simpson,\n2018) because the smooth functions allow nonlinear relationships between\ncovariates and the response to be learned from the data through the use of\npenalized splines. Within the R (R Core Team, 2024) ecosystem, Simon Wood's\nmgcv package (Wood, 2017) is widely used to fit GAMs and is a Recommended\npackage that ships with R as part of the default install. A growing number of\nother R packages build upon mgcv, for example as an engine to fit specialised\nmodels not handled by mgcv itself (e.g. GJMR, Marra & Radice, 2023), or to make\nuse of the wide range of splines available in mgcv (e.g. brms, B\\\"urkner,\n2017).\n  The gratia package builds upon mgcv by providing functions that make working\nwith GAMs easier. gratia takes a tidy approach (Wickham, 2014) providing\nggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "chunk-id": 4,
        "chunk": "ggplot2 (Wickham, 2016) replacements for mgcv's base graphics-based plots,\nfunctions for model diagnostics and exploration of fitted models, and a family\nof functions for drawing samples from the posterior distribution of a fitted\nGAM. Additional functionality is provided to facilitate the teaching and\nunderstanding of GAMs.",
        "authors": [
            "Gavin L. Simpson"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19082v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19082v1",
        "categories": [
            "Computation",
            "Methodology"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 1,
        "chunk": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 2,
        "chunk": "data, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 3,
        "chunk": "target images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000071,
        "doi": null,
        "title": "Unsupervised Latent Stain Adaption for Digital Pathology",
        "abstract": "In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "chunk-id": 4,
        "chunk": "extensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.",
        "authors": [
            "Daniel Reisenb\u00fcchler",
            "Lucas Luttner",
            "Nadine S. Schaadt",
            "Friedrich Feuerhake",
            "Dorit Merhof"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:08:42+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19081v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19081v1",
        "categories": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 1,
        "chunk": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 2,
        "chunk": "Generation (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 3,
        "chunk": "equipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 4,
        "chunk": "numerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000072,
        "doi": null,
        "title": "Distributed MIMO Networks with Rotary ULAs for Indoor Scenarios under Rician Fading",
        "abstract": "The Fifth-Generation (5G) wireless communications networks introduced native\nsupport for Machine-Type Communications (MTC) use cases. Nevertheless, current\n5G networks cannot fully meet the very stringent requirements regarding\nlatency, reliability, and number of connected devices of most MTC use cases.\nIndustry and academia have been working on the evolution from 5G to Sixth\nGeneration (6G) networks. One of the main novelties is adopting Distributed\nMultiple-Input Multiple-Output (D-MIMO) networks. However, most works studying\nD-MIMO consider antenna arrays with no movement capabilities, even though some\nrecent works have shown that this could bring substantial performance\nimprovements. In this work, we propose the utilization of Access Points (APs)\nequipped with Rotary Uniform Linear Arrays (RULAs) for this purpose.\nConsidering a spatially correlated Rician fading model, the optimal angular\nposition of the RULAs is jointly computed by the central processing unit using\nparticle swarm optimization as a function of the position of the active\ndevices. Considering the impact of imperfect positioning estimates, our\nnumerical results show that the RULAs's optimal rotation brings substantial\nperformance gains in terms of mean per-user spectral efficiency. The\nimprovement grows with the strength of the line-of-sight components of the\nchannel vectors. Given the total number of antenna elements, we study the\ntrade-off between the number of APs and the number of antenna elements per AP,\nrevealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "chunk-id": 5,
        "chunk": "revealing an optimal number of APs for the cases of APs equipped with static\nULAs and RULAs.",
        "authors": [
            "Eduardo Noboro Tominaga",
            "Onel Luis Alcaraz L\u00f3pez",
            "Tommy Svensson",
            "Richard Demo Souza",
            "Hirley Alves"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T11:06:37+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19078v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19078v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 1,
        "chunk": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 2,
        "chunk": "Poisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 3,
        "chunk": "future unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000073,
        "doi": null,
        "title": "Refinable modeling for unbinned SMEFT analyses",
        "abstract": "We present techniques for estimating the effects of systematic uncertainties\nin unbinned data analyses at the LHC. Our primary focus is constraining the\nWilson coefficients in the standard model effective field theory (SMEFT), but\nthe methodology applies to broader parametric models of phenomena beyond the\nstandard model (BSM). We elevate the well-established procedures for binned\nPoisson counting experiments to the unbinned case by utilizing machine-learned\nsurrogates of the likelihood ratio. This approach can be applied to various\ntheoretical, modeling, and experimental uncertainties. By establishing a common\nstatistical framework for BSM and systematic effects, we lay the groundwork for\nfuture unbinned analyses at the LHC. Additionally, we introduce a novel\ntree-boosting algorithm capable of learning highly accurate parameterizations\nof systematic effects. This algorithm extends the existing toolkit with a\nversatile and robust alternative. We demonstrate our approach using the example\nof an SMEFT interpretation of highly energetic top quark pair production in\nproton-proton collisions.",
        "chunk-id": 4,
        "chunk": "proton-proton collisions.",
        "authors": [
            "Robert Sch\u00f6fbeck"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:47:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19076v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19076v1",
        "categories": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 1,
        "chunk": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 2,
        "chunk": "complex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000074,
        "doi": null,
        "title": "Scatterer Recognition from LiDAR Point Clouds for Environment-Embedded Vehicular Channel Modeling via Synesthesia of Machines",
        "abstract": "In this paper, a novel environment-embedded vehicular channel model is\nproposed by scatterer recognition from light detection and ranging (LiDAR)\npoint clouds via Synesthesia of Machines (SoM). To provide a robust data\nfoundation, a new intelligent sensing-communication integration dataset in\nvehicular urban scenarios is constructed. Based on the constructed dataset, the\ncomplex SoM mechanism, i.e., mapping relationship between scatterers in\nelectromagnetic space and LiDAR point clouds in physical environment, is\nexplored via multilayer perceptron (MLP) with electromagnetic propagation\nmechanism. By using LiDAR point clouds to implement scatterer recognition,\nchannel non-stationarity and consistency are modeled in an environment-embedded\nmanner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "chunk-id": 3,
        "chunk": "manner. Using ray-tracing (RT)-based results as the ground truth, the scatterer\nrecognition accuracy exceeds 90%. The accuracy of the proposed model is further\nverified by the close fit between simulation results and RT results.",
        "authors": [
            "Ziwei Huang",
            "Lu Bai",
            "Zengrui Han",
            "Xiang Cheng"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:51+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19072v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19072v1",
        "categories": [
            "Signal Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 1,
        "chunk": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 2,
        "chunk": "generalization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000075,
        "doi": null,
        "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
        "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "chunk-id": 3,
        "chunk": "dataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.",
        "authors": [
            "Ondrej Sotolar"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:41:22+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19071v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19071v1",
        "categories": [
            "Computation and Language",
            "Artificial Intelligence",
            "Natural Language Processing"
        ]
    },
    {
        "id": 10000076,
        "doi": null,
        "title": "Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers",
        "abstract": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier\nhighlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "chunk-id": 1,
        "chunk": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier",
        "authors": [
            "Ainhize Barrainkua",
            "Paula Gordaliza",
            "Jose A. Lozano",
            "Novi Quadrianto"
        ],
        "journal_ref": "Presented at the XI Symposium of Theory and Applications of Data\n  Mining from the XX Conference of the Spanish Association for Artificial\n  Intelligence CAEPIA 2024",
        "published": "2024-06-27T10:34:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19066v1",
        "categories": [
            "Machine Learning",
            "Computers and Society",
            "Artificial intelligence, Reasoning under uncertainty",
            "General; Artificial Intelligence "
        ]
    },
    {
        "id": 10000076,
        "doi": null,
        "title": "Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers",
        "abstract": "This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier\nhighlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "chunk-id": 2,
        "chunk": "highlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.",
        "authors": [
            "Ainhize Barrainkua",
            "Paula Gordaliza",
            "Jose A. Lozano",
            "Novi Quadrianto"
        ],
        "journal_ref": "Presented at the XI Symposium of Theory and Applications of Data\n  Mining from the XX Conference of the Spanish Association for Artificial\n  Intelligence CAEPIA 2024",
        "published": "2024-06-27T10:34:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19066v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19066v1",
        "categories": [
            "Machine Learning",
            "Computers and Society",
            "Artificial intelligence, Reasoning under uncertainty",
            "General; Artificial Intelligence "
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 1,
        "chunk": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 2,
        "chunk": "knowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 3,
        "chunk": "over 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000077,
        "doi": null,
        "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
        "abstract": "The rapid evolution of large language models (LLMs) holds promise for\nreforming the methodology of spatio-temporal data mining. However, current\nworks for evaluating the spatio-temporal understanding capability of LLMs are\nsomewhat limited and biased. These works either fail to incorporate the latest\nlanguage models or only focus on assessing the memorized spatio-temporal\nknowledge. To address this gap, this paper dissects LLMs' capability of\nspatio-temporal data into four distinct dimensions: knowledge comprehension,\nspatio-temporal reasoning, accurate computation, and downstream applications.\nWe curate several natural language question-answer tasks for each category and\nbuild the benchmark dataset, namely STBench, containing 13 distinct tasks and\nover 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,\nsuch as GPT-4o, Gemma and Mistral. Experimental results reveal that existing\nLLMs show remarkable performance on knowledge comprehension and spatio-temporal\nreasoning tasks, with potential for further enhancement on other tasks through\nin-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "chunk-id": 4,
        "chunk": "in-context learning, chain-of-though prompting, and fine-tuning. The code and\ndatasets of STBench are released on https://github.com/LwbXc/STBench.",
        "authors": [
            "Wenbin Li",
            "Di Yao",
            "Ruibo Zhao",
            "Wenjie Chen",
            "Zijie Xu",
            "Chengxue Luo",
            "Chang Gong",
            "Quanliang Jing",
            "Haining Tan",
            "Jingping Bi"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:34:02+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19065v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19065v1",
        "categories": [
            "Computation and Language"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 1,
        "chunk": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 2,
        "chunk": "This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 3,
        "chunk": "Gaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 4,
        "chunk": "leads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 5,
        "chunk": "evolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000078,
        "doi": null,
        "title": "Entrywise dynamics and universality of general first order methods",
        "abstract": "General first order methods (GFOMs), including various gradient descent and\nAMP algorithms, constitute a broad class of iterative algorithms in modern\nstatistical learning problems. Some GFOMs also serve as constructive proof\ndevices, iteratively characterizing the empirical distributions of statistical\nestimators in the large system limits for any fixed number of iterations.\n  This paper develops a non-asymptotic, entrywise characterization for a\ngeneral class of GFOMs. Our characterizations capture the precise entrywise\nbehavior of the GFOMs, and hold universally across a broad class of\nheterogeneous random matrix models. As a corollary, we provide the first\nnon-asymptotic description of the empirical distributions of the GFOMs beyond\nGaussian ensembles.\n  We demonstrate the utility of these general results in two applications. In\nthe first application, we prove entrywise universality for regularized least\nsquares estimators in the linear model, by controlling the entrywise error\nrelative to a suitably constructed GFOM. This algorithmic proof method also\nleads to systematically improved averaged universality results for regularized\nregression estimators in the linear model, and resolves the universality\nconjecture for (regularized) MLEs in logistic regression. In the second\napplication, we obtain entrywise Gaussian approximations for a class of\ngradient descent algorithms. Our approach provides non-asymptotic state\nevolution for the bias and variance of the algorithm along the iteration path,\napplicable for non-convex loss functions.\n  The proof relies on a new recursive leave-k-out method that provides almost\ndelocalization for the GFOMs and their derivatives. Crucially, our method\nensures entrywise universality for up to poly-logarithmic many iterations,\nwhich facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "chunk-id": 6,
        "chunk": "which facilitates effective $\\ell_2/\\ell_\\infty$ control between certain GFOMs\nand statistical estimators in applications.",
        "authors": [
            "Qiyang Han"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:28:50+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19061v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19061v1",
        "categories": [
            "Statistics Theory",
            "Information Theory",
            "Information Theory",
            "Statistics Theory"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 1,
        "chunk": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 2,
        "chunk": "segmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 3,
        "chunk": "owing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 4,
        "chunk": "reveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000079,
        "doi": null,
        "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
        "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "chunk-id": 5,
        "chunk": "improving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.",
        "authors": [
            "Fuseini Mumuni",
            "Alhassan Mumuni"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:08:29+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19057v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19057v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 1,
        "chunk": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 2,
        "chunk": "of end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000080,
        "doi": null,
        "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
        "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "chunk-id": 3,
        "chunk": "with semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Thiago Gouv\u00eaa"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T10:01:56+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19054v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19054v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 1,
        "chunk": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 2,
        "chunk": "access to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 3,
        "chunk": "approximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000081,
        "doi": null,
        "title": "Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers",
        "abstract": "Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "chunk-id": 4,
        "chunk": "with continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.",
        "authors": [
            "Paul Fearnhead",
            "Sebastiano Grazzi",
            "Chris Nemeth",
            "Gareth O. Roberts"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:59:28+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19051v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19051v1",
        "categories": [
            "Machine Learning",
            "Machine Learning",
            "Computation",
            "Bayesian inference"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 1,
        "chunk": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 2,
        "chunk": "deployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 3,
        "chunk": "iterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 4,
        "chunk": "performance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000082,
        "doi": null,
        "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "chunk-id": 5,
        "chunk": "client model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
        "authors": [
            "Alexander Herzog",
            "Robbie Southam",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:58:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19050v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19050v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 1,
        "chunk": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 2,
        "chunk": "presence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 3,
        "chunk": "a large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000083,
        "doi": null,
        "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
        "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
        "chunk-id": 4,
        "chunk": "both synthetic and real datasets with noisy data and nuisance features.",
        "authors": [
            "Amartya Sanyal",
            "Yaxi Hu",
            "Yaodong Yu",
            "Yian Ma",
            "Yixin Wang",
            "Bernhard Sch\u00f6lkopf"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:57:31+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19049v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19049v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 1,
        "chunk": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 2,
        "chunk": "required to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 3,
        "chunk": "CMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 4,
        "chunk": "knowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000084,
        "doi": null,
        "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
        "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.",
        "chunk-id": 5,
        "chunk": "usage, advanced method development, and fair performance evaluation.",
        "authors": [
            "Zi Wang",
            "Fanwen Wang",
            "Chen Qin",
            "Jun Lyu",
            "Ouyang Cheng",
            "Shuo Wang",
            "Yan Li",
            "Mengyao Yu",
            "Haoyu Zhang",
            "Kunyuan Guo",
            "Zhang Shi",
            "Qirong Li",
            "Ziqiang Xu",
            "Yajing Zhang",
            "Hao Li",
            "Sha Hua",
            "Binghua Chen",
            "Longyu Sun",
            "Mengting Sun",
            "Qin Li",
            "Ying-Hua Chu",
            "Wenjia Bai",
            "Jing Qin",
            "Xiahai Zhuang",
            "Claudia Prieto",
            "Alistair Young",
            "Michael Markl",
            "He Wang",
            "Lianming Wu",
            "Guang Yang",
            "Xiaobo Qu",
            "Chengyan Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:50:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19043v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19043v1",
        "categories": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Databases"
        ]
    },
    {
        "id": 10000085,
        "doi": null,
        "title": "On Convex Optimization with Semi-Sensitive Features",
        "abstract": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically\nin terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "chunk-id": 1,
        "chunk": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically",
        "authors": [
            "Badih Ghazi",
            "Pritish Kamath",
            "Ravi Kumar",
            "Pasin Manurangsi",
            "Raghu Meka",
            "Chiyuan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:45:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19040v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19040v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 10000085,
        "doi": null,
        "title": "On Convex Optimization with Semi-Sensitive Features",
        "abstract": "We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically\nin terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "chunk-id": 2,
        "chunk": "in terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).",
        "authors": [
            "Badih Ghazi",
            "Pritish Kamath",
            "Ravi Kumar",
            "Pasin Manurangsi",
            "Raghu Meka",
            "Chiyuan Zhang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:45:52+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19040v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19040v1",
        "categories": [
            "Machine Learning",
            "Cryptography and Security",
            "Data Structures and Algorithms"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 1,
        "chunk": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 2,
        "chunk": "initiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 3,
        "chunk": "graph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000086,
        "doi": null,
        "title": "Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia",
        "abstract": "Graph-based models have become pivotal in understanding and predicting\nnavigational patterns within complex networks. Building on graph-based models,\nthe paper advances path extrapolation methods to efficiently predict Wikipedia\nnavigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from\nWikipedia, with a spotlight on the Central Macedonia region, Greece, to\ninitiate path generation. To build WCM, a crawling process is used that\nsimulates human navigation through Wikipedia. Experimentation shows that an\nextension of the graph neural network GRETEL, which resorts to dual hypergraph\ntransformation, performs better on a dense graph of WCM than on a sparse graph\nof WCM. Moreover, combining hypergraph features with features extracted from\ngraph edges has proven to enhance the model's effectiveness. A superior model's\nperformance is reported on the WCM dense graph than on the larger Wikispeedia\ndataset, suggesting that size may not be as influential in predictive accuracy\nas the quality of connections and feature extraction. The paper fits the track\nKnowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "chunk-id": 4,
        "chunk": "Knowledge Discovery and Machine Learning of the 16th International Conference\non Advances in Databases, Knowledge, and Data Applications.",
        "authors": [
            "Martha Sotiroudi",
            "Anastasia-Sotiria Toufa",
            "Constantine Kotropoulos"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:43:53+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19039v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19039v1",
        "categories": [
            "Databases"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 1,
        "chunk": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 2,
        "chunk": "often overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 3,
        "chunk": "generation, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 4,
        "chunk": "property and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000087,
        "doi": null,
        "title": "Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model",
        "abstract": "Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "chunk-id": 5,
        "chunk": "substantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.",
        "authors": [
            "Jiangtong Tan",
            "Feng Zhao"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:33:24+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19030v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19030v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 1,
        "chunk": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 2,
        "chunk": "developed a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 3,
        "chunk": "labelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 4,
        "chunk": "RankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000088,
        "doi": null,
        "title": "Efficient course recommendations with T5-based ranking and summarization",
        "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a\ncourse recommender system that ranks courses for skill-occupation pairs. The\nin-production recommender system BrightFit provides course recommendations from\nmultiple sources. Some of the course descriptions are long and noisy, while\nretrieval and ranking in an online system have to be highly efficient. We\ndeveloped a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as\nre-ranker. We compare two summarizers for course descriptions: a LongT5 model\nthat we finetuned for the task, and a generative LLM (Vicuna) with in-context\nlearning. We experiment with quantization to reduce the size of the ranking\nmodel and increase inference speed. We evaluate our rankers on two newly\nlabelled datasets, with an A/B test, and with a user questionnaire. On the two\nlabelled datasets, our proposed two-stage ranking with automatic summarization\nachieves a substantial improvement over the in-production (BM25) ranker:\nnDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two\ndatasets. We also achieve a 40% speed-up by using a quantized version of\nRankT5. The improved quality of the ranking was confirmed by the questionnaire\ncompleted by 29 respondents, but not by the A/B test. In the A/B test, a higher\nclickthrough rate was observed for the BM25-ranking than for the proposed\ntwo-stage retrieval. We conclude that T5-based re-ranking and summarization for\nonline course recommendation can obtain much better effectiveness than\nsingle-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "chunk-id": 5,
        "chunk": "single-step lexical retrieval, and that quantization has a large effect on\nRankT5. In the online evaluation, however, other factors than relevance play a\nrole (such as speed and interpretability of the retrieval results), as well as\nindividual preferences.",
        "authors": [
            "Thijmen Bijl",
            "Niels van Weeren",
            "Suzan Verberne"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:07:32+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19018v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19018v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 1,
        "chunk": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 2,
        "chunk": "with eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 3,
        "chunk": "that often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000089,
        "doi": null,
        "title": "Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes",
        "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
        "chunk-id": 4,
        "chunk": "the large data set upon completion of the review of this article.",
        "authors": [
            "Joachim Schaeffer",
            "Eric Lenz",
            "Duncan Gulla",
            "Martin Z. Bazant",
            "Richard D. Braatz",
            "Rolf Findeisen"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T09:00:05+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19015v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19015v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control",
            "Systems and Control",
            "Applications"
        ]
    },
    {
        "id": 10000090,
        "doi": null,
        "title": "Coded Cooperative Networks for Semi-Decentralized Federated Learning",
        "abstract": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless\ndiversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "chunk-id": 1,
        "chunk": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless",
        "authors": [
            "Shudi Weng",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19002v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000090,
        "doi": null,
        "title": "Coded Cooperative Networks for Semi-Decentralized Federated Learning",
        "abstract": "To enhance straggler resilience in federated learning (FL) systems, a\nsemi-decentralized approach has been recently proposed, enabling collaboration\nbetween clients. Unlike the existing semi-decentralized schemes, which\nadaptively adjust the collaboration weight according to the network topology,\nthis letter proposes a deterministic coded network that leverages wireless\ndiversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "chunk-id": 2,
        "chunk": "diversity for semi-decentralized FL without requiring prior information about\nthe entire network. Furthermore, the theoretical analyses of the outage and the\nconvergence rate of the proposed scheme are provided. Finally, the superiority\nof our proposed method over benchmark methods is demonstrated through\ncomprehensive simulations.",
        "authors": [
            "Shudi Weng",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:42:13+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.19002v1",
        "arxiv_link": "http://arxiv.org/abs/2406.19002v1",
        "categories": [
            "Information Theory",
            "Information Theory"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 1,
        "chunk": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 2,
        "chunk": "techniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 3,
        "chunk": "low task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000091,
        "doi": null,
        "title": "Zero-shot domain adaptation based on dual-level mix and contrast",
        "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "chunk-id": 4,
        "chunk": "method that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.",
        "authors": [
            "Yu Zhe",
            "Jun Sakuma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:37:26+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18996v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18996v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 1,
        "chunk": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 2,
        "chunk": "constrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 3,
        "chunk": "such a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 4,
        "chunk": "supplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000092,
        "doi": null,
        "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
        "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "chunk-id": 5,
        "chunk": "label learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
        "authors": [
            "Zhaobin Sun",
            "Nannan Wu",
            "Junjie Shi",
            "Li Yu",
            "Xin Yang",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:36:43+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18995v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18995v1",
        "categories": [
            "Machine Learning",
            "Artificial Intelligence"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 1,
        "chunk": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 2,
        "chunk": "typically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 3,
        "chunk": "(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000093,
        "doi": null,
        "title": "Semi-supervised Concept Bottleneck Models",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "chunk-id": 4,
        "chunk": "pseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.",
        "authors": [
            "Lijie Hu",
            "Tianhao Huang",
            "Huanyi Xie",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Lu Yu",
            "Di Wang"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:33:35+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18992v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18992v1",
        "categories": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 1,
        "chunk": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 2,
        "chunk": "the Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000094,
        "doi": null,
        "title": "A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis",
        "abstract": "A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "chunk-id": 3,
        "chunk": "not toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.",
        "authors": [
            "Alejandro Rib\u00e9s",
            "Nawfal Benchekroun",
            "Th\u00e9o Delagnes"
        ],
        "journal_ref": "AI for Science workshop at ICML (International Conference on\n  Machine Learning ), Jul 2024, Viena, Austria",
        "published": "2024-06-27T08:29:04+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18990v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18990v1",
        "categories": [
            "Machine Learning"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 1,
        "chunk": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 2,
        "chunk": "we study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 3,
        "chunk": "control over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 4,
        "chunk": "mine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000095,
        "doi": null,
        "title": "Amplify Graph Learning for Recommendation via Sparsity Completion",
        "abstract": "Graph learning models have been widely deployed in collaborative filtering\n(CF) based recommendation systems. Due to the issue of data sparsity, the graph\nstructure of the original input lacks potential positive preference edges,\nwhich significantly reduces the performance of recommendations. In this paper,\nwe study how to enhance the graph structure for CF more effectively, thereby\noptimizing the representation of graph nodes. Previous works introduced matrix\ncompletion techniques into CF, proposing the use of either stochastic\ncompletion methods or superficial structure completion to address this issue.\nHowever, most of these approaches employ random numerical filling that lack\ncontrol over noise perturbations and limit the in-depth exploration of\nhigher-order interaction features of nodes, resulting in biased graph\nrepresentations.\n  In this paper, we propose an Amplify Graph Learning framework based on\nSparsity Completion (called AGL-SC). First, we utilize graph neural network to\nmine direct interaction features between user and item nodes, which are used as\nthe inputs of the encoder. Second, we design a factorization-based method to\nmine higher-order interaction features. These features serve as perturbation\nfactors in the latent space of the hidden layer to facilitate generative\nenhancement. Finally, by employing the variational inference, the above\nmulti-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "chunk-id": 5,
        "chunk": "multi-order features are integrated to implement the completion and enhancement\nof missing graph structures. We conducted benchmark and strategy experiments on\nfour real-world datasets related to recommendation tasks. The experimental\nresults demonstrate that AGL-SC significantly outperforms the state-of-the-art\nmethods.",
        "authors": [
            "Peng Yuan",
            "Haojie Li",
            "Minying Fang",
            "Xu Yu",
            "Yongjing Hao",
            "Junwei Du"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:26:20+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18984v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18984v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 1,
        "chunk": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 2,
        "chunk": "systems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 3,
        "chunk": "resource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 4,
        "chunk": "existing thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000096,
        "doi": null,
        "title": "E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors",
        "abstract": "Energy efficiency has become a key concern in modern computing. Major\nprocessor vendors now offer heterogeneous architectures that combine powerful\ncores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips,\nand Samsungs Exyno's CPUs. However, apart from simple cost-based thread\nallocation strategies, today's OS schedulers do not fully exploit these\nsystems' potential for adaptive energy-efficient computing. This is, in part,\ndue to missing application-level interfaces to pass information about\ntask-level energy consumption and application-level elasticity. This paper\npresents E-Mapper, a novel resource management approach integrated into Linux\nfor improved execution on heterogeneous processors. In E-Mapper, we base\nresource allocation decisions on high-level application descriptions that user\ncan attach to programs or that the system can learn automatically at runtime.\nOur approach supports various programming models including OpenMP, Intel TBB,\nand TensorFlow. Crucially, E-Mapper leverages this information to extend beyond\nexisting thread-to-core allocation strategies by actively managing application\nconfigurations through a novel uniform application-resource manager interface.\nBy doing so, E-Mapper achieves substantial enhancements in both performance and\nenergy efficiency, particularly in multi-application scenarios. On an Intel\nRaptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "chunk-id": 5,
        "chunk": "Raptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application\nexecution on average by 20 % with an average reduction in energy consumption of\n34 %. We argue that our solution marks a crucial step toward creating a generic\napproach for sustainable and efficient computing across different processor\narchitectures.",
        "authors": [
            "Till Smejkal",
            "Robert Khasanov",
            "Jeronimo Castrillon",
            "Hermann H\u00e4rtig"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:19:39+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18980v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18980v1",
        "categories": [
            "Operating Systems"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 1,
        "chunk": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 2,
        "chunk": "propose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 3,
        "chunk": "accurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000097,
        "doi": null,
        "title": "RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton",
        "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "chunk-id": 4,
        "chunk": "adaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview",
        "authors": [
            "Fanfan Liu",
            "Feng Yan",
            "Liming Zheng",
            "Chengjian Feng",
            "Yiyang Huang",
            "Lin Ma"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T08:13:33+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18977v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18977v1",
        "categories": [
            "Robotics",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 1,
        "chunk": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 2,
        "chunk": "in unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 3,
        "chunk": "medical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000098,
        "doi": null,
        "title": "Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis",
        "abstract": "Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "chunk-id": 4,
        "chunk": "training. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.",
        "authors": [
            "Vu Minh Hieu Phan",
            "Yutong Xie",
            "Bowen Zhang",
            "Yuankai Qi",
            "Zhibin Liao",
            "Antonios Perperidis",
            "Son Lam Phung",
            "Johan W. Verjans",
            "Minh-Son To"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:59:25+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18967v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18967v1",
        "categories": [
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 1,
        "chunk": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 2,
        "chunk": "preliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 3,
        "chunk": "contemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 4,
        "chunk": "modality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    },
    {
        "id": 10000099,
        "doi": null,
        "title": "Multi-modal Food Recommendation using Clustering and Self-supervised Learning",
        "abstract": "Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "chunk-id": 5,
        "chunk": "graphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.",
        "authors": [
            "Yixin Zhang",
            "Xin Zhou",
            "Qianwen Meng",
            "Fanglin Zhu",
            "Yonghui Xu",
            "Zhiqi Shen",
            "Lizhen Cui"
        ],
        "journal_ref": "N/A",
        "published": "2024-06-27T07:45:17+00:00",
        "pdf_link": "http://arxiv.org/pdf/2406.18962v1",
        "arxiv_link": "http://arxiv.org/abs/2406.18962v1",
        "categories": [
            "Information Retrieval"
        ]
    }
]